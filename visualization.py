#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CluMP Visualization Module
è¦ä»¶å®šç¾©æ›¸ã®æ‹¡å¼µè¦ä»¶ã«å¯¾å¿œã—ãŸå¯è¦–åŒ–æ©Ÿèƒ½

æ©Ÿèƒ½:
- ãƒ’ãƒƒãƒˆç‡æ¨ç§»ã®å¯è¦–åŒ–
- ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å·®ã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
- æ¯”è¼ƒå®Ÿé¨“çµæœã®ãƒãƒ£ãƒ¼ãƒˆ
"""

# å¯è¦–åŒ–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
try:
    import matplotlib.pyplot as plt
    import matplotlib.patches as patches
    from matplotlib.colors import LinearSegmentedColormap
    import numpy as np
    import seaborn as sns
    VISUALIZATION_AVAILABLE = True
except ImportError as e:
    print(f"å¯è¦–åŒ–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨ã§ãã¾ã›ã‚“: {e}")
    print("matplotlib, numpy, seaborn ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„: pip install matplotlib numpy seaborn")
    VISUALIZATION_AVAILABLE = False
    # ãƒ€ãƒŸãƒ¼ã‚¯ãƒ©ã‚¹ã‚’å®šç¾©
    class plt:
        @staticmethod
        def figure(*args, **kwargs): pass
        @staticmethod
        def savefig(*args, **kwargs): pass
        @staticmethod
        def close(*args, **kwargs): pass
    import math as np

from typing import List, Dict, Any, Tuple, Optional
import os
import datetime


class CluMPVisualizer:
    """
    CluMPçµæœã®å¯è¦–åŒ–ã‚¯ãƒ©ã‚¹
    è¦ä»¶å®šç¾©æ›¸æº–æ‹ ã®å¯è¦–åŒ–æ©Ÿèƒ½ã‚’æä¾›
    """
    
    def __init__(self, output_dir: str = "visualization_output"):
        """
        å¯è¦–åŒ–å™¨ã‚’åˆæœŸåŒ–
        
        Args:
            output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        """
        self.base_output_dir = output_dir
        self.visualization_enabled = VISUALIZATION_AVAILABLE
        
        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãã®ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        self.session_dir = os.path.join(output_dir, f"session_{timestamp}")
        self.output_dir = self.session_dir
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        if not os.path.exists(self.output_dir):
            os.makedirs(self.output_dir)
            print(f"ğŸ“ å¯è¦–åŒ–å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆã—ã¾ã—ãŸ: {self.output_dir}")
        
        if self.visualization_enabled:
            # ãƒ•ã‚©ãƒ³ãƒˆè¨­å®šï¼ˆè‹±èªè¡¨è¨˜ç”¨ï¼‰
            plt.rcParams['font.family'] = ['DejaVu Sans', 'Arial', 'sans-serif']
            plt.rcParams['axes.unicode_minus'] = False
            
            # ã‚¹ã‚¿ã‚¤ãƒ«è¨­å®š
            plt.style.use('seaborn-v0_8-darkgrid')
            self.colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']
        else:
            print("å¯è¦–åŒ–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨ã§ããªã„ãŸã‚ã€ãƒ†ã‚­ã‚¹ãƒˆãƒ™ãƒ¼ã‚¹ã®ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚")
    
    def plot_hit_rate_progression(self, trace: List[int], 
                                chunk_size: int = 16, cluster_size: int = 32,
                                cache_size: int = 4096, prefetch_window: int = 16,
                                window_size: int = 1000, save_path: Optional[str] = None) -> str:
        """
        ãƒ’ãƒƒãƒˆç‡æ¨ç§»ã‚’å¯è¦–åŒ–
        
        Args:
            trace: ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¹
            chunk_size: ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º
            cluster_size: ã‚¯ãƒ©ã‚¹ã‚¿ã‚µã‚¤ã‚º
            cache_size: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚º
            prefetch_window: ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒçª“
            window_size: ç§»å‹•å¹³å‡ã®çª“ã‚µã‚¤ã‚º
            save_path: ä¿å­˜ãƒ‘ã‚¹ï¼ˆæŒ‡å®šã•ã‚Œãªã‘ã‚Œã°è‡ªå‹•ç”Ÿæˆï¼‰
            
        Returns:
            str: ä¿å­˜ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        if not self.visualization_enabled:
            return self._generate_text_report("hit_rate_progression", {
                "chunk_size": chunk_size,
                "cluster_size": cluster_size,
                "trace_length": len(trace)
            })
        
        from clump_simulator import CluMPSimulator
        
        # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿åˆæœŸåŒ–
        simulator = CluMPSimulator(chunk_size, cluster_size, cache_size, prefetch_window)
        
        # ã‚¢ã‚¯ã‚»ã‚¹æ¯ã®ãƒ’ãƒƒãƒˆç‡ã‚’è¨˜éŒ²
        access_counts = []
        hit_rates = []
        
        for i, block_id in enumerate(trace):
            simulator.process_access(block_id)
            
            # ä¸€å®šé–“éš”ã§ãƒ’ãƒƒãƒˆç‡ã‚’è¨˜éŒ²
            if (i + 1) % 100 == 0:
                access_counts.append(i + 1)
                current_hit_rate = simulator.cache_hits / simulator.total_accesses
                hit_rates.append(current_hit_rate)
        
        # ç§»å‹•å¹³å‡è¨ˆç®—
        if len(hit_rates) > window_size // 100:
            window = window_size // 100
            moving_avg = self._moving_average(hit_rates, window)
            moving_avg_x = access_counts[window-1:]
        else:
            moving_avg = hit_rates
            moving_avg_x = access_counts
        
        # ãƒ—ãƒ­ãƒƒãƒˆä½œæˆ
        fig, ax = plt.subplots(figsize=(12, 8))
        
        # ãƒ’ãƒƒãƒˆç‡æ¨ç§»
        ax.plot(access_counts, hit_rates, alpha=0.3, color=self.colors[0], 
                label='Instantaneous Hit Rate', linewidth=1)
        ax.plot(moving_avg_x, moving_avg, color=self.colors[1], 
                label=f'Moving Average (window={window_size})', linewidth=2)
        
        # æœ€çµ‚ãƒ’ãƒƒãƒˆç‡ã®æ°´å¹³ç·š
        final_hit_rate = hit_rates[-1]
        ax.axhline(y=final_hit_rate, color=self.colors[2], linestyle='--', 
                  label=f'Final Hit Rate: {final_hit_rate:.3f}')
        
        # ã‚°ãƒ©ãƒ•è¨­å®š
        ax.set_xlabel('Number of Accesses', fontsize=12)
        ax.set_ylabel('Hit Rate', fontsize=12)
        ax.set_title(f'CluMP Hit Rate Progression\n'
                    f'(Chunk={chunk_size}, Cluster={cluster_size}, '
                    f'Cache={cache_size}, Prefetch Window={prefetch_window})', 
                    fontsize=14, fontweight='bold')
        ax.legend()
        ax.grid(True, alpha=0.3)
        ax.set_ylim(0, 1)
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æƒ…å ±ã‚’è¿½åŠ 
        info_text = (f'Parameters:\n'
                    f'â€¢ Chunk Size: {chunk_size} blocks\n'
                    f'â€¢ Cluster Size: {cluster_size} chunks\n' 
                    f'â€¢ Cache Size: {cache_size} blocks\n'
                    f'â€¢ Prefetch Window: {prefetch_window} blocks')
        ax.text(0.02, 0.98, info_text, transform=ax.transAxes, fontsize=10,
                verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
        
        plt.tight_layout()
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        if save_path is None:
            save_path = os.path.join(self.output_dir, 
                                   f'hit_rate_progression_c{chunk_size}_cl{cluster_size}.png')
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        return save_path
    
    def _moving_average(self, data: List[float], window: int) -> List[float]:
        """ç§»å‹•å¹³å‡ã‚’è¨ˆç®—"""
        if not VISUALIZATION_AVAILABLE:
            # numpy ãŒåˆ©ç”¨ã§ããªã„å ´åˆã®æ‰‹å‹•å®Ÿè£…
            result = []
            for i in range(window - 1, len(data)):
                avg = sum(data[i - window + 1:i + 1]) / window
                result.append(avg)
            return result
        else:
            return list(np.convolve(data, np.ones(window)/window, mode='valid'))
    
    def _generate_text_report(self, report_type: str, data: Dict[str, Any]) -> str:
        """ãƒ†ã‚­ã‚¹ãƒˆãƒ™ãƒ¼ã‚¹ã®ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        timestamp = __import__('datetime').datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{report_type}_{timestamp}.txt"
        filepath = os.path.join(self.output_dir, filename)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(f"CluMP {report_type} ãƒ¬ãƒãƒ¼ãƒˆ\n")
            f.write("=" * 50 + "\n")
            f.write(f"ç”Ÿæˆæ—¥æ™‚: {__import__('datetime').datetime.now()}\n\n")
            
            for key, value in data.items():
                f.write(f"{key}: {value}\n")
            
            f.write("\næ³¨æ„: å¯è¦–åŒ–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨ã§ããªã„ãŸã‚ã€ã‚°ãƒ©ãƒ•ã¯ç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚\n")
            f.write("matplotlib, numpy, seaborn ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\n")
        
        return filepath
    
    def plot_parameter_heatmap(self, results: List[Dict[str, Any]], 
                             metric: str = 'hit_rate',
                             save_path: Optional[str] = None) -> str:
        """
        ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å·®ã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’ä½œæˆ
        
        Args:
            results: å®Ÿé¨“çµæœã®ãƒªã‚¹ãƒˆ
            metric: å¯è¦–åŒ–ã™ã‚‹è©•ä¾¡æŒ‡æ¨™
            save_path: ä¿å­˜ãƒ‘ã‚¹
            
        Returns:
            str: ä¿å­˜ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        if not self.visualization_enabled:
            return self._generate_parameter_text_report(results, metric)
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®çµ„ã¿åˆã‚ã›ã‚’æŠ½å‡º
        chunk_sizes = sorted(list(set(r['chunk_size'] for r in results)))
        cluster_sizes = sorted(list(set(r['cluster_size'] for r in results)))
        
        # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ç”¨ã®ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ä½œæˆ
        heatmap_data = [[0 for _ in chunk_sizes] for _ in cluster_sizes]
        
        for result in results:
            chunk_idx = chunk_sizes.index(result['chunk_size'])
            cluster_idx = cluster_sizes.index(result['cluster_size'])
            heatmap_data[cluster_idx][chunk_idx] = result[metric]
        
        # ãƒ—ãƒ­ãƒƒãƒˆä½œæˆ
        fig, ax = plt.subplots(figsize=(10, 8))
        
        # ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—è¨­å®š
        if metric == 'hit_rate':
            cmap = 'RdYlGn'
            vmin, vmax = 0, 1
        elif metric == 'prefetch_efficiency':
            cmap = 'Blues'
            vmin, vmax = 0, 1
        else:
            cmap = 'viridis'
            vmin, vmax = None, None
        
        # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—æç”»
        heatmap_array = np.array(heatmap_data)
        im = ax.imshow(heatmap_array, cmap=cmap, aspect='auto', vmin=vmin, vmax=vmax)
        
        # è»¸è¨­å®š
        ax.set_xticks(range(len(chunk_sizes)))
        ax.set_yticks(range(len(cluster_sizes)))
        ax.set_xticklabels(chunk_sizes)
        ax.set_yticklabels(cluster_sizes)
        ax.set_xlabel('Chunk Size (blocks)', fontsize=12)
        ax.set_ylabel('Cluster Size (chunks)', fontsize=12)
        
        # ã‚¿ã‚¤ãƒˆãƒ«è¨­å®š
        metric_names = {
            'hit_rate': 'Hit Rate',
            'prefetch_efficiency': 'Prefetch Efficiency',
            'memory_usage_mc_rows': 'Memory Usage (MC Rows)'
        }
        title = f'Parameter {metric_names.get(metric, metric)} Heatmap'
        ax.set_title(title, fontsize=14, fontweight='bold')
        
        # æ•°å€¤ã‚’å„ã‚»ãƒ«ã«è¡¨ç¤º
        for i in range(len(cluster_sizes)):
            for j in range(len(chunk_sizes)):
                value = heatmap_data[i][j]
                if metric in ['hit_rate', 'prefetch_efficiency']:
                    text = f'{value:.3f}'
                else:
                    text = f'{int(value)}'
                ax.text(j, i, text, ha='center', va='center', 
                       color='white' if value < (vmax or np.max(heatmap_array)) * 0.5 else 'black')
        
        # ã‚«ãƒ©ãƒ¼ãƒãƒ¼
        cbar = plt.colorbar(im, ax=ax)
        if metric in ['hit_rate', 'prefetch_efficiency']:
            cbar.set_label(f'{metric_names.get(metric, metric)} (0-1)', fontsize=12)
        else:
            cbar.set_label(metric_names.get(metric, metric), fontsize=12)
        
        plt.tight_layout()
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        if save_path is None:
            save_path = os.path.join(self.output_dir, f'parameter_heatmap_{metric}.png')
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        return save_path
    
    def _generate_parameter_text_report(self, results: List[Dict[str, Any]], metric: str) -> str:
        """ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åˆ†æã®ãƒ†ã‚­ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        timestamp = __import__('datetime').datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"parameter_analysis_{metric}_{timestamp}.txt"
        filepath = os.path.join(self.output_dir, filename)
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®çµ„ã¿åˆã‚ã›ã‚’æŠ½å‡º
        chunk_sizes = sorted(list(set(r['chunk_size'] for r in results)))
        cluster_sizes = sorted(list(set(r['cluster_size'] for r in results)))
        
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(f"CluMP ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åˆ†æãƒ¬ãƒãƒ¼ãƒˆ - {metric}\n")
            f.write("=" * 60 + "\n")
            f.write(f"ç”Ÿæˆæ—¥æ™‚: {__import__('datetime').datetime.now()}\n\n")
            
            f.write("ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åˆ¥çµæœ:\n")
            f.write("-" * 40 + "\n")
            
            # è¡¨å½¢å¼ã§å‡ºåŠ›
            f.write(f"{'ãƒãƒ£ãƒ³ã‚¯\\ã‚¯ãƒ©ã‚¹ã‚¿':<12}")
            for cluster_size in cluster_sizes:
                f.write(f"{cluster_size:>8}")
            f.write("\n")
            
            for chunk_size in chunk_sizes:
                f.write(f"{chunk_size:<12}")
                for cluster_size in cluster_sizes:
                    # è©²å½“ã™ã‚‹çµæœã‚’æ¤œç´¢
                    value = None
                    for result in results:
                        if result['chunk_size'] == chunk_size and result['cluster_size'] == cluster_size:
                            value = result[metric]
                            break
                    
                    if value is not None:
                        if metric in ['hit_rate', 'prefetch_efficiency']:
                            f.write(f"{value:8.3f}")
                        else:
                            f.write(f"{int(value):8}")
                    else:
                        f.write(f"{'N/A':>8}")
                f.write("\n")
            
            # æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ç‰¹å®š
            best_result = max(results, key=lambda x: x[metric])
            f.write(f"\næœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:\n")
            f.write(f"  ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º: {best_result['chunk_size']}\n")
            f.write(f"  ã‚¯ãƒ©ã‚¹ã‚¿ã‚µã‚¤ã‚º: {best_result['cluster_size']}\n")
            f.write(f"  {metric}: {best_result[metric]}\n")
        
        return filepath
    
    def plot_baseline_comparison(self, comparison: Dict[str, Dict[str, Any]], 
                               save_path: Optional[str] = None) -> str:
        """
        ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆã‚’ä½œæˆ
        
        Args:
            comparison: æ¯”è¼ƒçµæœ
            save_path: ä¿å­˜ãƒ‘ã‚¹
            
        Returns:
            str: ä¿å­˜ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        if not self.visualization_enabled:
            return self._generate_comparison_text_report(comparison)
        
        clump = comparison['clump']
        baseline = comparison['baseline']
        
        # æ¯”è¼ƒã™ã‚‹æŒ‡æ¨™
        metrics = ['hit_rate', 'prefetch_efficiency', 'prefetch_total', 'prefetch_used']
        metric_names = ['Hit Rate', 'Prefetch Efficiency', 'Prefetch Total', 'Prefetch Used']
        
        # ãƒ‡ãƒ¼ã‚¿æº–å‚™
        clump_values = [clump[metric] for metric in metrics]
        baseline_values = [baseline[metric] for metric in metrics]
        
        # ãƒ—ãƒ­ãƒƒãƒˆä½œæˆ
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
        axes = [ax1, ax2, ax3, ax4]
        
        for i, (ax, metric, name) in enumerate(zip(axes, metrics, metric_names)):
            methods = ['CluMP', 'Baseline']
            values = [clump_values[i], baseline_values[i]]
            colors = [self.colors[0], self.colors[1]]
            
            bars = ax.bar(methods, values, color=colors, alpha=0.8)
            
            # æ•°å€¤ãƒ©ãƒ™ãƒ«è¿½åŠ 
            for bar, value in zip(bars, values):
                height = bar.get_height()
                if metric in ['hit_rate', 'prefetch_efficiency']:
                    label = f'{value:.3f}'
                else:
                    label = f'{int(value):,}'
                ax.text(bar.get_x() + bar.get_width()/2., height + height*0.01,
                       label, ha='center', va='bottom', fontweight='bold')
            
            ax.set_title(name, fontsize=12, fontweight='bold')
            ax.set_ylabel('Value', fontsize=10)
            
            if metric in ['hit_rate', 'prefetch_efficiency']:
                ax.set_ylim(0, 1)
            else:
                ax.set_ylim(0, max(values) * 1.1)
            
            # æ”¹å–„ç‡è¨ˆç®—ã¨è¡¨ç¤º
            if baseline_values[i] > 0:
                improvement = ((clump_values[i] - baseline_values[i]) / baseline_values[i]) * 100
                improvement_text = f'Improvement: {improvement:+.1f}%'
                ax.text(0.5, 0.95, improvement_text, transform=ax.transAxes, 
                       ha='center', va='top', fontsize=10, 
                       bbox=dict(boxstyle='round', facecolor='lightgreen' if improvement > 0 else 'lightcoral', alpha=0.7))
        
        plt.suptitle('CluMP vs Baseline Comparison', fontsize=16, fontweight='bold')
        plt.tight_layout()
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        if save_path is None:
            save_path = os.path.join(self.output_dir, 'baseline_comparison.png')
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        return save_path
    
    def _generate_comparison_text_report(self, comparison: Dict[str, Dict[str, Any]]) -> str:
        """ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒã®ãƒ†ã‚­ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        timestamp = __import__('datetime').datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"baseline_comparison_{timestamp}.txt"
        filepath = os.path.join(self.output_dir, filename)
        
        clump = comparison['clump']
        baseline = comparison['baseline']
        
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write("CluMP vs ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆ\n")
            f.write("=" * 50 + "\n")
            f.write(f"ç”Ÿæˆæ—¥æ™‚: {__import__('datetime').datetime.now()}\n\n")
            
            metrics = [
                ('hit_rate', 'ãƒ’ãƒƒãƒˆç‡'),
                ('prefetch_efficiency', 'ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒåŠ¹ç‡'),
                ('prefetch_total', 'ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒç·æ•°'),
                ('prefetch_used', 'ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒä½¿ç”¨æ•°'),
                ('memory_usage_mc_rows', 'ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ (MCè¡Œæ•°)')
            ]
            
            for metric, name in metrics:
                if metric in clump and metric in baseline:
                    clump_val = clump[metric]
                    baseline_val = baseline[metric]
                    
                    f.write(f"{name}:\n")
                    if isinstance(clump_val, float):
                        f.write(f"  CluMP:      {clump_val:.3f}\n")
                    else:
                        f.write(f"  CluMP:      {clump_val}\n")
                    
                    if isinstance(baseline_val, float):
                        f.write(f"  ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³: {baseline_val:.3f}\n")
                    else:
                        f.write(f"  ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³: {baseline_val}\n")
                    
                    if baseline_val > 0:
                        improvement = ((clump_val - baseline_val) / baseline_val) * 100
                        f.write(f"  æ”¹å–„ç‡:     {improvement:+.1f}%\n")
                    f.write("\n")
        
        return filepath
    
    def create_visualization_report(self, results: List[Dict[str, Any]], 
                                  analysis: Dict[str, Any],
                                  comparison: Dict[str, Dict[str, Any]],
                                  trace: List[int]) -> List[str]:
        """
        åŒ…æ‹¬çš„ãªå¯è¦–åŒ–ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
        
        å„ç¨®é¡ã®ã‚°ãƒ©ãƒ•ã”ã¨ã«ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆã—ã€æ•´ç†ã•ã‚ŒãŸå½¢ã§å‡ºåŠ›ã—ã¾ã™ã€‚
        
        ãƒ•ã‚©ãƒ«ãƒ€æ§‹é€ :
        visualization_output/
        â””â”€â”€ session_YYYYMMDD_HHMMSS/
            â”œâ”€â”€ hit_rate_progression/
            â”œâ”€â”€ parameter_heatmaps/
            â”œâ”€â”€ baseline_comparison/
            â””â”€â”€ summary_report.txt
        
        Args:
            results: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å®Ÿé¨“çµæœ
            analysis: åˆ†æçµæœ
            comparison: ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒçµæœ
            trace: ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¹
            
        Returns:
            List[str]: ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆ
        """
        generated_files = []
        
        print("ğŸ“Š å¯è¦–åŒ–ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­...")
        print(f"å‡ºåŠ›å…ˆ: {self.output_dir}")
        
        # ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ
        subfolders = {
            'hit_rate_progression': 'ãƒ’ãƒƒãƒˆç‡æ¨ç§»',
            'parameter_heatmaps': 'ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—',
            'baseline_comparison': 'ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒ'
        }
        
        for folder_name, description in subfolders.items():
            folder_path = os.path.join(self.output_dir, folder_name)
            if not os.path.exists(folder_path):
                os.makedirs(folder_path)
                print(f"  ğŸ“ {description}ãƒ•ã‚©ãƒ«ãƒ€ä½œæˆ: {folder_name}/")
        
        # 1. ãƒ’ãƒƒãƒˆç‡æ¨ç§»
        print("  1. ãƒ’ãƒƒãƒˆç‡æ¨ç§»ãƒãƒ£ãƒ¼ãƒˆç”Ÿæˆä¸­...")
        best_params = analysis['best_parameters']
        hit_rate_path = self.plot_hit_rate_progression(
            trace, 
            chunk_size=best_params['chunk_size'],
            cluster_size=best_params['cluster_size'],
            save_path=os.path.join(self.output_dir, 'hit_rate_progression', 
                                 f'hit_rate_progression_best_params.png')
        )
        generated_files.append(hit_rate_path)
        
        # 2. ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼ˆè¤‡æ•°æŒ‡æ¨™ï¼‰
        metrics_info = {
            'hit_rate': 'ãƒ’ãƒƒãƒˆç‡',
            'prefetch_efficiency': 'ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒåŠ¹ç‡', 
            'memory_usage_mc_rows': 'ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡'
        }
        
        for metric, description in metrics_info.items():
            print(f"  2. {description}ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ç”Ÿæˆä¸­...")
            heatmap_path = self.plot_parameter_heatmap(
                results, 
                metric,
                save_path=os.path.join(self.output_dir, 'parameter_heatmaps',
                                     f'heatmap_{metric}.png')
            )
            generated_files.append(heatmap_path)
        
        # 3. ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒ
        if comparison:
            print("  3. ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆç”Ÿæˆä¸­...")
            comparison_path = self.plot_baseline_comparison(
                comparison,
                save_path=os.path.join(self.output_dir, 'baseline_comparison',
                                     'clump_vs_baseline.png')
            )
            generated_files.append(comparison_path)
        else:
            print("  3. ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒãƒ‡ãƒ¼ã‚¿ãªã— - ã‚¹ã‚­ãƒƒãƒ—")
        
        # 4. ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
        print("  4. ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­...")
        summary_path = self._create_summary_report(results, analysis, comparison)
        generated_files.append(summary_path)
        
        print(f"âœ… å¯è¦–åŒ–ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†ï¼")
        print(f"ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {self.output_dir}")
        print(f"ğŸ“„ ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(generated_files)}")
        print(f"\nğŸ“‹ ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«:")
        for i, path in enumerate(generated_files, 1):
            relative_path = os.path.relpath(path, self.base_output_dir)
            print(f"  {i}. {relative_path}")
        
        return generated_files
    
    def _create_summary_report(self, results: List[Dict[str, Any]], 
                             analysis: Dict[str, Any],
                             comparison: Optional[Dict[str, Dict[str, Any]]]) -> str:
        """
        å¯è¦–åŒ–ãƒ¬ãƒãƒ¼ãƒˆã®ã‚µãƒãƒªãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        
        Args:
            results: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å®Ÿé¨“çµæœ
            analysis: åˆ†æçµæœ  
            comparison: ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒçµæœ
            
        Returns:
            str: ã‚µãƒãƒªãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        """
        summary_path = os.path.join(self.output_dir, 'summary_report.txt')
        
        with open(summary_path, 'w', encoding='utf-8') as f:
            # ãƒ˜ãƒƒãƒ€ãƒ¼
            timestamp = datetime.datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S")
            f.write("=" * 80 + "\n")
            f.write("CluMP å¯è¦–åŒ–ãƒ¬ãƒãƒ¼ãƒˆ ã‚µãƒãƒªãƒ¼\n")
            f.write("=" * 80 + "\n")
            f.write(f"ç”Ÿæˆæ—¥æ™‚: {timestamp}\n")
            f.write(f"å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {self.output_dir}\n\n")
            
            # å®Ÿé¨“æ¦‚è¦
            f.write("ğŸ“Š å®Ÿé¨“æ¦‚è¦\n")
            f.write("-" * 40 + "\n")
            f.write(f"ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿çµ„ã¿åˆã‚ã›æ•°: {len(results)}\n")
            
            chunk_sizes = sorted(list(set(r['chunk_size'] for r in results)))
            cluster_sizes = sorted(list(set(r['cluster_size'] for r in results)))
            f.write(f"ãƒ†ã‚¹ãƒˆã—ãŸãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º: {chunk_sizes}\n")
            f.write(f"ãƒ†ã‚¹ãƒˆã—ãŸã‚¯ãƒ©ã‚¹ã‚¿ã‚µã‚¤ã‚º: {cluster_sizes}\n\n")
            
            # æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            if 'best_parameters' in analysis:
                best = analysis['best_parameters']
                f.write("ğŸ† æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\n")
                f.write("-" * 40 + "\n")
                f.write(f"ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º: {best['chunk_size']} ãƒ–ãƒ­ãƒƒã‚¯\n")
                f.write(f"ã‚¯ãƒ©ã‚¹ã‚¿ã‚µã‚¤ã‚º: {best['cluster_size']} ãƒãƒ£ãƒ³ã‚¯\n")
                f.write(f"ãƒ’ãƒƒãƒˆç‡: {best['hit_rate']:.3f} ({best['hit_rate']*100:.1f}%)\n")
                f.write(f"ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒåŠ¹ç‡: {best['prefetch_efficiency']:.3f} ({best['prefetch_efficiency']*100:.1f}%)\n")
                f.write(f"MCè¡Œæ•°: {best['mc_rows']:,}\n\n")
            
            # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒ
            if comparison and 'clump' in comparison and 'baseline' in comparison:
                clump_hit = comparison['clump']['hit_rate']
                baseline_hit = comparison['baseline']['hit_rate']
                if baseline_hit > 0:
                    improvement = (clump_hit - baseline_hit) / baseline_hit * 100
                    f.write("ğŸ“ˆ ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒ\n")
                    f.write("-" * 40 + "\n")
                    f.write(f"CluMP ãƒ’ãƒƒãƒˆç‡: {clump_hit:.3f} ({clump_hit*100:.1f}%)\n")
                    f.write(f"ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ ãƒ’ãƒƒãƒˆç‡: {baseline_hit:.3f} ({baseline_hit*100:.1f}%)\n")
                    f.write(f"æ”¹å–„ç‡: {improvement:+.1f}%\n\n")
            
            # ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«
            f.write("ğŸ“„ ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«\n")
            f.write("-" * 40 + "\n")
            f.write("hit_rate_progression/\n")
            f.write("  - hit_rate_progression_best_params.png : æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã®ãƒ’ãƒƒãƒˆç‡æ¨ç§»\n\n")
            
            f.write("parameter_heatmaps/\n")
            f.write("  - heatmap_hit_rate.png : ãƒ’ãƒƒãƒˆç‡ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—\n")
            f.write("  - heatmap_prefetch_efficiency.png : ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒåŠ¹ç‡ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—\n") 
            f.write("  - heatmap_memory_usage_mc_rows.png : ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—\n\n")
            
            if comparison:
                f.write("baseline_comparison/\n")
                f.write("  - clump_vs_baseline.png : CluMP vs ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒ\n\n")
            
            # ä½¿ç”¨æ–¹æ³•
            f.write("ğŸ’¡ ãƒ•ã‚¡ã‚¤ãƒ«ã®è¦‹æ–¹\n")
            f.write("-" * 40 + "\n")
            f.write("1. ãƒ’ãƒƒãƒˆç‡æ¨ç§»: å­¦ç¿’åŠ¹æœã¨åæŸã®æ§˜å­ã‚’ç¢ºèª\n")
            f.write("2. ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿é–“ã®æ€§èƒ½å·®ã‚’è‰²ã§å¯è¦–åŒ–\n")
            f.write("3. ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒ: CluMPã®æœ‰åŠ¹æ€§ã‚’å®šé‡è©•ä¾¡\n")
            f.write("4. æš–è‰²ç³»(èµ¤): é«˜æ€§èƒ½ã€å¯’è‰²ç³»(é’): ä½æ€§èƒ½\n\n")
            
            f.write("=" * 80 + "\n")
        
        return summary_path


def create_visualization_demo():
    """
    å¯è¦–åŒ–ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    
    æ–°ã—ã„ãƒ•ã‚©ãƒ«ãƒ€æ§‹é€ ã§ã®å¯è¦–åŒ–æ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆã—ã¾ã™ã€‚
    """
    from clump_simulator import TraceGenerator
    import random
    
    # ãƒ‡ãƒ¢ç”¨ã®è¨­å®š
    random.seed(42)
    visualizer = CluMPVisualizer(output_dir="demo_visualization")
    
    print("ğŸ“Š å¯è¦–åŒ–ãƒ‡ãƒ¢å®Ÿè¡Œä¸­...")
    print(f"å¯è¦–åŒ–æ©Ÿèƒ½åˆ©ç”¨å¯èƒ½: {VISUALIZATION_AVAILABLE}")
    print(f"å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {visualizer.output_dir}")
    
    # å°è¦æ¨¡ãƒˆãƒ¬ãƒ¼ã‚¹ç”Ÿæˆ
    trace = TraceGenerator.generate_synthetic_trace(
        n_events=2000,  # è¦æ¨¡ã‚’å°ã•ãã—ã¦ãƒ†ã‚¹ãƒˆ
        num_files=20,
        avg_file_length_blocks=50,
        sequential_prob=0.6,
        jump_prob=0.1
    )
    
    # ãƒ’ãƒƒãƒˆç‡æ¨ç§»ã®ä¾‹ï¼ˆãƒ‡ãƒ¢ç”¨ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ã«ä¿å­˜ï¼‰
    print("1. ãƒ’ãƒƒãƒˆç‡æ¨ç§»ãƒãƒ£ãƒ¼ãƒˆç”Ÿæˆ...")
    demo_subfolder = os.path.join(visualizer.output_dir, "demo_charts")
    if not os.path.exists(demo_subfolder):
        os.makedirs(demo_subfolder)
    
    hit_rate_path = visualizer.plot_hit_rate_progression(
        trace,
        save_path=os.path.join(demo_subfolder, "demo_hit_rate_progression.png")
    )
    print(f"   â†’ {os.path.relpath(hit_rate_path)}")
    
    print("âœ… å¯è¦–åŒ–ãƒ‡ãƒ¢å®Œäº†ï¼")
    print(f"ğŸ“ å‡ºåŠ›å…ˆã‚’ç¢ºèªã—ã¦ãã ã•ã„: {visualizer.output_dir}")


if __name__ == "__main__":
    create_visualization_demo()