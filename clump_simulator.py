#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CluMP (CLUstered Markov-chain Prefetching) Simulator - Paper-Based Implementation
è«–æ–‡æº–æ‹ å®Œå…¨ç‰ˆå®Ÿè£…

åŸºäºè«–æ–‡ "CluMP: Clustered Markov Chain for Storage I/O Prefetch" çš„ç²¾ç¢ºå¯¦ç¾
Section 3.2-3.3ã®è¨­è¨ˆä»•æ§˜ã¨Section 4ã®è©•ä¾¡æ–¹æ³•ã‚’å¿ å®Ÿã«å†ç¾

ä¸»è¦ãªä¿®æ­£ç‚¹:
1. MCRowæ§‹é€ ï¼šè«–æ–‡æº–æ‹ ã®6ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰(CN1-CN3, P1-P3)ã¨å‹•çš„ã‚½ãƒ¼ãƒˆ
2. 8ã‚¹ãƒ†ãƒƒãƒ—ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼šè«–æ–‡Section 3.3ã®å®Œå…¨å®Ÿè£…
3. ãƒãƒ£ãƒ³ã‚¯ãƒ»ã‚¯ãƒ©ã‚¹ã‚¿ç®¡ç†ï¼šå‹•çš„å‰²ã‚Šå½“ã¦ã¨ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–
4. Linuxå…ˆèª­ã¿æ¯”è¼ƒï¼šè«–æ–‡ã¨åŒã˜æ¡ä»¶ã§ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³å®Ÿè£…
5. è©•ä¾¡æŒ‡æ¨™ï¼šãƒ—ãƒªãƒ•ã‚§ãƒƒãƒãƒ’ãƒƒãƒˆç‡ã€ãƒŸã‚¹ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒã€ãƒ¡ãƒ¢ãƒªã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰

ä½œæˆè€…: GitHub Copilot (è«–æ–‡æº–æ‹ ç‰ˆ)
æ›´æ–°æ—¥: 2025å¹´9æœˆ19æ—¥
å‚è€ƒæ–‡çŒ®: CluMPè«–æ–‡ Section 3-4
"""

from collections import OrderedDict
import logging
import random
import time
import math
from typing import List, Dict, Tuple, Optional, Any, Union

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')


class LRUCache:
    """
    LRU (Least Recently Used) ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®å®Ÿè£…
    
    CluMPã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«ãŠã‘ã‚‹ä¸­æ ¸çš„ãªã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†ã‚¯ãƒ©ã‚¹ã€‚
    è«–æ–‡ã«åŸºã¥ãã€ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒçµ±è¨ˆã‚‚ç®¡ç†ã™ã‚‹ã€‚
    
    çµ±è¨ˆè¿½è·¡:
    - prefetch_total: ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒã•ã‚ŒãŸãƒ–ãƒ­ãƒƒã‚¯ç·æ•°
    - prefetch_used: å®Ÿéš›ã«ã‚¢ã‚¯ã‚»ã‚¹ã•ã‚ŒãŸãƒ—ãƒªãƒ•ã‚§ãƒƒãƒãƒ–ãƒ­ãƒƒã‚¯æ•°  
    - prefetch_unused: æœªä½¿ç”¨ã®ã¾ã¾è¿½ã„å‡ºã•ã‚ŒãŸãƒ—ãƒªãƒ•ã‚§ãƒƒãƒãƒ–ãƒ­ãƒƒã‚¯æ•°
    """
    
    def __init__(self, cache_size_blocks: int):
        """
        LRUã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’åˆæœŸåŒ–
        
        Args:
            cache_size_blocks: ã‚­ãƒ£ãƒƒã‚·ãƒ¥å®¹é‡ï¼ˆãƒ–ãƒ­ãƒƒã‚¯æ•°ï¼‰
        """
        if cache_size_blocks <= 0:
            raise ValueError("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºã¯æ­£ã®å€¤ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™")
            
        self.cache_size = cache_size_blocks
        # key=block_id, val=(is_prefetched, was_used_after_prefetch)
        self.cache: OrderedDict[int, Tuple[bool, bool]] = OrderedDict()
        
        # ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒçµ±è¨ˆï¼ˆè«–æ–‡æº–æ‹ ï¼‰
        self.prefetch_stats = {
            "prefetch_total": 0,           # ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒç·æ•°
            "prefetch_used": 0,            # ä½¿ç”¨ã•ã‚ŒãŸãƒ—ãƒªãƒ•ã‚§ãƒƒãƒæ•°
            "prefetch_unused": 0           # æœªä½¿ç”¨ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒæ•°
        }
        
        logging.debug(f"LRUCacheåˆæœŸåŒ–: ã‚µã‚¤ã‚º={cache_size_blocks}ãƒ–ãƒ­ãƒƒã‚¯")
    
    def access(self, block_id: int) -> bool:
        """
        ãƒ–ãƒ­ãƒƒã‚¯ã‚¢ã‚¯ã‚»ã‚¹å‡¦ç†
        
        Args:
            block_id: ã‚¢ã‚¯ã‚»ã‚¹å¯¾è±¡ã®ãƒ–ãƒ­ãƒƒã‚¯ID
            
        Returns:
            bool: ãƒ’ãƒƒãƒˆã—ãŸå ´åˆTrueã€ãƒŸã‚¹ã—ãŸå ´åˆFalse
        """
        if block_id in self.cache:
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆï¼šLRUé †åºã‚’æ›´æ–°
            is_prefetched, was_used = self.cache[block_id]
            
            # ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒã•ã‚ŒãŸãƒ–ãƒ­ãƒƒã‚¯ã®åˆå›ã‚¢ã‚¯ã‚»ã‚¹
            if is_prefetched and not was_used:
                self.prefetch_stats["prefetch_used"] += 1
                was_used = True
            
            # LRUé †åºæ›´æ–°ï¼ˆæœ€æ–°ã«ç§»å‹•ï¼‰
            self.cache[block_id] = (is_prefetched, was_used)
            self.cache.move_to_end(block_id)
            
            return True
        
        return False  # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹
    
    def insert(self, block_id: int, is_prefetch: bool = False) -> None:
        """
        ãƒ–ãƒ­ãƒƒã‚¯ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«æŒ¿å…¥
        
        Args:
            block_id: æŒ¿å…¥ã™ã‚‹ãƒ–ãƒ­ãƒƒã‚¯ID
            is_prefetch: ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒã«ã‚ˆã‚‹æŒ¿å…¥ã‹ã©ã†ã‹
        """
        if block_id in self.cache:
            # æ—¢å­˜ãƒ–ãƒ­ãƒƒã‚¯ã®å ´åˆã¯çŠ¶æ…‹ã‚’æ›´æ–°
            _, was_used = self.cache[block_id]
            self.cache[block_id] = (is_prefetch, was_used)
            self.cache.move_to_end(block_id)
            return
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥å®¹é‡ãƒã‚§ãƒƒã‚¯
        if len(self.cache) >= self.cache_size:
            # LRUï¼ˆæœ€ã‚‚å¤ã„ï¼‰ã‚¨ãƒ³ãƒˆãƒªã‚’è¿½ã„å‡ºã—
            lru_block, (was_prefetched, was_used) = self.cache.popitem(last=False)
            
            # æœªä½¿ç”¨ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒã®çµ±è¨ˆæ›´æ–°
            if was_prefetched and not was_used:
                self.prefetch_stats["prefetch_unused"] += 1
        
        # æ–°ãƒ–ãƒ­ãƒƒã‚¯æŒ¿å…¥
        self.cache[block_id] = (is_prefetch, False)
        
        # ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒçµ±è¨ˆæ›´æ–°
        if is_prefetch:
            self.prefetch_stats["prefetch_total"] += 1
    
    def get_prefetch_stats(self) -> Dict[str, int]:
        """ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒçµ±è¨ˆã‚’å–å¾—"""
        return self.prefetch_stats.copy()
    
    def get_cache_info(self) -> Dict[str, Any]:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥æƒ…å ±ã‚’å–å¾—"""
        return {
            "cache_size": self.cache_size,
            "current_usage": len(self.cache),
            "usage_rate": len(self.cache) / self.cache_size
        }


class MCRow:
    """
    Markov Chain Row - ãƒãƒ«ã‚³ãƒ•é€£é–ã®è¡Œï¼ˆè«–æ–‡æº–æ‹ ç‰ˆï¼‰
    
    è«–æ–‡Section 3.3ã«åŸºã¥ãæ­£ç¢ºãªå®Ÿè£…ï¼š
    - CN1, CN2, CN3: æ¬¡ãƒãƒ£ãƒ³ã‚¯å€™è£œï¼ˆç¢ºç‡é †ï¼‰
    - P1, P2, P3: å¯¾å¿œã™ã‚‹é·ç§»é »åº¦
    - å‹•çš„ã‚½ãƒ¼ãƒˆæ©Ÿèƒ½ï¼ˆé »åº¦é †ã€åŒå€¤ãªã‚‰æœ€æ–°å„ªå…ˆï¼‰
    - CN3ã¯ã‚½ãƒ¼ãƒˆç”¨ãƒãƒƒãƒ•ã‚¡ã¨ã—ã¦ã‚‚æ©Ÿèƒ½
    """
    
    def __init__(self):
        """MCRowã‚’åˆæœŸåŒ–"""
        # è«–æ–‡æº–æ‹ ã®6ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ§‹é€ 
        self.CN1: int = -1  # æœ€ã‚‚é »ç¹ã«ã‚¢ã‚¯ã‚»ã‚¹ã•ã‚Œã‚‹ãƒãƒ£ãƒ³ã‚¯ç•ªå·
        self.CN2: int = -1  # 2ç•ªç›®ã«é »ç¹ã«ã‚¢ã‚¯ã‚»ã‚¹ã•ã‚Œã‚‹ãƒãƒ£ãƒ³ã‚¯ç•ªå·
        self.CN3: int = -1  # æœ€ã‚‚æœ€è¿‘ã‚¢ã‚¯ã‚»ã‚¹ã•ã‚ŒãŸãƒãƒ£ãƒ³ã‚¯ç•ªå·ï¼ˆã‚½ãƒ¼ãƒˆãƒãƒƒãƒ•ã‚¡ï¼‰
        self.P1: int = 0    # CN1ã¸ã®é·ç§»é »åº¦
        self.P2: int = 0    # CN2ã¸ã®é·ç§»é »åº¦  
        self.P3: int = 0    # CN3ã¸ã®é·ç§»é »åº¦
        
        # æœ€æ–°æ›´æ–°æ™‚åˆ»ï¼ˆåŒå€¤ã‚½ãƒ¼ãƒˆç”¨ï¼‰
        self._last_update_time = {
            1: 0,  # CN1ã®æœ€çµ‚æ›´æ–°æ™‚åˆ»
            2: 0,  # CN2ã®æœ€çµ‚æ›´æ–°æ™‚åˆ»
            3: 0   # CN3ã®æœ€çµ‚æ›´æ–°æ™‚åˆ»
        }
        self._global_time = 0
    
    def update_transition(self, next_chunk_id: int) -> None:
        """
        é·ç§»ã‚’æ›´æ–°ï¼ˆè«–æ–‡æº–æ‹ ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼‰
        
        Args:
            next_chunk_id: æ¬¡ã«ã‚¢ã‚¯ã‚»ã‚¹ã•ã‚ŒãŸãƒãƒ£ãƒ³ã‚¯ID
            
        è«–æ–‡ã®è¨˜è¿°ï¼š
        "è¤‡æ•°ã®Pxå€¤ãŒç­‰ã—ã„å ´åˆã€æœ€ã‚‚æœ€è¿‘æ›´æ–°ã•ã‚ŒãŸå€¤ãŒæ¬¡ã«ã‚¢ã‚¯ã‚»ã‚¹ã•ã‚Œã‚‹ç¢ºç‡ãŒé«˜ã„ã¨è¦‹ãªã•ã‚Œã‚‹"
        """
        self._global_time += 1
        
        # æ—¢å­˜ãƒãƒ£ãƒ³ã‚¯ã®å ´åˆï¼šå¯¾å¿œã™ã‚‹é »åº¦ã‚’å¢—åŠ 
        if next_chunk_id == self.CN1:
            self.P1 += 1
            self._last_update_time[1] = self._global_time
        elif next_chunk_id == self.CN2:
            self.P2 += 1
            self._last_update_time[2] = self._global_time
        elif next_chunk_id == self.CN3:
            self.P3 += 1
            self._last_update_time[3] = self._global_time
        else:
            # æ–°ãƒãƒ£ãƒ³ã‚¯ã®å ´åˆï¼šCN3ã‚’ç½®æ›
            self.CN3 = next_chunk_id
            self.P3 = 1
            self._last_update_time[3] = self._global_time
        
        # å‹•çš„ã‚½ãƒ¼ãƒˆå®Ÿè¡Œï¼ˆé »åº¦é †ã€åŒå€¤ãªã‚‰æœ€æ–°å„ªå…ˆï¼‰
        self._sort_candidates()
    
    def _sort_candidates(self) -> None:
        """
        å€™è£œã‚’ã‚½ãƒ¼ãƒˆï¼ˆé »åº¦é †ã€åŒå€¤ãªã‚‰æœ€æ–°æ›´æ–°å„ªå…ˆï¼‰
        
        è«–æ–‡ã®è¨˜è¿°ï¼š
        "P1ã¨P2ãŒåŒã˜å€¤ã‚’æŒã¤ãŒã€æœ€ã‚‚æœ€è¿‘æ›´æ–°ã•ã‚ŒãŸCN2ã«æ ¼ç´ã•ã‚ŒãŸãƒãƒ£ãƒ³ã‚¯å€¤ãŒ
        CN1ã®ãƒãƒ£ãƒ³ã‚¯å€¤ã¨äº¤æ›ã•ã‚Œã€CN1ã®ä»¥å‰ã®å€¤ãŒCN2ã«å‰²ã‚Šå½“ã¦ã‚‰ã‚Œã‚‹"
        """
        # ç¾åœ¨ã®å€™è£œãƒªã‚¹ãƒˆï¼ˆæœ‰åŠ¹ãªã‚‚ã®ã®ã¿ï¼‰
        candidates = []
        
        if self.CN1 >= 0:
            candidates.append((self.CN1, self.P1, self._last_update_time[1], 1))
        if self.CN2 >= 0:
            candidates.append((self.CN2, self.P2, self._last_update_time[2], 2))
        if self.CN3 >= 0:
            candidates.append((self.CN3, self.P3, self._last_update_time[3], 3))
        
        # ã‚½ãƒ¼ãƒˆï¼šé »åº¦é™é †ã€åŒå€¤ãªã‚‰æ›´æ–°æ™‚åˆ»é™é †
        candidates.sort(key=lambda x: (-x[1], -x[2]))
        
        # ãƒªã‚»ãƒƒãƒˆ
        self.CN1 = self.CN2 = self.CN3 = -1
        self.P1 = self.P2 = self.P3 = 0
        
        # ã‚½ãƒ¼ãƒˆçµæœã‚’åæ˜ 
        for i, (chunk_id, freq, update_time, original_pos) in enumerate(candidates):
            if i == 0:
                self.CN1, self.P1 = chunk_id, freq
                self._last_update_time[1] = update_time
            elif i == 1:
                self.CN2, self.P2 = chunk_id, freq
                self._last_update_time[2] = update_time
            elif i == 2:
                self.CN3, self.P3 = chunk_id, freq
                self._last_update_time[3] = update_time
    
    def predict_next_chunk(self) -> Optional[int]:
        """
        æ¬¡ã®ãƒãƒ£ãƒ³ã‚¯ã‚’äºˆæ¸¬
        
        Returns:
            Optional[int]: CN1ï¼ˆæœ€é«˜ç¢ºç‡ã®æ¬¡ãƒãƒ£ãƒ³ã‚¯ï¼‰ã€å­˜åœ¨ã—ãªã„å ´åˆNone
            
        è«–æ–‡ã®è¨˜è¿°ï¼š
        "ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒç›®çš„ã§ã¯ã€CluMPã¯å¸¸ã«CN1ã‚’å‚ç…§ã—ã€ãã‚Œã‚’ä½¿ç”¨ã—ã¦æ¬¡ã®I/Oè¦æ±‚ã‚’äºˆæ¸¬ã™ã‚‹"
        """
        return self.CN1 if self.CN1 >= 0 else None
    
    def get_transition_info(self) -> Dict[str, Any]:
        """é·ç§»æƒ…å ±ã‚’å–å¾—"""
        return {
            "CN1": self.CN1, "P1": self.P1,
            "CN2": self.CN2, "P2": self.P2,
            "CN3": self.CN3, "P3": self.P3,
            "total_transitions": self.P1 + self.P2 + self.P3,
            "prediction": self.predict_next_chunk()
        }


class ClusterManager:
    """
    ã‚¯ãƒ©ã‚¹ã‚¿ãƒãƒãƒ¼ã‚¸ãƒ£ï¼ˆè«–æ–‡æº–æ‹ ç‰ˆï¼‰
    
    è«–æ–‡Section 3.2ã®è¨­è¨ˆï¼š
    - ãƒãƒ£ãƒ³ã‚¯ = ãƒ‡ã‚£ã‚¹ã‚¯ãƒ–ãƒ­ãƒƒã‚¯ã®ã‚»ãƒƒãƒˆ
    - ã‚¯ãƒ©ã‚¹ã‚¿ = MCãƒ•ãƒ©ã‚°ãƒ¡ãƒ³ãƒˆã®ã‚»ãƒƒãƒˆ
    - å‹•çš„å‰²ã‚Šå½“ã¦ï¼ˆå¿…è¦æ™‚ã®ã¿ãƒ¡ãƒ¢ãƒªä½¿ç”¨ï¼‰
    - ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ = CL_total Ã— 24B Ã— CL_size
    """
    
    def __init__(self, cluster_size_chunks: int):
        """
        ã‚¯ãƒ©ã‚¹ã‚¿ãƒãƒãƒ¼ã‚¸ãƒ£ã‚’åˆæœŸåŒ–
        
        Args:
            cluster_size_chunks: ã‚¯ãƒ©ã‚¹ã‚¿ã‚µã‚¤ã‚ºï¼ˆãƒãƒ£ãƒ³ã‚¯æ•°ï¼‰
        """
        if cluster_size_chunks <= 0:
            raise ValueError("ã‚¯ãƒ©ã‚¹ã‚¿ã‚µã‚¤ã‚ºã¯æ­£ã®å€¤ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™")
            
        self.cluster_size = cluster_size_chunks
        
        # å‹•çš„MCå‰²ã‚Šå½“ã¦ç®¡ç†
        # key=cluster_id, value=Dict[chunk_id_in_cluster, MCRow]
        self.clusters: Dict[int, Dict[int, MCRow]] = {}
        
        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡è¿½è·¡
        self.allocated_mc_rows = 0
        
        logging.debug(f"ClusterManageråˆæœŸåŒ–: CL_size={cluster_size_chunks}")
    
    def get_mc_row(self, chunk_id: int, allocate: bool = False) -> Optional[MCRow]:
        """
        MCRowã‚’å–å¾—ï¼ˆå¿…è¦ã«å¿œã˜ã¦å‹•çš„å‰²ã‚Šå½“ã¦ï¼‰
        
        Args:
            chunk_id: ãƒãƒ£ãƒ³ã‚¯ID
            allocate: å­˜åœ¨ã—ãªã„å ´åˆã«æ–°è¦å‰²ã‚Šå½“ã¦ã™ã‚‹ã‹
            
        Returns:
            Optional[MCRow]: MCRowã€å­˜åœ¨ã—ãªã„å ´åˆNone
        """
        cluster_id = chunk_id // self.cluster_size
        chunk_in_cluster = chunk_id % self.cluster_size
        
        # ã‚¯ãƒ©ã‚¹ã‚¿ãŒå­˜åœ¨ã—ãªã„å ´åˆ
        if cluster_id not in self.clusters:
            if not allocate:
                return None
            # æ–°ã‚¯ãƒ©ã‚¹ã‚¿ã‚’å‹•çš„å‰²ã‚Šå½“ã¦
            self.clusters[cluster_id] = {}
            logging.debug(f"æ–°ã‚¯ãƒ©ã‚¹ã‚¿å‰²ã‚Šå½“ã¦: cluster_id={cluster_id}")
        
        # MCRowãŒå­˜åœ¨ã—ãªã„å ´åˆ
        if chunk_in_cluster not in self.clusters[cluster_id]:
            if not allocate:
                return None
            # æ–°MCRowã‚’å‹•çš„å‰²ã‚Šå½“ã¦
            self.clusters[cluster_id][chunk_in_cluster] = MCRow()
            self.allocated_mc_rows += 1
            logging.debug(f"æ–°MCRowå‰²ã‚Šå½“ã¦: chunk_id={chunk_id}, "
                         f"total_mc_rows={self.allocated_mc_rows}")
        
        return self.clusters[cluster_id][chunk_in_cluster]
    
    def get_memory_usage(self) -> int:
        """
        MCã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’å–å¾—ï¼ˆè«–æ–‡ã®è¨ˆç®—å¼ã«åŸºã¥ãï¼‰
        
        Returns:
            int: ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ï¼ˆãƒã‚¤ãƒˆï¼‰
            
        è«–æ–‡ã®è¨ˆç®—å¼ï¼š
        Mem_required = CL_total Ã— 24B Ã— CL_size
        ãŸã ã—å®Ÿéš›ã®ä½¿ç”¨é‡ã¯å‹•çš„å‰²ã‚Šå½“ã¦ã«ã‚ˆã‚Šå¤§å¹…ã«å‰Šæ¸›
        """
        # 24B = 6ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ Ã— 4B (CN1-CN3, P1-P3)
        bytes_per_mc_row = 24
        return self.allocated_mc_rows * bytes_per_mc_row
    
    def get_cluster_info(self) -> Dict[str, Any]:
        """ã‚¯ãƒ©ã‚¹ã‚¿æƒ…å ±ã‚’å–å¾—"""
        total_possible_clusters = len(self.clusters) * self.cluster_size if self.clusters else 0
        
        return {
            "cluster_size": self.cluster_size,
            "allocated_clusters": len(self.clusters),
            "allocated_mc_rows": self.allocated_mc_rows,
            "memory_usage_bytes": self.get_memory_usage(),
            "memory_usage_kb": self.get_memory_usage() / 1024,
            "efficiency": (self.allocated_mc_rows / max(total_possible_clusters, 1)) if total_possible_clusters > 0 else 0
        }


class CluMPSimulator:
    """
    CluMP ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ãƒ¡ã‚¤ãƒ³ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ï¼ˆè«–æ–‡æº–æ‹ ç‰ˆï¼‰
    
    è«–æ–‡Section 3.3ã®8ã‚¹ãƒ†ãƒƒãƒ—ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’å®Œå…¨å®Ÿè£…ï¼š
    1. ãƒ‡ã‚£ã‚¹ã‚¯I/Oèª­ã¿å–ã‚Šæ“ä½œãŒè¦æ±‚ã•ã‚Œã‚‹
    2. è¦æ±‚ã•ã‚ŒãŸãƒ‡ã‚£ã‚¹ã‚¯ãƒ–ãƒ­ãƒƒã‚¯ãŒãƒ¡ãƒ¢ãƒªã«å­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    3. è¦æ±‚ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãŒãƒ¡ãƒ¢ãƒªã«å­˜åœ¨ã—ãªã„å ´åˆã€ãƒ‡ã‚£ã‚¹ã‚¯ã‹ã‚‰ã®èª­ã¿å–ã‚Šã‚’è¦æ±‚
    4. ãƒ‡ã‚£ã‚¹ã‚¯ã‹ã‚‰å¯¾å¿œã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€ãƒ¡ãƒ¢ãƒªã«èª­ã¿è¾¼ã‚€
    5. ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹æ—¢å­˜ã®ãƒãƒ«ã‚³ãƒ•é€£é–ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    6. äºˆæ¸¬ã•ã‚ŒãŸãƒãƒ«ã‚³ãƒ•é€£é–ãŒå­˜åœ¨ã™ã‚‹å ´åˆã€å¯¾å¿œã™ã‚‹ãƒãƒ£ãƒ³ã‚¯ç•ªå·ã®æƒ…å ±ã‚’æ›´æ–°
    7. æ›´æ–°ã•ã‚ŒãŸãƒãƒ«ã‚³ãƒ•é€£é–ã®äºˆæ¸¬ã‚’ä½¿ç”¨ã—ã¦ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒã‚’å®Ÿè¡Œ
    8. ãƒãƒ«ã‚³ãƒ•é€£é–ãŒå­˜åœ¨ã—ãªã„å ´åˆã€åˆ©ç”¨å¯èƒ½ãªæƒ…å ±ã‚’ä½¿ç”¨ã—ã¦æ–°ã—ã„ã‚‚ã®ã‚’ä½œæˆ
    """
    
    def __init__(self, chunk_size_blocks: int, cluster_size_chunks: int, 
                 cache_size_blocks: int, prefetch_window_blocks: int):
        """
        CluMPã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ã‚’åˆæœŸåŒ–
        
        Args:
            chunk_size_blocks: ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºï¼ˆãƒ–ãƒ­ãƒƒã‚¯æ•°ï¼‰
            cluster_size_chunks: ã‚¯ãƒ©ã‚¹ã‚¿ã‚µã‚¤ã‚ºï¼ˆãƒãƒ£ãƒ³ã‚¯æ•°ï¼‰
            cache_size_blocks: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºï¼ˆãƒ–ãƒ­ãƒƒã‚¯æ•°ï¼‰
            prefetch_window_blocks: ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒçª“ã‚µã‚¤ã‚ºï¼ˆãƒ–ãƒ­ãƒƒã‚¯æ•°ï¼‰
        """
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¤œè¨¼
        if any(x <= 0 for x in [chunk_size_blocks, cluster_size_chunks, 
                                cache_size_blocks, prefetch_window_blocks]):
            raise ValueError("ã™ã¹ã¦ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯æ­£ã®å€¤ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™")
        
        # åŸºæœ¬ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.chunk_size = chunk_size_blocks
        self.cluster_size = cluster_size_chunks
        self.cache_size = cache_size_blocks
        self.prefetch_window = prefetch_window_blocks
        
        # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–
        self.cache = LRUCache(cache_size_blocks)
        self.cluster_manager = ClusterManager(cluster_size_chunks)
        
        # çµ±è¨ˆã‚«ã‚¦ãƒ³ã‚¿
        self.total_accesses = 0
        self.cache_hits = 0
        self.previous_chunk_id: Optional[int] = None
        
        logging.info(f"CluMPã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿åˆæœŸåŒ–: chunk={chunk_size_blocks}, "
                    f"cluster={cluster_size_chunks}, cache={cache_size_blocks}, "
                    f"prefetch_window={prefetch_window_blocks}")
    
    def _get_chunk_id(self, block_id: int) -> int:
        """ãƒ–ãƒ­ãƒƒã‚¯IDã‹ã‚‰ãƒãƒ£ãƒ³ã‚¯IDã‚’è¨ˆç®—"""
        return block_id // self.chunk_size
    
    def _prefetch_chunk(self, chunk_id: int) -> None:
        """
        ãƒãƒ£ãƒ³ã‚¯ã‚’ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒï¼ˆè«–æ–‡æº–æ‹ ï¼‰
        
        Args:
            chunk_id: ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒå¯¾è±¡ã®ãƒãƒ£ãƒ³ã‚¯ID
        """
        start_block = chunk_id * self.chunk_size
        
        # ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒçª“ã‚µã‚¤ã‚ºåˆ†ã®ãƒ–ãƒ­ãƒƒã‚¯ã‚’ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒ
        for i in range(self.prefetch_window):
            prefetch_block = start_block + i
            if not self.cache.access(prefetch_block):
                # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹ã®å ´åˆã€ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒã¨ã—ã¦æŒ¿å…¥
                self.cache.insert(prefetch_block, is_prefetch=True)
                logging.debug(f"ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒ: block={prefetch_block}")
    
    def process_access(self, block_id: int) -> bool:
        """
        ãƒ–ãƒ­ãƒƒã‚¯ã‚¢ã‚¯ã‚»ã‚¹å‡¦ç†ï¼ˆè«–æ–‡Section 3.3ã®8ã‚¹ãƒ†ãƒƒãƒ—ï¼‰
        
        Args:
            block_id: ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ãƒ–ãƒ­ãƒƒã‚¯ID
            
        Returns:
            bool: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆã—ãŸå ´åˆTrue
        """
        self.total_accesses += 1
        current_chunk_id = self._get_chunk_id(block_id)
        
        # Step 1: ãƒ‡ã‚£ã‚¹ã‚¯I/Oèª­ã¿å–ã‚Šæ“ä½œãŒè¦æ±‚ã•ã‚Œã‚‹
        logging.debug(f"Step 1: I/Oè¦æ±‚ block={block_id}, chunk={current_chunk_id}")
        
        # Step 2: è¦æ±‚ã•ã‚ŒãŸãƒ‡ã‚£ã‚¹ã‚¯ãƒ–ãƒ­ãƒƒã‚¯ãŒãƒ¡ãƒ¢ãƒªã«å­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        cache_hit = self.cache.access(block_id)
        logging.debug(f"Step 2: ãƒ¡ãƒ¢ãƒªå­˜åœ¨ç¢ºèª hit={cache_hit}")
        
        if cache_hit:
            self.cache_hits += 1
            # ãƒ’ãƒƒãƒˆã®å ´åˆã‚‚MCæ›´æ–°ã¯å®Ÿè¡Œ
            if self.previous_chunk_id is not None:
                self._update_markov_chain(current_chunk_id)
        else:
            # Step 3: ãƒ‡ã‚£ã‚¹ã‚¯ã‹ã‚‰ã®èª­ã¿å–ã‚Šã‚’è¦æ±‚
            # Step 4: ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ»ãƒ¡ãƒ¢ãƒªèª­ã¿è¾¼ã¿
            logging.debug(f"Step 3-4: ãƒ‡ã‚£ã‚¹ã‚¯èª­ã¿å–ã‚Šãƒ»ãƒ¡ãƒ¢ãƒªèª­ã¿è¾¼ã¿")
            self.cache.insert(block_id, is_prefetch=False)
            
            # Step 5: æ—¢å­˜ã®ãƒãƒ«ã‚³ãƒ•é€£é–ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            # Step 6: MCæƒ…å ±æ›´æ–°
            if self.previous_chunk_id is not None:
                self._update_markov_chain(current_chunk_id)
            
            # Step 7: CN1ãƒ™ãƒ¼ã‚¹ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒå®Ÿè¡Œ
            self._execute_prediction_and_prefetch(current_chunk_id)
            
            # Step 8: æ–°MCã®ä½œæˆï¼ˆupdate_markov_chainã§è‡ªå‹•å‡¦ç†ï¼‰
        
        # æ¬¡å›ã®ãŸã‚ã«ç¾åœ¨ãƒãƒ£ãƒ³ã‚¯ã‚’ä¿å­˜
        self.previous_chunk_id = current_chunk_id
        return cache_hit
    
    def _update_markov_chain(self, current_chunk_id: int) -> None:
        """
        ãƒãƒ«ã‚³ãƒ•é€£é–ã‚’æ›´æ–°ï¼ˆStep 6-8ï¼‰
        
        Args:
            current_chunk_id: ç¾åœ¨ã®ãƒãƒ£ãƒ³ã‚¯ID
        """
        if self.previous_chunk_id is None:
            return
        
        # å‰ãƒãƒ£ãƒ³ã‚¯ã®MCRowã‚’å–å¾—ï¼ˆå¿…è¦ã«å¿œã˜ã¦æ–°è¦ä½œæˆï¼‰
        mc_row = self.cluster_manager.get_mc_row(self.previous_chunk_id, allocate=True)
        
        # é·ç§»ã‚’æ›´æ–°
        mc_row.update_transition(current_chunk_id)
        
        logging.debug(f"MCæ›´æ–°: {self.previous_chunk_id} -> {current_chunk_id}")
    
    def _execute_prediction_and_prefetch(self, current_chunk_id: int) -> None:
        """
        äºˆæ¸¬ã¨ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒã‚’å®Ÿè¡Œï¼ˆStep 7ï¼‰
        
        Args:
            current_chunk_id: ç¾åœ¨ã®ãƒãƒ£ãƒ³ã‚¯ID
        """
        # ç¾åœ¨ãƒãƒ£ãƒ³ã‚¯ã®MCRowã‹ã‚‰äºˆæ¸¬
        mc_row = self.cluster_manager.get_mc_row(current_chunk_id, allocate=False)
        
        if mc_row is not None:
            predicted_chunk = mc_row.predict_next_chunk()
            if predicted_chunk is not None:
                logging.debug(f"äºˆæ¸¬ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒ: chunk={predicted_chunk}")
                self._prefetch_chunk(predicted_chunk)
    
    def get_evaluation_metrics(self) -> Dict[str, Any]:
        """
        è©•ä¾¡æŒ‡æ¨™ã‚’å–å¾—ï¼ˆè«–æ–‡Section 4æº–æ‹ ï¼‰
        
        Returns:
            Dict[str, Any]: è©•ä¾¡æŒ‡æ¨™è¾æ›¸
        """
        prefetch_stats = self.cache.get_prefetch_stats()
        cluster_info = self.cluster_manager.get_cluster_info()
        cache_info = self.cache.get_cache_info()
        
        # ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒåŠ¹ç‡è¨ˆç®—
        prefetch_efficiency = 0.0
        if prefetch_stats["prefetch_total"] > 0:
            prefetch_efficiency = prefetch_stats["prefetch_used"] / prefetch_stats["prefetch_total"]
        
        # ãƒ’ãƒƒãƒˆç‡è¨ˆç®—
        hit_rate = 0.0
        if self.total_accesses > 0:
            hit_rate = self.cache_hits / self.total_accesses
        
        return {
            # åŸºæœ¬çµ±è¨ˆ
            "total_accesses": self.total_accesses,
            "cache_hits": self.cache_hits,
            "hit_rate": hit_rate,
            
            # ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒçµ±è¨ˆï¼ˆè«–æ–‡Section 4.3æº–æ‹ ï¼‰
            "prefetch_total": prefetch_stats["prefetch_total"],
            "prefetch_used": prefetch_stats["prefetch_used"],
            "prefetch_unused": prefetch_stats["prefetch_unused"],
            "prefetch_efficiency": prefetch_efficiency,
            
            # ãƒ¡ãƒ¢ãƒªã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ï¼ˆè«–æ–‡Section 4.4æº–æ‹ ï¼‰
            "memory_usage_mc_rows": cluster_info["allocated_mc_rows"],
            "memory_usage_bytes": cluster_info["memory_usage_bytes"],
            "memory_usage_kb": cluster_info["memory_usage_kb"],
            
            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
            "chunk_size": self.chunk_size,
            "cluster_size": self.cluster_size,
            "cache_size": self.cache_size,
            "prefetch_window": self.prefetch_window,
            
            # è©³ç´°æƒ…å ±
            "cache_info": cache_info,
            "cluster_info": cluster_info
        }


class LinuxReadAhead:
    """
    Linuxå…ˆèª­ã¿ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼ˆè«–æ–‡æº–æ‹ ç‰ˆï¼‰
    
    è«–æ–‡Section 2.1ã¨Section 4ã®æ¯”è¼ƒæ¡ä»¶ã«åŸºã¥ãå®Ÿè£…ï¼š
    - é€æ¬¡ã‚¢ã‚¯ã‚»ã‚¹æ¤œå‡º
    - 128KBåˆæœŸçª“ã‚µã‚¤ã‚º
    - ç¶™ç¶šçš„é€æ¬¡ã‚¢ã‚¯ã‚»ã‚¹æ™‚ã®çª“å€å¢—
    - éé€æ¬¡ã‚¢ã‚¯ã‚»ã‚¹æ™‚ã®çª“ãƒªã‚»ãƒƒãƒˆ
    """
    
    def __init__(self, cache_size_blocks: int, initial_window_kb: int = 128):
        """
        Linuxå…ˆèª­ã¿ã‚’åˆæœŸåŒ–
        
        Args:
            cache_size_blocks: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºï¼ˆãƒ–ãƒ­ãƒƒã‚¯æ•°ï¼‰
            initial_window_kb: åˆæœŸå…ˆèª­ã¿çª“ã‚µã‚¤ã‚ºï¼ˆKBï¼‰
        """
        self.cache = LRUCache(cache_size_blocks)
        self.cache_size = cache_size_blocks
        
        # å…ˆèª­ã¿ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆè«–æ–‡æº–æ‹ ï¼‰
        self.initial_window_kb = initial_window_kb
        self.current_window_kb = initial_window_kb
        self.max_window_kb = 2048  # æœ€å¤§çª“ã‚µã‚¤ã‚º
        
        # é€æ¬¡ã‚¢ã‚¯ã‚»ã‚¹æ¤œå‡º
        self.last_block_id: Optional[int] = None
        self.consecutive_sequential = 0
        self.sequential_threshold = 2  # é€æ¬¡åˆ¤å®šé–¾å€¤
        
        # çµ±è¨ˆ
        self.total_accesses = 0
        self.cache_hits = 0
        
        # 4KBãƒ–ãƒ­ãƒƒã‚¯ã‚µã‚¤ã‚ºä»®å®š
        self.block_size_kb = 4
        
        logging.info(f"Linuxå…ˆèª­ã¿åˆæœŸåŒ–: cache={cache_size_blocks}, "
                    f"window={initial_window_kb}KB")
    
    def _is_sequential(self, block_id: int) -> bool:
        """é€æ¬¡ã‚¢ã‚¯ã‚»ã‚¹ã‹ã©ã†ã‹åˆ¤å®š"""
        if self.last_block_id is None:
            return False
        return block_id == self.last_block_id + 1
    
    def _execute_readahead(self, block_id: int) -> None:
        """
        å…ˆèª­ã¿å®Ÿè¡Œï¼ˆè«–æ–‡æº–æ‹ ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼‰
        
        Args:
            block_id: é–‹å§‹ãƒ–ãƒ­ãƒƒã‚¯ID
        """
        # çª“ã‚µã‚¤ã‚ºï¼ˆãƒ–ãƒ­ãƒƒã‚¯æ•°ï¼‰è¨ˆç®—
        window_blocks = self.current_window_kb // self.block_size_kb
        
        # å…ˆèª­ã¿å®Ÿè¡Œ
        for i in range(1, window_blocks + 1):
            readahead_block = block_id + i
            if not self.cache.access(readahead_block):
                self.cache.insert(readahead_block, is_prefetch=True)
                logging.debug(f"å…ˆèª­ã¿: block={readahead_block}")
    
    def process_access(self, block_id: int) -> bool:
        """
        ãƒ–ãƒ­ãƒƒã‚¯ã‚¢ã‚¯ã‚»ã‚¹å‡¦ç†ï¼ˆLinuxå…ˆèª­ã¿ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼‰
        
        Args:
            block_id: ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ãƒ–ãƒ­ãƒƒã‚¯ID
            
        Returns:
            bool: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆã—ãŸå ´åˆTrue
        """
        self.total_accesses += 1
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¢ã‚¯ã‚»ã‚¹
        cache_hit = self.cache.access(block_id)
        if cache_hit:
            self.cache_hits += 1
        else:
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹ï¼šãƒ–ãƒ­ãƒƒã‚¯ã‚’èª­ã¿è¾¼ã¿
            self.cache.insert(block_id, is_prefetch=False)
        
        # é€æ¬¡æ€§ãƒã‚§ãƒƒã‚¯
        is_sequential = self._is_sequential(block_id)
        
        if is_sequential:
            self.consecutive_sequential += 1
            
            # ç¶™ç¶šçš„é€æ¬¡ã‚¢ã‚¯ã‚»ã‚¹ï¼šçª“å€å¢—
            if self.consecutive_sequential >= self.sequential_threshold:
                self.current_window_kb = min(self.current_window_kb * 2, 
                                           self.max_window_kb)
                logging.debug(f"çª“å€å¢—: {self.current_window_kb}KB")
            
            # å…ˆèª­ã¿å®Ÿè¡Œ
            self._execute_readahead(block_id)
            
        else:
            # éé€æ¬¡ã‚¢ã‚¯ã‚»ã‚¹ï¼šçª“ãƒªã‚»ãƒƒãƒˆ
            self.consecutive_sequential = 0
            self.current_window_kb = self.initial_window_kb
            # å…ˆèª­ã¿ã¯å®Ÿè¡Œã—ãªã„
        
        self.last_block_id = block_id
        return cache_hit
    
    def get_evaluation_metrics(self) -> Dict[str, Any]:
        """è©•ä¾¡æŒ‡æ¨™ã‚’å–å¾—"""
        prefetch_stats = self.cache.get_prefetch_stats()
        
        # ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒåŠ¹ç‡è¨ˆç®—
        prefetch_efficiency = 0.0
        if prefetch_stats["prefetch_total"] > 0:
            prefetch_efficiency = prefetch_stats["prefetch_used"] / prefetch_stats["prefetch_total"]
        
        # ãƒ’ãƒƒãƒˆç‡è¨ˆç®—
        hit_rate = 0.0
        if self.total_accesses > 0:
            hit_rate = self.cache_hits / self.total_accesses
        
        return {
            # åŸºæœ¬çµ±è¨ˆ
            "total_accesses": self.total_accesses,
            "cache_hits": self.cache_hits,
            "hit_rate": hit_rate,
            
            # ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒçµ±è¨ˆ
            "prefetch_total": prefetch_stats["prefetch_total"],
            "prefetch_used": prefetch_stats["prefetch_used"],
            "prefetch_unused": prefetch_stats["prefetch_unused"],
            "prefetch_efficiency": prefetch_efficiency,
            
            # å…ˆèª­ã¿å›ºæœ‰æƒ…å ±
            "current_window_kb": self.current_window_kb,
            "consecutive_sequential": self.consecutive_sequential,
            "algorithm": "Linux ReadAhead"
        }


class WorkloadGenerator:
    """
    ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ç”Ÿæˆå™¨ï¼ˆè«–æ–‡Section 4.1æº–æ‹ ï¼‰
    
    KVMèµ·å‹•ã¨Linuxã‚«ãƒ¼ãƒãƒ«ãƒ“ãƒ«ãƒ‰ã«ç›¸å½“ã™ã‚‹åˆæˆãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã‚’ç”Ÿæˆ
    """
    
    @staticmethod
    def generate_kvm_workload(total_blocks: int = 10000, 
                             block_range: int = 50000) -> List[int]:
        """
        KVMèµ·å‹•ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ç”Ÿæˆï¼ˆ42.53MBç›¸å½“ï¼‰
        
        Args:
            total_blocks: ç·ã‚¢ã‚¯ã‚»ã‚¹æ•°
            block_range: ãƒ–ãƒ­ãƒƒã‚¯ç¯„å›²
            
        Returns:
            List[int]: ãƒ–ãƒ­ãƒƒã‚¯ã‚¢ã‚¯ã‚»ã‚¹ã‚·ãƒ¼ã‚±ãƒ³ã‚¹
        """
        trace = []
        
        # KVMèµ·å‹•ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼š
        # 40% é€æ¬¡ã‚¢ã‚¯ã‚»ã‚¹ï¼ˆèµ·å‹•ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ï¼‰
        # 35% ãƒ©ãƒ³ãƒ€ãƒ ã‚¢ã‚¯ã‚»ã‚¹ï¼ˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
        # 25% å°è¦æ¨¡ã‚¸ãƒ£ãƒ³ãƒ—ï¼ˆãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒ­ãƒ¼ãƒ‰ï¼‰
        
        current_block = random.randint(0, block_range // 10)
        
        for _ in range(total_blocks):
            access_type = random.random()
            
            if access_type < 0.4:
                # é€æ¬¡ã‚¢ã‚¯ã‚»ã‚¹
                trace.append(current_block)
                current_block += 1
            elif access_type < 0.75:
                # ãƒ©ãƒ³ãƒ€ãƒ ã‚¢ã‚¯ã‚»ã‚¹
                current_block = random.randint(0, block_range)
                trace.append(current_block)
            else:
                # å°è¦æ¨¡ã‚¸ãƒ£ãƒ³ãƒ—
                jump = random.randint(10, 100)
                current_block += jump
                trace.append(current_block % block_range)
        
        return trace
    
    @staticmethod
    def generate_kernel_build_workload(total_blocks: int = 50000,
                                     block_range: int = 200000) -> List[int]:
        """
        Linuxã‚«ãƒ¼ãƒãƒ«ãƒ“ãƒ«ãƒ‰ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ç”Ÿæˆï¼ˆ7.96GBç›¸å½“ï¼‰
        
        Args:
            total_blocks: ç·ã‚¢ã‚¯ã‚»ã‚¹æ•°
            block_range: ãƒ–ãƒ­ãƒƒã‚¯ç¯„å›²
            
        Returns:
            List[int]: ãƒ–ãƒ­ãƒƒã‚¯ã‚¢ã‚¯ã‚»ã‚¹ã‚·ãƒ¼ã‚±ãƒ³ã‚¹
        """
        trace = []
        
        # ã‚«ãƒ¼ãƒãƒ«ãƒ“ãƒ«ãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼š
        # 30% é€æ¬¡ã‚¢ã‚¯ã‚»ã‚¹ï¼ˆã‚½ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ï¼‰
        # 50% ãƒ©ãƒ³ãƒ€ãƒ ã‚¢ã‚¯ã‚»ã‚¹ï¼ˆãƒ˜ãƒƒãƒ€ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
        # 20% å¤§è¦æ¨¡ã‚¸ãƒ£ãƒ³ãƒ—ï¼ˆä¸¦åˆ—ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ï¼‰
        
        current_block = random.randint(0, block_range // 10)
        
        for _ in range(total_blocks):
            access_type = random.random()
            
            if access_type < 0.3:
                # é€æ¬¡ã‚¢ã‚¯ã‚»ã‚¹ï¼ˆã‚½ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
                trace.append(current_block)
                current_block += 1
            elif access_type < 0.8:
                # ãƒ©ãƒ³ãƒ€ãƒ ã‚¢ã‚¯ã‚»ã‚¹ï¼ˆãƒ˜ãƒƒãƒ€ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
                current_block = random.randint(0, block_range)
                trace.append(current_block)
            else:
                # å¤§è¦æ¨¡ã‚¸ãƒ£ãƒ³ãƒ—ï¼ˆä¸¦åˆ—ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ï¼‰
                jump = random.randint(1000, 10000)
                current_block += jump
                trace.append(current_block % block_range)
        
        return trace


def compare_clump_vs_readahead(trace: List[int],
                              clump_params: Dict[str, int],
                              cache_size: int = 4096) -> Dict[str, Any]:
    """
    CluMPã¨Linuxå…ˆèª­ã¿ã®æ¯”è¼ƒå®Ÿé¨“ï¼ˆè«–æ–‡æº–æ‹ ï¼‰
    
    Args:
        trace: ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¹
        clump_params: CluMPãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        cache_size: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚º
        
    Returns:
        Dict[str, Any]: æ¯”è¼ƒçµæœ
    """
    # CluMPå®Ÿè¡Œ
    clump = CluMPSimulator(
        chunk_size_blocks=clump_params["chunk_size"],
        cluster_size_chunks=clump_params["cluster_size"],
        cache_size_blocks=cache_size,
        prefetch_window_blocks=clump_params["prefetch_window"]
    )
    
    for block_id in trace:
        clump.process_access(block_id)
    
    clump_results = clump.get_evaluation_metrics()
    
    # Linuxå…ˆèª­ã¿å®Ÿè¡Œ
    readahead = LinuxReadAhead(cache_size_blocks=cache_size)
    
    for block_id in trace:
        readahead.process_access(block_id)
    
    readahead_results = readahead.get_evaluation_metrics()
    
    # æ¯”è¼ƒçµæœ
    improvement = {
        "hit_rate_improvement": clump_results["hit_rate"] / readahead_results["hit_rate"] if readahead_results["hit_rate"] > 0 else float('inf'),
        "hit_rate_difference": clump_results["hit_rate"] - readahead_results["hit_rate"],
        "prefetch_efficiency_improvement": clump_results["prefetch_efficiency"] / readahead_results["prefetch_efficiency"] if readahead_results["prefetch_efficiency"] > 0 else float('inf')
    }
    
    return {
        "clump": clump_results,
        "readahead": readahead_results,
        "improvement": improvement
    }


if __name__ == "__main__":
    # ä¹±æ•°ã‚·ãƒ¼ãƒ‰å›ºå®šï¼ˆå†ç¾æ€§ç¢ºä¿ï¼‰
    random.seed(42)
    
    print("CluMPè«–æ–‡æº–æ‹ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿")
    print("=" * 60)
    
    # è«–æ–‡æº–æ‹ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    clump_params = {
        "chunk_size": 16,      # è«–æ–‡ã§åŠ¹æœçš„ã¨ã•ã‚ŒãŸå€¤
        "cluster_size": 64,    # è«–æ–‡ã§åŠ¹æœçš„ã¨ã•ã‚ŒãŸå€¤
        "prefetch_window": 16
    }
    
    # KVMãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆ
    print("\nğŸš€ KVMãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆ")
    print("-" * 40)
    
    kvm_trace = WorkloadGenerator.generate_kvm_workload(total_blocks=10000)
    kvm_results = compare_clump_vs_readahead(kvm_trace, clump_params)
    
    print(f"Linuxå…ˆèª­ã¿ ãƒ’ãƒƒãƒˆç‡: {kvm_results['readahead']['hit_rate']:.3f}")
    print(f"CluMP ãƒ’ãƒƒãƒˆç‡: {kvm_results['clump']['hit_rate']:.3f}")
    print(f"æ”¹å–„å€ç‡: {kvm_results['improvement']['hit_rate_improvement']:.2f}x")
    print(f"CluMP MCè¡Œæ•°: {kvm_results['clump']['memory_usage_mc_rows']}")
    
    # ã‚«ãƒ¼ãƒãƒ«ãƒ“ãƒ«ãƒ‰ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆ
    print("\nğŸ”¨ ã‚«ãƒ¼ãƒãƒ«ãƒ“ãƒ«ãƒ‰ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆ")
    print("-" * 40)
    
    kernel_trace = WorkloadGenerator.generate_kernel_build_workload(total_blocks=20000)
    kernel_results = compare_clump_vs_readahead(kernel_trace, clump_params)
    
    print(f"Linuxå…ˆèª­ã¿ ãƒ’ãƒƒãƒˆç‡: {kernel_results['readahead']['hit_rate']:.3f}")
    print(f"CluMP ãƒ’ãƒƒãƒˆç‡: {kernel_results['clump']['hit_rate']:.3f}")
    print(f"æ”¹å–„å€ç‡: {kernel_results['improvement']['hit_rate_improvement']:.2f}x")
    print(f"CluMP MCè¡Œæ•°: {kernel_results['clump']['memory_usage_mc_rows']}")
    
    print("\nâœ… è«–æ–‡æº–æ‹ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº†")
    print("ç›®æ¨™å€¤: KVM 1.91xæ”¹å–„, ã‚«ãƒ¼ãƒãƒ«ãƒ“ãƒ«ãƒ‰ 1.31xæ”¹å–„")