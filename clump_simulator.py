#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CluMP (CLUstered Markov-chain Prefetching) Simulator
è¦ä»¶å®šç¾©æ›¸ã«åŸºã¥ãæŠœæœ¬çš„æ”¹è‰¯ç‰ˆ

ç›®çš„:
- CluMPã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã«ã‚ˆã‚Šå†ç¾
- Linux read-aheadã‚„å˜ç´”ãªãƒ—ãƒªãƒ•ã‚§ãƒƒãƒæ–¹å¼ã¨æ¯”è¼ƒå¯èƒ½
- è«–æ–‡ã®æ€§èƒ½è©•ä¾¡æŒ‡æ¨™ï¼ˆãƒ’ãƒƒãƒˆç‡ã€ç„¡é§„ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒç‡ã€ãƒ¡ãƒ¢ãƒªæ¶ˆè²»é‡ãªã©ï¼‰ã‚’å†ç¾

ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£:
1. LRUCache: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†ã¨ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒçµ±è¨ˆè¿½è·¡
2. MCRow: ãƒãƒ«ã‚³ãƒ•é€£é–ã®çŠ¶æ…‹é·ç§»è¨˜éŒ²ï¼ˆCN1-CN3, P1-P3ï¼‰
3. ClusterManager: MCRowã®ã‚ªãƒ³ãƒ‡ãƒãƒ³ãƒ‰å‰²ã‚Šå½“ã¦ç®¡ç†
4. CluMPSimulator: ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®å®Ÿè£…
5. TraceGenerator: åˆæˆãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ç”Ÿæˆ

ä½œæˆè€…: GitHub Copilot & User
æ›´æ–°æ—¥: 2025å¹´9æœˆ13æ—¥
"""

from collections import OrderedDict
import random
import time
import statistics
import logging
from typing import List, Dict, Tuple, Optional, Any, Union

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')


class LRUCache:
    """
    LRU (Least Recently Used) ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®å®Ÿè£…
    
    CluMPã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«ãŠã‘ã‚‹ä¸­æ ¸çš„ãªã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†ã‚¯ãƒ©ã‚¹ã€‚
    è¦ä»¶å®šç¾©æ›¸ã«åŸºã¥ãã€ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒçµ±è¨ˆã‚‚ç®¡ç†ã™ã‚‹ã€‚
    
    æ©Ÿèƒ½:
    - ãƒ–ãƒ­ãƒƒã‚¯ãƒ¬ãƒ™ãƒ«ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†
    - LRU (Least Recently Used) ã‚¨ãƒ“ã‚¯ã‚·ãƒ§ãƒ³æ–¹å¼
    - ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒãƒ–ãƒ­ãƒƒã‚¯ã®çµ±è¨ˆè¿½è·¡
    - ãƒ’ãƒƒãƒˆ/ãƒŸã‚¹ç‡ã®æ­£ç¢ºãªè¨ˆç®—
    
    çµ±è¨ˆè¿½è·¡:
    - prefetch_total: ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒã•ã‚ŒãŸãƒ–ãƒ­ãƒƒã‚¯ç·æ•°
    - prefetch_used: å®Ÿéš›ã«ã‚¢ã‚¯ã‚»ã‚¹ã•ã‚ŒãŸãƒ—ãƒªãƒ•ã‚§ãƒƒãƒãƒ–ãƒ­ãƒƒã‚¯æ•°
    - prefetch_unused_evicted: æœªä½¿ç”¨ã®ã¾ã¾è¿½ã„å‡ºã•ã‚ŒãŸãƒ—ãƒªãƒ•ã‚§ãƒƒãƒãƒ–ãƒ­ãƒƒã‚¯æ•°
    """
    
    def __init__(self, cache_size_blocks: int):
        """
        LRUã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’åˆæœŸåŒ–
        
        Args:
            cache_size_blocks: ã‚­ãƒ£ãƒƒã‚·ãƒ¥å®¹é‡ï¼ˆãƒ–ãƒ­ãƒƒã‚¯æ•°ï¼‰
            
        Raises:
            ValueError: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºãŒç„¡åŠ¹ãªå ´åˆ
        """
        if cache_size_blocks <= 0:
            raise ValueError(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºã¯æ­£ã®å€¤ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™: {cache_size_blocks}")
            
        self.cache_size = cache_size_blocks
        # key=block_id, val=(is_prefetched, was_used_after_prefetch)
        # OrderedDictã‚’ä½¿ç”¨ã—ã¦LRUé †åºã‚’åŠ¹ç‡çš„ã«ç®¡ç†
        self.cache: OrderedDict[int, Tuple[bool, bool]] = OrderedDict()
        
        # ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒçµ±è¨ˆï¼ˆè¦ä»¶å®šç¾©æ›¸æº–æ‹ ï¼‰
        self.prefetch_stats = {
            "prefetch_total": 0,           # ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒã•ã‚ŒãŸãƒ–ãƒ­ãƒƒã‚¯æ•°
            "prefetch_used": 0,            # å®Ÿéš›ã‚¢ã‚¯ã‚»ã‚¹ã•ã‚Œãƒ’ãƒƒãƒˆã«è²¢çŒ®ã—ãŸãƒ—ãƒªãƒ•ã‚§ãƒƒãƒæ•°
            "prefetch_unused_evicted": 0   # ä½¿ã‚ã‚Œãšã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰è¿½ã„å‡ºã•ã‚ŒãŸãƒ—ãƒªãƒ•ã‚§ãƒƒãƒæ•°
        }
        
        logging.debug(f"LRUCacheåˆæœŸåŒ–: ã‚µã‚¤ã‚º={cache_size_blocks}ãƒ–ãƒ­ãƒƒã‚¯")
    
    def access(self, block_id: int) -> bool:
        """
        ãƒ–ãƒ­ãƒƒã‚¯ã‚¢ã‚¯ã‚»ã‚¹å‡¦ç†
        
        æŒ‡å®šã•ã‚ŒãŸãƒ–ãƒ­ãƒƒã‚¯ãŒã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«å­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ã—ã€
        å­˜åœ¨ã™ã‚‹å ´åˆã¯LRUé †åºã‚’æ›´æ–°ã—ã¦ãƒ’ãƒƒãƒˆã‚’è¿”ã™ã€‚
        
        Args:
            block_id: ã‚¢ã‚¯ã‚»ã‚¹å¯¾è±¡ã®ãƒ–ãƒ­ãƒƒã‚¯ID
            
        Returns:
            bool: ãƒ’ãƒƒãƒˆã—ãŸå ´åˆTrueã€ãƒŸã‚¹ã—ãŸå ´åˆFalse
            
        Note:
            ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒã•ã‚ŒãŸãƒ–ãƒ­ãƒƒã‚¯ãŒåˆå›ã‚¢ã‚¯ã‚»ã‚¹ã•ã‚ŒãŸå ´åˆã€
            prefetch_usedçµ±è¨ˆã‚’æ›´æ–°ã™ã‚‹ã€‚
        """
        if block_id in self.cache:
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆ: LRUé †åºã‚’æ›´æ–°ï¼ˆæœ€æ–°ã«ã™ã‚‹ï¼‰
            is_prefetched, was_used = self.cache.pop(block_id)
            
            # ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒã•ã‚ŒãŸãƒ–ãƒ­ãƒƒã‚¯ãŒåˆã‚ã¦ä½¿ç”¨ã•ã‚Œã‚‹å ´åˆ
            if is_prefetched and not was_used:
                self.prefetch_stats["prefetch_used"] += 1
                was_used = True
                logging.debug(f"ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒãƒ–ãƒ­ãƒƒã‚¯ {block_id} ãŒåˆå›ä½¿ç”¨ã•ã‚Œã¾ã—ãŸ")
            
            # æœ€æ–°ä½ç½®ã«å†æŒ¿å…¥ï¼ˆLRUæ›´æ–°ï¼‰
            self.cache[block_id] = (is_prefetched, was_used)
            return True
        
        return False  # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹
    
    def insert(self, block_id: int, is_prefetch: bool = False) -> None:
        """
        ãƒ–ãƒ­ãƒƒã‚¯ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«æŒ¿å…¥
        
        æ–°ã—ã„ãƒ–ãƒ­ãƒƒã‚¯ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«è¿½åŠ ã™ã‚‹ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒæº€æ¯ã®å ´åˆã¯
        LRUï¼ˆæœ€ã‚‚å¤ã„ï¼‰ã‚¨ãƒ³ãƒˆãƒªã‚’è¿½ã„å‡ºã—ã¦ã‚¹ãƒšãƒ¼ã‚¹ã‚’ç¢ºä¿ã™ã‚‹ã€‚
        
        Args:
            block_id: æŒ¿å…¥ã™ã‚‹ãƒ–ãƒ­ãƒƒã‚¯ID
            is_prefetch: ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒã«ã‚ˆã‚‹æŒ¿å…¥ã‹ã©ã†ã‹
            
        Note:
            - æ—¢å­˜ãƒ–ãƒ­ãƒƒã‚¯ã®å ´åˆã¯çŠ¶æ…‹ã‚’æ›´æ–°
            - ã‚­ãƒ£ãƒƒã‚·ãƒ¥æº€æ¯æ™‚ã¯LRUã‚¨ãƒ³ãƒˆãƒªã‚’è¿½ã„å‡ºã—
            - æœªä½¿ç”¨ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒã®è¿½ã„å‡ºã—æ™‚ã¯çµ±è¨ˆã‚’æ›´æ–°
        """
        if block_id in self.cache:
            # æ—¢ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«å­˜åœ¨ã™ã‚‹å ´åˆã¯çŠ¶æ…‹ã‚’æ›´æ–°
            existing_prefetch, was_used = self.cache.pop(block_id)
            is_prefetched = existing_prefetch or is_prefetch
            self.cache[block_id] = (is_prefetched, was_used)
            logging.debug(f"æ—¢å­˜ãƒ–ãƒ­ãƒƒã‚¯ {block_id} ã®çŠ¶æ…‹ã‚’æ›´æ–°")
            return
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥å®¹é‡ãƒã‚§ãƒƒã‚¯
        if len(self.cache) >= self.cache_size:
            # LRUï¼ˆæœ€ã‚‚å¤ã„ï¼‰ã‚¨ãƒ³ãƒˆãƒªã‚’è¿½ã„å‡ºã—
            evicted_block, (evicted_prefetch, evicted_used) = self.cache.popitem(last=False)
            
            # æœªä½¿ç”¨ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒã®è¿½ã„å‡ºã—ã‚’è¨˜éŒ²
            if evicted_prefetch and not evicted_used:
                self.prefetch_stats["prefetch_unused_evicted"] += 1
                logging.debug(f"æœªä½¿ç”¨ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒãƒ–ãƒ­ãƒƒã‚¯ {evicted_block} ã‚’è¿½ã„å‡ºã—")
        
        # æ–°ã—ã„ãƒ–ãƒ­ãƒƒã‚¯ã‚’æŒ¿å…¥
        self.cache[block_id] = (is_prefetch, False)
        
        # ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒçµ±è¨ˆã‚’æ›´æ–°
        if is_prefetch:
            self.prefetch_stats["prefetch_total"] += 1
            logging.debug(f"ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒãƒ–ãƒ­ãƒƒã‚¯ {block_id} ã‚’æŒ¿å…¥")
    
    def get_prefetch_stats(self) -> Dict[str, int]:
        """
        ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒçµ±è¨ˆã‚’å–å¾—
        
        Returns:
            Dict[str, int]: ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒé–¢é€£ã®çµ±è¨ˆæƒ…å ±
        """
        return dict(self.prefetch_stats)
    
    def get_cache_info(self) -> Dict[str, Any]:
        """
        ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®è©³ç´°æƒ…å ±ã‚’å–å¾—ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
        
        Returns:
            Dict[str, Any]: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®è©³ç´°æƒ…å ±
        """
        total_blocks = len(self.cache)
        prefetch_blocks = sum(1 for is_prefetch, _ in self.cache.values() if is_prefetch)
        
        return {
            "total_blocks": total_blocks,
            "prefetch_blocks": prefetch_blocks,
            "regular_blocks": total_blocks - prefetch_blocks,
            "utilization": total_blocks / self.cache_size if self.cache_size > 0 else 0
        }


class MCRow:
    """
    Markov Chain Row - ãƒãƒ«ã‚³ãƒ•é€£é–ã®è¡Œ
    
    CluMPã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®æ ¸å¿ƒéƒ¨åˆ†ã€‚å„ãƒãƒ£ãƒ³ã‚¯ã‹ã‚‰ä»–ã®ãƒãƒ£ãƒ³ã‚¯ã¸ã®
    çŠ¶æ…‹é·ç§»ç¢ºç‡ã‚’å­¦ç¿’ãƒ»è¨˜éŒ²ã—ã€æ¬¡ã®ã‚¢ã‚¯ã‚»ã‚¹å…ˆã‚’äºˆæ¸¬ã™ã‚‹ã€‚
    
    ãƒ‡ãƒ¼ã‚¿æ§‹é€ :
    - CN1, CN2, CN3: é·ç§»å€™è£œãƒãƒ£ãƒ³ã‚¯IDï¼ˆç¢ºç‡é †ï¼‰
    - P1, P2, P3: å¯¾å¿œã™ã‚‹é·ç§»é »åº¦
    
    å­¦ç¿’æ–¹å¼:
    - ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’: ã‚¢ã‚¯ã‚»ã‚¹æ¯ã«é·ç§»ã‚’è¨˜éŒ²
    - é »åº¦ãƒ™ãƒ¼ã‚¹: é·ç§»å›æ•°ã«ã‚ˆã‚Šç¢ºç‡ã‚’è¨ˆç®—
    - ä¸Šä½3å€™è£œã®ã¿ä¿æŒï¼ˆãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–ï¼‰
    
    äºˆæ¸¬æ–¹å¼:
    - CN1ï¼ˆæœ€é »å‡ºé·ç§»å…ˆï¼‰ã‚’æ¬¡ã®ã‚¢ã‚¯ã‚»ã‚¹äºˆæ¸¬ã¨ã—ã¦ä½¿ç”¨
    """
    
    # ã‚¯ãƒ©ã‚¹å®šæ•°: ä¿æŒã™ã‚‹å€™è£œæ•°
    MAX_CANDIDATES = 3
    
    def __init__(self):
        """
        MCRowã‚’åˆæœŸåŒ–
        
        ã™ã¹ã¦ã®å€™è£œãƒãƒ£ãƒ³ã‚¯IDã¨ç¢ºç‡ã‚’åˆæœŸçŠ¶æ…‹ã«è¨­å®šã™ã‚‹ã€‚
        """
        # å€™è£œãƒãƒ£ãƒ³ã‚¯IDï¼ˆCN1, CN2, CN3ï¼‰
        self.candidate_chunks: List[Optional[int]] = [None] * self.MAX_CANDIDATES
        # å‡ºç¾é »åº¦ï¼ˆP1, P2, P3ï¼‰
        self.probabilities: List[int] = [0] * self.MAX_CANDIDATES
        
        logging.debug("MCRowåˆæœŸåŒ–å®Œäº†")
    
    def update_transition(self, next_chunk_id: int) -> None:
        """
        çŠ¶æ…‹é·ç§»ã‚’æ›´æ–°
        
        æ–°ã—ã„é·ç§»ã€Œç¾åœ¨ã®ãƒãƒ£ãƒ³ã‚¯ â†’ next_chunk_idã€ã‚’è¨˜éŒ²ã—ã€
        å€™è£œãƒªã‚¹ãƒˆã‚’é »åº¦é †ã«ä¸¦ã³æ›¿ãˆã‚‹ã€‚
        
        Args:
            next_chunk_id: é·ç§»å…ˆã®ãƒãƒ£ãƒ³ã‚¯ID
            
        Algorithm:
        1. æ—¢å­˜å€™è£œã®å ´åˆ: é »åº¦ã‚’å¢—åŠ ã—ã¦ã‚½ãƒ¼ãƒˆ
        2. æ–°è¦å€™è£œã®å ´åˆ: CN3ä½ç½®ã«æŒ¿å…¥ã—ã¦ã‚½ãƒ¼ãƒˆ
        3. ãƒãƒ–ãƒ«ã‚½ãƒ¼ãƒˆã§é »åº¦é †ã«ä¸¦ã³æ›¿ãˆ
        """
        if next_chunk_id in self.candidate_chunks:
            # æ—¢å­˜ã®å€™è£œã®å ´åˆã€é »åº¦ã‚’å¢—åŠ ã—ã¦ã‚½ãƒ¼ãƒˆ
            index = self.candidate_chunks.index(next_chunk_id)
            self.probabilities[index] += 1
            
            # é »åº¦é †ã«ãƒãƒ–ãƒ«ã‚½ãƒ¼ãƒˆï¼ˆé™é †ï¼‰
            self._bubble_sort_candidates(index)
            
            logging.debug(f"æ—¢å­˜å€™è£œ {next_chunk_id} ã®é »åº¦ã‚’æ›´æ–°: {self.probabilities[0]}")
        else:
            # æ–°ã—ã„å€™è£œã®å ´åˆã€CN3ä½ç½®ã«æŒ¿å…¥
            self.candidate_chunks[2] = next_chunk_id
            self.probabilities[2] = 1
            
            # å¿…è¦ã«å¿œã˜ã¦ãƒãƒ–ãƒ«ã‚¢ãƒƒãƒ—
            self._bubble_sort_candidates(2)
            
            logging.debug(f"æ–°è¦å€™è£œ {next_chunk_id} ã‚’è¿½åŠ ")
    
    def _bubble_sort_candidates(self, start_index: int) -> None:
        """
        å€™è£œãƒªã‚¹ãƒˆã‚’é »åº¦é †ã«ãƒãƒ–ãƒ«ã‚½ãƒ¼ãƒˆ
        
        Args:
            start_index: ã‚½ãƒ¼ãƒˆé–‹å§‹ä½ç½®
            
        Note:
            åŠ¹ç‡ã®ãŸã‚ã€å¤‰æ›´ã•ã‚ŒãŸä½ç½®ã‹ã‚‰ã®ã¿ã‚½ãƒ¼ãƒˆã‚’å®Ÿè¡Œ
        """
        i = start_index
        while i > 0 and (self.probabilities[i] > self.probabilities[i-1] or 
                         (self.probabilities[i] == self.probabilities[i-1] and 
                          self.candidate_chunks[i] is not None)):
            # ã‚¹ãƒ¯ãƒƒãƒ—å®Ÿè¡Œ
            self.probabilities[i], self.probabilities[i-1] = \
                self.probabilities[i-1], self.probabilities[i]
            self.candidate_chunks[i], self.candidate_chunks[i-1] = \
                self.candidate_chunks[i-1], self.candidate_chunks[i]
            i -= 1
    
    def predict_next_chunk(self) -> Optional[int]:
        """
        æ¬¡ã®ãƒãƒ£ãƒ³ã‚¯ã‚’äºˆæ¸¬
        
        æœ€ã‚‚é »åº¦ã®é«˜ã„é·ç§»å…ˆï¼ˆCN1ï¼‰ã‚’äºˆæ¸¬çµæœã¨ã—ã¦è¿”ã™ã€‚
        
        Returns:
            Optional[int]: äºˆæ¸¬ã•ã‚Œã‚‹ãƒãƒ£ãƒ³ã‚¯IDï¼ˆCN1ï¼‰ã€ãªã‘ã‚Œã°None
        """
        prediction = self.candidate_chunks[0]
        if prediction is not None:
            logging.debug(f"ãƒãƒ£ãƒ³ã‚¯äºˆæ¸¬: {prediction} (é »åº¦: {self.probabilities[0]})")
        return prediction
    
    def get_transition_info(self) -> Dict[str, Any]:
        """
        é·ç§»æƒ…å ±ã®è©³ç´°ã‚’å–å¾—ï¼ˆãƒ‡ãƒãƒƒã‚°ãƒ»åˆ†æç”¨ï¼‰
        
        Returns:
            Dict[str, Any]: é·ç§»å€™è£œã¨ç¢ºç‡ã®è©³ç´°æƒ…å ±
        """
        total_transitions = sum(self.probabilities)
        
        candidates_info = []
        for i in range(self.MAX_CANDIDATES):
            if self.candidate_chunks[i] is not None:
                probability = self.probabilities[i] / total_transitions if total_transitions > 0 else 0
                candidates_info.append({
                    "rank": i + 1,
                    "chunk_id": self.candidate_chunks[i],
                    "frequency": self.probabilities[i],
                    "probability": probability
                })
        
        return {
            "total_transitions": total_transitions,
            "candidates": candidates_info
        }


class ClusterManager:
    """
    ã‚¯ãƒ©ã‚¹ã‚¿ãƒãƒãƒ¼ã‚¸ãƒ£
    
    ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–ã®ãŸã‚ã€è¤‡æ•°ã®ãƒãƒ£ãƒ³ã‚¯ã‚’CLsizeå˜ä½ã«ã¾ã¨ã‚ã€
    MCRowã‚’ã‚ªãƒ³ãƒ‡ãƒãƒ³ãƒ‰ã§å‰²ã‚Šå½“ã¦ç®¡ç†ã™ã‚‹ã€‚
    
    è¨­è¨ˆæ€æƒ³:
    - ã‚ªãƒ³ãƒ‡ãƒãƒ³ãƒ‰å‰²ã‚Šå½“ã¦: ä½¿ç”¨ã•ã‚Œãªã„MCRowã¯ãƒ¡ãƒ¢ãƒªã‚’æ¶ˆè²»ã—ãªã„
    - éšå±¤ç®¡ç†: ã‚¯ãƒ©ã‚¹ã‚¿ â†’ ãƒãƒ£ãƒ³ã‚¯ â†’ MCRowã®éšå±¤æ§‹é€ 
    - åŠ¹ç‡çš„æ¤œç´¢: ã‚¯ãƒ©ã‚¹ã‚¿IDã«ã‚ˆã‚‹é«˜é€Ÿã‚¢ã‚¯ã‚»ã‚¹
    
    ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–:
    - æœªä½¿ç”¨ãƒãƒ£ãƒ³ã‚¯ã®MCRowã¯ä½œæˆã—ãªã„
    - ã‚¢ã‚¯ã‚»ã‚¹ãŒç™ºç”Ÿã—ãŸæ™‚ç‚¹ã§åˆã‚ã¦å‰²ã‚Šå½“ã¦
    - å…¨ä½“ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’è¿½è·¡
    """
    
    def __init__(self, cluster_size_chunks: int):
        """
        ã‚¯ãƒ©ã‚¹ã‚¿ãƒãƒãƒ¼ã‚¸ãƒ£ã‚’åˆæœŸåŒ–
        
        Args:
            cluster_size_chunks: ã‚¯ãƒ©ã‚¹ã‚¿ã‚µã‚¤ã‚ºï¼ˆãƒãƒ£ãƒ³ã‚¯æ•°ï¼‰
            
        Raises:
            ValueError: ã‚¯ãƒ©ã‚¹ã‚¿ã‚µã‚¤ã‚ºãŒç„¡åŠ¹ãªå ´åˆ
        """
        if cluster_size_chunks <= 0:
            raise ValueError(f"ã‚¯ãƒ©ã‚¹ã‚¿ã‚µã‚¤ã‚ºã¯æ­£ã®å€¤ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™: {cluster_size_chunks}")
            
        self.cluster_size = cluster_size_chunks
        # cluster_id -> {chunk_id: MCRow}
        self.clusters: Dict[int, Dict[int, MCRow]] = {}
        
        logging.debug(f"ClusterManageråˆæœŸåŒ–: ã‚¯ãƒ©ã‚¹ã‚¿ã‚µã‚¤ã‚º={cluster_size_chunks}ãƒãƒ£ãƒ³ã‚¯")
    
    def get_mc_row(self, chunk_id: int, allocate: bool = False) -> Optional[MCRow]:
        """
        æŒ‡å®šã•ã‚ŒãŸãƒãƒ£ãƒ³ã‚¯ã®MCRowã‚’å–å¾—
        
        ãƒãƒ£ãƒ³ã‚¯IDã‹ã‚‰å¯¾å¿œã™ã‚‹ã‚¯ãƒ©ã‚¹ã‚¿ã‚’ç‰¹å®šã—ã€MCRowã‚’å–å¾—ã™ã‚‹ã€‚
        allocateãŒTrueã®å ´åˆã€å­˜åœ¨ã—ãªã„å ´åˆã¯æ–°è¦ä½œæˆã™ã‚‹ã€‚
        
        Args:
            chunk_id: ãƒãƒ£ãƒ³ã‚¯ID
            allocate: å­˜åœ¨ã—ãªã„å ´åˆã«æ–°è¦ä½œæˆã™ã‚‹ã‹ã©ã†ã‹
            
        Returns:
            Optional[MCRow]: MCRowã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã€å­˜åœ¨ã—ãªã‘ã‚Œã°None
            
        Note:
            ã‚ªãƒ³ãƒ‡ãƒãƒ³ãƒ‰å‰²ã‚Šå½“ã¦ã«ã‚ˆã‚Šã€ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’æœ€å°åŒ–
        """
        cluster_id = chunk_id // self.cluster_size
        
        # ã‚¯ãƒ©ã‚¹ã‚¿ã®å–å¾—ã¾ãŸã¯ä½œæˆ
        if cluster_id in self.clusters:
            cluster = self.clusters[cluster_id]
        else:
            if not allocate:
                return None
            cluster = {}
            self.clusters[cluster_id] = cluster
            logging.debug(f"æ–°è¦ã‚¯ãƒ©ã‚¹ã‚¿ {cluster_id} ã‚’ä½œæˆ")
        
        # MCRowã®å–å¾—ã¾ãŸã¯ä½œæˆ
        mc_row = cluster.get(chunk_id)
        if mc_row is None and allocate:
            mc_row = MCRow()
            cluster[chunk_id] = mc_row
            logging.debug(f"ãƒãƒ£ãƒ³ã‚¯ {chunk_id} ã®MCRowã‚’æ–°è¦ä½œæˆ (ã‚¯ãƒ©ã‚¹ã‚¿ {cluster_id})")
        
        return mc_row
    
    def get_memory_usage(self) -> int:
        """
        ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ï¼ˆç”Ÿæˆã•ã‚ŒãŸMCRowæ•°ï¼‰ã‚’å–å¾—
        
        Returns:
            int: MCRowæ•°
        """
        total_rows = 0
        for cluster in self.clusters.values():
            total_rows += len(cluster)
        return total_rows
    
    def get_cluster_info(self) -> Dict[str, Any]:
        """
        ã‚¯ãƒ©ã‚¹ã‚¿ã®è©³ç´°æƒ…å ±ã‚’å–å¾—ï¼ˆåˆ†æãƒ»ãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
        
        Returns:
            Dict[str, Any]: ã‚¯ãƒ©ã‚¹ã‚¿ã¨MCRowã®çµ±è¨ˆæƒ…å ±
        """
        total_clusters = len(self.clusters)
        total_mc_rows = self.get_memory_usage()
        
        cluster_utilization = []
        for cluster_id, cluster in self.clusters.items():
            cluster_utilization.append({
                "cluster_id": cluster_id,
                "mc_rows": len(cluster),
                "utilization": len(cluster) / self.cluster_size
            })
        
        avg_utilization = (total_mc_rows / (total_clusters * self.cluster_size) 
                          if total_clusters > 0 else 0)
        
        return {
            "total_clusters": total_clusters,
            "total_mc_rows": total_mc_rows,
            "cluster_size": self.cluster_size,
            "average_utilization": avg_utilization,
            "cluster_details": cluster_utilization
        }


class CluMPSimulator:
    """
    CluMP ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ãƒ¡ã‚¤ãƒ³ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿
    
    è¦ä»¶å®šç¾©æ›¸ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ å‡¦ç†ãƒ•ãƒ­ãƒ¼ã«å¾“ã£ã¦å®Ÿè£…ã•ã‚ŒãŸã€
    CluMPï¼ˆCLUstered Markov-chain Prefetchingï¼‰ã®ä¸­æ ¸å®Ÿè£…ã€‚
    
    ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ æ¦‚è¦:
    1. è¤‡æ•°ã®ãƒ–ãƒ­ãƒƒã‚¯ã‚’ã€Œãƒãƒ£ãƒ³ã‚¯ã€å˜ä½ã«ã¾ã¨ã‚ã‚‹
    2. ãƒãƒ«ã‚³ãƒ•é€£é–ã§ã€Œãƒãƒ£ãƒ³ã‚¯A â†’ ãƒãƒ£ãƒ³ã‚¯Bã€ã®é·ç§»ã‚’å­¦ç¿’
    3. å­¦ç¿’ã—ãŸé·ç§»ç¢ºç‡ã§æ¬¡ã®ã‚¢ã‚¯ã‚»ã‚¹å…ˆã‚’äºˆæ¸¬
    4. äºˆæ¸¬ã—ãŸãƒãƒ£ãƒ³ã‚¯ã‚’äº‹å‰ã«ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒã—ã¦æ€§èƒ½å‘ä¸Š
    
    å‡¦ç†ãƒ•ãƒ­ãƒ¼ï¼ˆè¦ä»¶å®šç¾©æ›¸æº–æ‹ ï¼‰:
    1. ã‚¢ã‚¯ã‚»ã‚¹å‡¦ç†ï¼šã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ç¢ºèªã—ã€ãƒ’ãƒƒãƒˆ/ãƒŸã‚¹ã‚’åˆ¤å®š
    2. ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ›´æ–°ï¼šãƒŸã‚¹ãªã‚‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’èª­ã¿è¾¼ã¿ã€LRUæ–¹å¼ã§ç®¡ç†
    3. MCæ›´æ–°ï¼šã€Œå‰ãƒãƒ£ãƒ³ã‚¯ â†’ ç¾ãƒãƒ£ãƒ³ã‚¯ã€ã®é·ç§»ã‚’æ›´æ–°
    4. äºˆæ¸¬ãƒ»ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒï¼šCN1ã‚’å‚ç…§ã—ã€äºˆæ¸¬ãƒãƒ£ãƒ³ã‚¯ã‚’PrefetchWindowåˆ†ãƒ­ãƒ¼ãƒ‰
    
    ç‰¹å¾´:
    - ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ï¼šã‚¢ã‚¯ã‚»ã‚¹æ¯ã«ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ›´æ–°
    - ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ï¼šæœªä½¿ç”¨ãƒãƒ£ãƒ³ã‚¯ã®MCRowã¯ä½œæˆã—ãªã„
    - çµ±è¨ˆè¿½è·¡ï¼šè©³ç´°ãªãƒ—ãƒªãƒ•ã‚§ãƒƒãƒåŠ¹æœã‚’æ¸¬å®š
    """
    
    def __init__(self, chunk_size_blocks: int, cluster_size_chunks: int, 
                 cache_size_blocks: int, prefetch_window_blocks: int):
        """
        CluMPã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ã‚’åˆæœŸåŒ–
        
        Args:
            chunk_size_blocks: ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºï¼ˆãƒ–ãƒ­ãƒƒã‚¯æ•°ï¼‰
            cluster_size_chunks: ã‚¯ãƒ©ã‚¹ã‚¿ã‚µã‚¤ã‚ºï¼ˆãƒãƒ£ãƒ³ã‚¯æ•°ï¼‰
            cache_size_blocks: ã‚­ãƒ£ãƒƒã‚·ãƒ¥å®¹é‡ï¼ˆãƒ–ãƒ­ãƒƒã‚¯æ•°ï¼‰
            prefetch_window_blocks: ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒæ™‚ã«èª­ã¿è¾¼ã‚€ãƒ–ãƒ­ãƒƒã‚¯æ•°
            
        Raises:
            ValueError: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒç„¡åŠ¹ãªå ´åˆ
        """
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¤œè¨¼
        if chunk_size_blocks <= 0:
            raise ValueError(f"ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã¯æ­£ã®å€¤ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™: {chunk_size_blocks}")
        if cluster_size_chunks <= 0:
            raise ValueError(f"ã‚¯ãƒ©ã‚¹ã‚¿ã‚µã‚¤ã‚ºã¯æ­£ã®å€¤ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™: {cluster_size_chunks}")
        if cache_size_blocks <= 0:
            raise ValueError(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºã¯æ­£ã®å€¤ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™: {cache_size_blocks}")
        if prefetch_window_blocks <= 0:
            raise ValueError(f"ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒçª“ã¯æ­£ã®å€¤ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™: {prefetch_window_blocks}")
        
        self.chunk_size = chunk_size_blocks
        self.cluster_size = cluster_size_chunks
        self.prefetch_window = prefetch_window_blocks
        
        # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–
        self.cache = LRUCache(cache_size_blocks)
        self.cluster_manager = ClusterManager(cluster_size_chunks)
        
        # çµ±è¨ˆæƒ…å ±
        self.total_accesses = 0
        self.cache_hits = 0
        self.previous_chunk_id: Optional[int] = None
        
        logging.info(f"CluMPSimulatoråˆæœŸåŒ–å®Œäº†: "
                    f"chunk={chunk_size_blocks}, cluster={cluster_size_chunks}, "
                    f"cache={cache_size_blocks}, prefetch_window={prefetch_window_blocks}")
    
    def _get_chunk_id(self, block_id: int) -> int:
        """
        ãƒ–ãƒ­ãƒƒã‚¯IDã‹ã‚‰ãƒãƒ£ãƒ³ã‚¯IDã‚’è¨ˆç®—
        
        Args:
            block_id: ãƒ–ãƒ­ãƒƒã‚¯ID
            
        Returns:
            int: ãƒãƒ£ãƒ³ã‚¯ID
            
        Note:
            ãƒãƒ£ãƒ³ã‚¯ID = ãƒ–ãƒ­ãƒƒã‚¯ID Ã· ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºï¼ˆæ•´æ•°é™¤ç®—ï¼‰
            ä¾‹: ãƒ–ãƒ­ãƒƒã‚¯8ã€ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º4 â†’ ãƒãƒ£ãƒ³ã‚¯2
        """
        return block_id // self.chunk_size
    
    def _prefetch_chunk(self, chunk_id: int) -> None:
        """
        æŒ‡å®šã•ã‚ŒãŸãƒãƒ£ãƒ³ã‚¯ã‚’ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒ
        
        äºˆæ¸¬ã•ã‚ŒãŸãƒãƒ£ãƒ³ã‚¯ã®é–‹å§‹ãƒ–ãƒ­ãƒƒã‚¯ã‹ã‚‰ã€ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒçª“ã‚µã‚¤ã‚ºåˆ†ã®
        ãƒ–ãƒ­ãƒƒã‚¯ã‚’äº‹å‰ã«èª­ã¿è¾¼ã‚“ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«æ ¼ç´ã™ã‚‹ã€‚
        
        Args:
            chunk_id: ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒå¯¾è±¡ã®ãƒãƒ£ãƒ³ã‚¯ID
            
        Note:
            ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒçª“ãŒãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã‚ˆã‚Šå¤§ãã„å ´åˆã€
            æ¬¡ã®ãƒãƒ£ãƒ³ã‚¯ã«ã¾ãŸãŒã£ã¦ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒã‚’å®Ÿè¡Œ
        """
        start_block = chunk_id * self.chunk_size
        prefetched_blocks = []
        
        for offset in range(self.prefetch_window):
            prefetch_block = start_block + offset
            self.cache.insert(prefetch_block, is_prefetch=True)
            prefetched_blocks.append(prefetch_block)
        
        logging.debug(f"ãƒãƒ£ãƒ³ã‚¯ {chunk_id} ã‚’ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒ: ãƒ–ãƒ­ãƒƒã‚¯ {prefetched_blocks}")
    
    def process_access(self, block_id: int) -> bool:
        """
        ã‚¢ã‚¯ã‚»ã‚¹å‡¦ç†ï¼ˆè¦ä»¶å®šç¾©æ›¸ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ å‡¦ç†ãƒ•ãƒ­ãƒ¼ã«å¾“ã†ï¼‰
        
        CluMPã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ä¸­æ ¸å‡¦ç†ã€‚å˜ä¸€ãƒ–ãƒ­ãƒƒã‚¯ã‚¢ã‚¯ã‚»ã‚¹ã«å¯¾ã—ã¦ã€
        ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç¢ºèªã€å­¦ç¿’æ›´æ–°ã€äºˆæ¸¬ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒã®å…¨å·¥ç¨‹ã‚’å®Ÿè¡Œã€‚
        
        Args:
            block_id: ã‚¢ã‚¯ã‚»ã‚¹å¯¾è±¡ã®ãƒ–ãƒ­ãƒƒã‚¯ID
            
        Returns:
            bool: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆã—ãŸã‹ã©ã†ã‹
            
        Algorithm:
        1. ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¢ã‚¯ã‚»ã‚¹ â†’ ãƒ’ãƒƒãƒˆ/ãƒŸã‚¹åˆ¤å®š
        2. ãƒŸã‚¹ã®å ´åˆ â†’ ãƒ–ãƒ­ãƒƒã‚¯èª­ã¿è¾¼ã¿ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥æŒ¿å…¥
        3. ãƒãƒ«ã‚³ãƒ•é€£é–å­¦ç¿’ â†’ å‰ãƒãƒ£ãƒ³ã‚¯ã‹ã‚‰ã®é·ç§»ã‚’è¨˜éŒ²
        4. æ¬¡ãƒãƒ£ãƒ³ã‚¯äºˆæ¸¬ â†’ CN1ã‹ã‚‰äºˆæ¸¬ã€ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒå®Ÿè¡Œ
        """
        self.total_accesses += 1
        current_chunk_id = self._get_chunk_id(block_id)
        
        # 1. ã‚¢ã‚¯ã‚»ã‚¹å‡¦ç†ï¼šã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ç¢ºèªã—ã€ãƒ’ãƒƒãƒˆ/ãƒŸã‚¹ã‚’åˆ¤å®š
        cache_hit = self.cache.access(block_id)
        
        if cache_hit:
            self.cache_hits += 1
            logging.debug(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆ: ãƒ–ãƒ­ãƒƒã‚¯ {block_id} (ãƒãƒ£ãƒ³ã‚¯ {current_chunk_id})")
            
            # 3. MCæ›´æ–°ï¼šã€Œå‰ãƒãƒ£ãƒ³ã‚¯ â†’ ç¾ãƒãƒ£ãƒ³ã‚¯ã€ã®é·ç§»ã‚’æ›´æ–°
            self._update_markov_chain(current_chunk_id)
            self.previous_chunk_id = current_chunk_id
            return True
        
        # 2. ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ›´æ–°ï¼šãƒŸã‚¹ãªã‚‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’èª­ã¿è¾¼ã¿ã€LRUæ–¹å¼ã§ç®¡ç†
        self.cache.insert(block_id, is_prefetch=False)
        logging.debug(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹: ãƒ–ãƒ­ãƒƒã‚¯ {block_id} ã‚’èª­ã¿è¾¼ã¿ (ãƒãƒ£ãƒ³ã‚¯ {current_chunk_id})")
        
        # 3. MCæ›´æ–°ï¼šã€Œå‰ãƒãƒ£ãƒ³ã‚¯ â†’ ç¾ãƒãƒ£ãƒ³ã‚¯ã€ã®é·ç§»ã‚’æ›´æ–°
        self._update_markov_chain(current_chunk_id)
        
        self.previous_chunk_id = current_chunk_id
        
        # 4. äºˆæ¸¬ãƒ»ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒï¼šCN1ã‚’å‚ç…§ã—ã€äºˆæ¸¬ãƒãƒ£ãƒ³ã‚¯ã‚’PrefetchWindowåˆ†ãƒ­ãƒ¼ãƒ‰
        self._execute_prediction_and_prefetch(current_chunk_id)
        
        return False
    
    def _update_markov_chain(self, current_chunk_id: int) -> None:
        """
        ãƒãƒ«ã‚³ãƒ•é€£é–ã®å­¦ç¿’æ›´æ–°
        
        Args:
            current_chunk_id: ç¾åœ¨ã®ãƒãƒ£ãƒ³ã‚¯ID
        """
        if (self.previous_chunk_id is not None and 
            self.previous_chunk_id != current_chunk_id):
            mc_row = self.cluster_manager.get_mc_row(self.previous_chunk_id, allocate=True)
            mc_row.update_transition(current_chunk_id)
            logging.debug(f"é·ç§»å­¦ç¿’: ãƒãƒ£ãƒ³ã‚¯ {self.previous_chunk_id} â†’ {current_chunk_id}")
    
    def _execute_prediction_and_prefetch(self, current_chunk_id: int) -> None:
        """
        äºˆæ¸¬ã¨ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒã®å®Ÿè¡Œ
        
        Args:
            current_chunk_id: ç¾åœ¨ã®ãƒãƒ£ãƒ³ã‚¯ID
        """
        mc_row = self.cluster_manager.get_mc_row(current_chunk_id, allocate=False)
        if mc_row is not None:
            predicted_chunk = mc_row.predict_next_chunk()
            if predicted_chunk is not None:
                self._prefetch_chunk(predicted_chunk)
                logging.debug(f"äºˆæ¸¬ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒ: ãƒãƒ£ãƒ³ã‚¯ {current_chunk_id} â†’ {predicted_chunk}")
    
    def get_evaluation_metrics(self) -> Dict[str, Any]:
        """
        è©•ä¾¡æŒ‡æ¨™ã‚’è¨ˆç®—ï¼ˆè¦ä»¶å®šç¾©æ›¸æº–æ‹ ï¼‰
        
        Returns:
            Dict[str, Any]: è©•ä¾¡æŒ‡æ¨™ã®è¾æ›¸
        """
        prefetch_stats = self.cache.get_prefetch_stats()
        
        # ãƒ’ãƒƒãƒˆç‡
        hit_rate = self.cache_hits / self.total_accesses if self.total_accesses > 0 else 0.0
        
        # ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒåŠ¹ç‡
        prefetch_efficiency = (prefetch_stats["prefetch_used"] / 
                             prefetch_stats["prefetch_total"]) if prefetch_stats["prefetch_total"] > 0 else 0.0
        
        return {
            # åŸºæœ¬çµ±è¨ˆ
            "total_accesses": self.total_accesses,
            "cache_hits": self.cache_hits,
            "hit_rate": hit_rate,
            
            # ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒçµ±è¨ˆï¼ˆè¦ä»¶å®šç¾©æ›¸æº–æ‹ ï¼‰
            "prefetch_total": prefetch_stats["prefetch_total"],
            "prefetch_used": prefetch_stats["prefetch_used"],
            "prefetch_unused_evicted": prefetch_stats["prefetch_unused_evicted"],
            "prefetch_efficiency": prefetch_efficiency,
            
            # ãƒ¡ãƒ¢ãƒªæ¶ˆè²»ï¼ˆç”Ÿæˆã•ã‚ŒãŸMCRowæ•°ï¼‰
            "memory_usage_mc_rows": self.cluster_manager.get_memory_usage(),
            
            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æƒ…å ±
            "chunk_size": self.chunk_size,
            "cluster_size": self.cluster_size,
            "cache_size": self.cache.cache_size,
            "prefetch_window": self.prefetch_window
        }


class TraceGenerator:
    """
    åˆæˆãƒˆãƒ¬ãƒ¼ã‚¹ç”Ÿæˆå™¨
    è¦ä»¶å®šç¾©æ›¸ã«åŸºã¥ãå…¥åŠ›ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    """
    
    @staticmethod
    def generate_synthetic_trace(n_events: int = 20000, num_files: int = 50,
                               avg_file_length_blocks: int = 200,
                               sequential_prob: float = 0.6,
                               jump_prob: float = 0.1) -> List[int]:
        """
        åˆæˆãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã‚’ç”Ÿæˆ
        
        Args:
            n_events: ç”Ÿæˆã™ã‚‹ã‚¢ã‚¯ã‚»ã‚¹ã‚¤ãƒ™ãƒ³ãƒˆæ•°
            num_files: ãƒ•ã‚¡ã‚¤ãƒ«æ•°
            avg_file_length_blocks: ãƒ•ã‚¡ã‚¤ãƒ«ã®å¹³å‡é•·ï¼ˆãƒ–ãƒ­ãƒƒã‚¯æ•°ï¼‰
            sequential_prob: é †æ¬¡ã‚¢ã‚¯ã‚»ã‚¹ç¢ºç‡
            jump_prob: åŒä¸€ãƒ•ã‚¡ã‚¤ãƒ«å†…ãƒ©ãƒ³ãƒ€ãƒ ã‚¸ãƒ£ãƒ³ãƒ—ç¢ºç‡
            
        Returns:
            List[int]: ãƒ–ãƒ­ãƒƒã‚¯IDã®ãƒªã‚¹ãƒˆ
        """
        # ãƒ•ã‚¡ã‚¤ãƒ«é…ç½®ã®è¨­å®š
        files = []
        base_block = 0
        
        for _ in range(num_files):
            length = max(10, int(random.expovariate(1/avg_file_length_blocks)))
            files.append((base_block, base_block + length - 1))
            base_block += length + random.randint(1, 50)  # ãƒ•ã‚¡ã‚¤ãƒ«é–“ã‚®ãƒ£ãƒƒãƒ—
        
        # ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¹ç”Ÿæˆ
        trace = []
        current_file_idx = random.randrange(num_files)
        current_block = random.randrange(files[current_file_idx][0], 
                                       files[current_file_idx][1] + 1)
        
        for _ in range(n_events):
            prob = random.random()
            
            if prob < sequential_prob:
                # é †æ¬¡ã‚¢ã‚¯ã‚»ã‚¹
                if current_block < files[current_file_idx][1]:
                    current_block += 1
                else:
                    # ãƒ•ã‚¡ã‚¤ãƒ«æœ«å°¾ãªã‚‰åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚¸ãƒ£ãƒ³ãƒ—
                    current_file_idx = random.randrange(num_files)
                    current_block = random.randrange(files[current_file_idx][0], 
                                                   files[current_file_idx][1] + 1)
            elif prob < sequential_prob + jump_prob:
                # åŒä¸€ãƒ•ã‚¡ã‚¤ãƒ«å†…ãƒ©ãƒ³ãƒ€ãƒ ã‚¸ãƒ£ãƒ³ãƒ—
                current_block = random.randrange(files[current_file_idx][0], 
                                               files[current_file_idx][1] + 1)
            else:
                # åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚¸ãƒ£ãƒ³ãƒ—
                current_file_idx = random.randrange(num_files)
                current_block = random.randrange(files[current_file_idx][0], 
                                               files[current_file_idx][1] + 1)
            
            trace.append(current_block)
        
        return trace


def run_clump_simulation(trace: List[int], chunk_size: int = 8, 
                        cluster_size: int = 32, cache_size: int = 4096,
                        prefetch_window: int = 16) -> Dict[str, Any]:
    """
    CluMPã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ
    
    Args:
        trace: ãƒ–ãƒ­ãƒƒã‚¯ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¹
        chunk_size: ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºï¼ˆãƒ–ãƒ­ãƒƒã‚¯æ•°ï¼‰
        cluster_size: ã‚¯ãƒ©ã‚¹ã‚¿ã‚µã‚¤ã‚ºï¼ˆãƒãƒ£ãƒ³ã‚¯æ•°ï¼‰
        cache_size: ã‚­ãƒ£ãƒƒã‚·ãƒ¥å®¹é‡ï¼ˆãƒ–ãƒ­ãƒƒã‚¯æ•°ï¼‰
        prefetch_window: ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒçª“ã‚µã‚¤ã‚ºï¼ˆãƒ–ãƒ­ãƒƒã‚¯æ•°ï¼‰
        
    Returns:
        Dict[str, Any]: è©•ä¾¡æŒ‡æ¨™
    """
    simulator = CluMPSimulator(chunk_size, cluster_size, cache_size, prefetch_window)
    
    # ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’é †æ¬¡å‡¦ç†
    for block_id in trace:
        simulator.process_access(block_id)
    
    return simulator.get_evaluation_metrics()


def get_simulation_config() -> Dict[str, Any]:
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®šã‚’å–å¾—
    
    Returns:
        Dict[str, Any]: ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š
    """
    print("\nğŸ”§ CluMP ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š")
    print("-" * 50)
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
    config = {
        "trace": {
            "n_events": 50000,
            "num_files": 80,
            "avg_file_length_blocks": 150,
            "sequential_prob": 0.55,
            "jump_prob": 0.15
        },
        "clump": {
            "chunk_size": 32,
            "cluster_size": 32,
            "cache_size": 4096,
            "prefetch_window": 16
        }
    }
    
    print("å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠã—ã¦ãã ã•ã„:")
    print("1. ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã§å®Ÿè¡Œ")
    print("2. ã‚«ã‚¹ã‚¿ãƒ è¨­å®šã§å®Ÿè¡Œ")
    print("3. ã‚¯ã‚¤ãƒƒã‚¯å®Ÿè¡Œï¼ˆå°è¦æ¨¡ãƒ†ã‚¹ãƒˆï¼‰")
    
    try:
        choice = input("\né¸æŠã—ã¦ãã ã•ã„ (1-3, ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1): ").strip()
        
        if choice == "2":
            print("\nğŸ“Š ãƒˆãƒ¬ãƒ¼ã‚¹è¨­å®š")
            config["trace"]["n_events"] = int(input(f"ã‚¢ã‚¯ã‚»ã‚¹æ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {config['trace']['n_events']:,}): ") or config["trace"]["n_events"])
            config["trace"]["num_files"] = int(input(f"ãƒ•ã‚¡ã‚¤ãƒ«æ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {config['trace']['num_files']}): ") or config["trace"]["num_files"])
            config["trace"]["avg_file_length_blocks"] = int(input(f"å¹³å‡ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º(ãƒ–ãƒ­ãƒƒã‚¯) (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {config['trace']['avg_file_length_blocks']}): ") or config["trace"]["avg_file_length_blocks"])
            config["trace"]["sequential_prob"] = float(input(f"é †æ¬¡ã‚¢ã‚¯ã‚»ã‚¹ç¢ºç‡ (0.0-1.0, ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {config['trace']['sequential_prob']}): ") or config["trace"]["sequential_prob"])
            config["trace"]["jump_prob"] = float(input(f"ã‚¸ãƒ£ãƒ³ãƒ—ç¢ºç‡ (0.0-1.0, ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {config['trace']['jump_prob']}): ") or config["trace"]["jump_prob"])
            
            print("\nâš™ï¸ CluMPãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š")
            config["clump"]["chunk_size"] = int(input(f"ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º (ãƒ–ãƒ­ãƒƒã‚¯æ•°, ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {config['clump']['chunk_size']}): ") or config["clump"]["chunk_size"])
            config["clump"]["cluster_size"] = int(input(f"ã‚¯ãƒ©ã‚¹ã‚¿ã‚µã‚¤ã‚º (ãƒãƒ£ãƒ³ã‚¯æ•°, ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {config['clump']['cluster_size']}): ") or config["clump"]["cluster_size"])
            config["clump"]["cache_size"] = int(input(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚º (ãƒ–ãƒ­ãƒƒã‚¯æ•°, ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {config['clump']['cache_size']:,}): ") or config["clump"]["cache_size"])
            config["clump"]["prefetch_window"] = int(input(f"ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒçª“ã‚µã‚¤ã‚º (ãƒ–ãƒ­ãƒƒã‚¯æ•°, ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {config['clump']['prefetch_window']}): ") or config["clump"]["prefetch_window"])
            
        elif choice == "3":
            # ã‚¯ã‚¤ãƒƒã‚¯å®Ÿè¡Œè¨­å®š
            config["trace"]["n_events"] = 10000
            config["trace"]["num_files"] = 20
            config["trace"]["avg_file_length_blocks"] = 50
            config["clump"]["cache_size"] = 2048
            print("ã‚¯ã‚¤ãƒƒã‚¯å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰: å°è¦æ¨¡è¨­å®šã§é«˜é€Ÿå®Ÿè¡Œ")
            
    except (ValueError, KeyboardInterrupt):
        print("\nâš ï¸ å…¥åŠ›ã‚¨ãƒ©ãƒ¼ã¾ãŸã¯ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
    
    return config


def print_config_summary(config: Dict[str, Any]) -> None:
    """è¨­å®šã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""
    print("\nğŸ“‹ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®šã‚µãƒãƒªãƒ¼")
    print("-" * 50)
    trace = config["trace"]
    clump = config["clump"]
    
    print(f"ğŸ“Š ãƒˆãƒ¬ãƒ¼ã‚¹:")
    print(f"   ã‚¢ã‚¯ã‚»ã‚¹æ•°: {trace['n_events']:,}")
    print(f"   ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {trace['num_files']}")
    print(f"   å¹³å‡ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {trace['avg_file_length_blocks']} ãƒ–ãƒ­ãƒƒã‚¯")
    print(f"   é †æ¬¡ã‚¢ã‚¯ã‚»ã‚¹ç¢ºç‡: {trace['sequential_prob']:.1%}")
    print(f"   ã‚¸ãƒ£ãƒ³ãƒ—ç¢ºç‡: {trace['jump_prob']:.1%}")
    
    print(f"\nâš™ï¸ CluMPãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:")
    print(f"   ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º: {clump['chunk_size']} ãƒ–ãƒ­ãƒƒã‚¯")
    print(f"   ã‚¯ãƒ©ã‚¹ã‚¿ã‚µã‚¤ã‚º: {clump['cluster_size']} ãƒãƒ£ãƒ³ã‚¯")
    print(f"   ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚º: {clump['cache_size']:,} ãƒ–ãƒ­ãƒƒã‚¯")
    print(f"   ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒçª“: {clump['prefetch_window']} ãƒ–ãƒ­ãƒƒã‚¯")


def print_evaluation_results(results: Dict[str, Any]) -> None:
    """
    è©•ä¾¡çµæœã‚’è¡¨ç¤º
    
    Args:
        results: è©•ä¾¡æŒ‡æ¨™ã®è¾æ›¸
    """
    print("\n" + "=" * 60)
    print("CluMP ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœ")
    print("=" * 60)
    
    print(f"ğŸ“ˆ åŸºæœ¬çµ±è¨ˆ:")
    print(f"   ç·ã‚¢ã‚¯ã‚»ã‚¹æ•°: {results['total_accesses']:,}")
    print(f"   ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆæ•°: {results['cache_hits']:,}")
    print(f"   ãƒ’ãƒƒãƒˆç‡: {results['hit_rate']:.3f} ({results['hit_rate']*100:.1f}%)")
    
    print(f"\nğŸ¯ ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒçµ±è¨ˆ:")
    print(f"   ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒç·æ•°: {results['prefetch_total']:,}")
    print(f"   ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒä½¿ç”¨æ•°: {results['prefetch_used']:,}")
    print(f"   æœªä½¿ç”¨ã§è¿½ã„å‡ºã—: {results['prefetch_unused_evicted']:,}")
    print(f"   ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒåŠ¹ç‡: {results['prefetch_efficiency']:.3f} ({results['prefetch_efficiency']*100:.1f}%)")
    
    print(f"\nğŸ’¾ ãƒ¡ãƒ¢ãƒªæ¶ˆè²»:")
    print(f"   MCè¡Œæ•°: {results['memory_usage_mc_rows']:,}")
    
    print(f"\nâš™ï¸ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š:")
    print(f"   ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º: {results['chunk_size']} ãƒ–ãƒ­ãƒƒã‚¯")
    print(f"   ã‚¯ãƒ©ã‚¹ã‚¿ã‚µã‚¤ã‚º: {results['cluster_size']} ãƒãƒ£ãƒ³ã‚¯")
    print(f"   ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚º: {results['cache_size']:,} ãƒ–ãƒ­ãƒƒã‚¯")
    print(f"   ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒçª“: {results['prefetch_window']} ãƒ–ãƒ­ãƒƒã‚¯")
    
    # ç°¡æ˜“æ€§èƒ½è©•ä¾¡
    if results['hit_rate'] >= 0.7:
        performance = "å„ªç§€ ğŸŒŸ"
    elif results['hit_rate'] >= 0.5:
        performance = "è‰¯å¥½ ğŸ‘"
    elif results['hit_rate'] >= 0.3:
        performance = "æ™®é€š ğŸ˜"
    else:
        performance = "è¦æ”¹å–„ ğŸ˜"
    
    print(f"\nğŸ† æ€§èƒ½è©•ä¾¡: {performance}")
    print("=" * 60)


def run_custom_simulation() -> None:
    """ã‚«ã‚¹ã‚¿ãƒ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã®å˜ä¸€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ"""
    print("\nğŸš€ ã‚«ã‚¹ã‚¿ãƒ CluMPã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
    print("-" * 50)
    
    try:
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å…¥åŠ›
        chunk_size = int(input("ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º (ãƒ–ãƒ­ãƒƒã‚¯æ•°, ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 8): ") or "8")
        cluster_size = int(input("ã‚¯ãƒ©ã‚¹ã‚¿ã‚µã‚¤ã‚º (ãƒãƒ£ãƒ³ã‚¯æ•°, ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 32): ") or "32")
        cache_size = int(input("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚º (ãƒ–ãƒ­ãƒƒã‚¯æ•°, ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 4096): ") or "4096")
        prefetch_window = int(input("ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒçª“ (ãƒ–ãƒ­ãƒƒã‚¯æ•°, ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 16): ") or "16")
        n_events = int(input("ã‚¢ã‚¯ã‚»ã‚¹æ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 10000): ") or "10000")
        
        print(f"\nğŸ“Š è¨­å®šç¢ºèª:")
        print(f"   ãƒãƒ£ãƒ³ã‚¯: {chunk_size}, ã‚¯ãƒ©ã‚¹ã‚¿: {cluster_size}")
        print(f"   ã‚­ãƒ£ãƒƒã‚·ãƒ¥: {cache_size:,}, ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒçª“: {prefetch_window}")
        print(f"   ã‚¢ã‚¯ã‚»ã‚¹æ•°: {n_events:,}")
        
        # å®Ÿè¡Œç¢ºèª
        confirm = input("\nã“ã®è¨­å®šã§å®Ÿè¡Œã—ã¾ã™ã‹ï¼Ÿ (y/N): ").strip().lower()
        if confirm not in ['y', 'yes']:
            print("å®Ÿè¡Œã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸã€‚")
            return
        
        # å°è¦æ¨¡ãƒˆãƒ¬ãƒ¼ã‚¹ç”Ÿæˆ
        print("\nãƒˆãƒ¬ãƒ¼ã‚¹ç”Ÿæˆä¸­...")
        trace = TraceGenerator.generate_synthetic_trace(
            n_events=n_events,
            num_files=20,
            avg_file_length_blocks=50,
            sequential_prob=0.6,
            jump_prob=0.15
        )
        
        # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
        print("ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œä¸­...")
        start_time = time.time()
        results = run_clump_simulation(
            trace=trace,
            chunk_size=chunk_size,
            cluster_size=cluster_size,
            cache_size=cache_size,
            prefetch_window=prefetch_window
        )
        execution_time = time.time() - start_time
        
        # çµæœè¡¨ç¤º
        print_evaluation_results(results)
        print(f"\nâ±ï¸ å®Ÿè¡Œæ™‚é–“: {execution_time:.2f}ç§’")
        
    except (ValueError, KeyboardInterrupt):
        print("\nâš ï¸ å…¥åŠ›ã‚¨ãƒ©ãƒ¼ã¾ãŸã¯ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸã€‚")


if __name__ == "__main__":
    # å†ç¾å¯èƒ½ãªçµæœã®ãŸã‚ä¹±æ•°ã‚·ãƒ¼ãƒ‰ã‚’å›ºå®š
    random.seed(42)
    
    print("CluMP ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ï¼ˆè¦ä»¶å®šç¾©æ›¸æº–æ‹ ç‰ˆï¼‰")
    print("=" * 60)
    
    print("\nå®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠã—ã¦ãã ã•ã„:")
    print("1. æ¨™æº–ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆè¨­å®šå¯èƒ½ï¼‰")
    print("2. ã‚«ã‚¹ã‚¿ãƒ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å®Ÿé¨“ï¼ˆç°¡æ˜“ç‰ˆï¼‰")
    print("3. ãƒ‡ãƒ¢å®Ÿè¡Œï¼ˆå›ºå®šè¨­å®šï¼‰")
    
    try:
        mode = input("\né¸æŠã—ã¦ãã ã•ã„ (1-3, ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1): ").strip()
        
        if mode == "2":
            run_custom_simulation()
        elif mode == "3":
            # ãƒ‡ãƒ¢å®Ÿè¡Œ
            print("\nğŸ® ãƒ‡ãƒ¢å®Ÿè¡Œï¼ˆå›ºå®šè¨­å®šï¼‰")
            trace = TraceGenerator.generate_synthetic_trace(
                n_events=25000,
                num_files=40,
                avg_file_length_blocks=100,
                sequential_prob=0.6,
                jump_prob=0.1
            )
            print(f"ãƒˆãƒ¬ãƒ¼ã‚¹ç”Ÿæˆå®Œäº†: {len(trace)} ã‚¢ã‚¯ã‚»ã‚¹")
            print("CluMPã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œä¸­...")
            
            results = run_clump_simulation(
                trace=trace,
                chunk_size=16,
                cluster_size=32,
                cache_size=4096,
                prefetch_window=16
            )
            print_evaluation_results(results)
        else:
            # ãƒ¢ãƒ¼ãƒ‰1: æ¨™æº–ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
            config = get_simulation_config()
            print_config_summary(config)
            
            # å®Ÿè¡Œç¢ºèª
            print("\n" + "=" * 60)
            confirm = input("ã“ã®è¨­å®šã§å®Ÿè¡Œã—ã¾ã™ã‹ï¼Ÿ (y/N): ").strip().lower()
            if confirm not in ['y', 'yes']:
                print("å®Ÿè¡Œã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸã€‚")
                exit()
            
            print("\nåˆæˆãƒˆãƒ¬ãƒ¼ã‚¹ã‚’ç”Ÿæˆä¸­...")
            trace = TraceGenerator.generate_synthetic_trace(**config["trace"])
            print(f"ãƒˆãƒ¬ãƒ¼ã‚¹ç”Ÿæˆå®Œäº†: {len(trace)} ã‚¢ã‚¯ã‚»ã‚¹")
            print("CluMPã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œä¸­...")
            
            start_time = time.time()
            results = run_clump_simulation(trace=trace, **config["clump"])
            execution_time = time.time() - start_time
            
            # çµæœè¡¨ç¤º
            print_evaluation_results(results)
            print(f"\nâ±ï¸ å®Ÿè¡Œæ™‚é–“: {execution_time:.2f}ç§’")
            
    except KeyboardInterrupt:
        print("\n\nå®Ÿè¡Œã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸã€‚")
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    
    print("\nğŸ‰ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº†ï¼")
