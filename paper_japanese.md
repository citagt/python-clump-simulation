# CluMP: ストレージI/Oプリフェッチのためのクラスタ化マルコフ連鎖

**著者:** Sungmin Jung, Hyeonmyeong Lee, Heeseung Jo

## 概要

CPUとストレージ技術の進歩により、タスクの処理速度は向上している。しかし、ディスクとメモリ間のデータ転送速度は相対的に低下している。その結果、I/O処理速度の問題は、I/O集約的なタスクにおいて重要な懸念事項となっている。本研究論文では、クラスタ化マルコフ連鎖を使用してプロセス内で要求される次のブロックを予測するCluMPを提案する。Linuxシステムで一般的に使用される単純な先読みアプローチと比較して、CluMPはより正確にプリフェッチを予測し、予測プロセスに必要なメモリを削減できる。CluMPは、KVMワークロードにおいて先読みと比較して最大191.41%のメモリヒット率向上を実証し、Linuxカーネルビルドワークロードにおいても最大130.81%の改善を達成した。さらに、CluMPは複数のパラメータを組み込むことで、ユーザーの目的や使用されるワークロードに対する適応性の利点を提供し、様々なワークロードパターンにわたって最適なパフォーマンスを可能にする。

**キーワード:** プリフェッチ; マルコフ連鎖; データ予測; ディスクI/O

# 1. はじめに

ストレージデバイスの容量とCPUの処理能力は着実に向上している。しかし、ディスクI/Oシステムの帯域幅とアクセス時間の性能は大幅な進歩を見せていない。その結果、CPUとディスクI/Oシステム間の性能格差は拡大している。RAIDなどのディスクアレイは全体的なI/Oスループットを向上させることができるが、機械的動作による長いランダムアクセス待機時間に依然として悩まされている。メインメモリを利用するディスクバッファとキャッシュ層は待機時間を削減できるが、頻繁なキャッシュミスを伴うワークロードでは、アクセス時間の改善は限定的である。その結果、ボトルネックを防ぎ、ディスクI/O集約的なタスクを処理する際の性能を向上させるためのオペレーティングシステムレベルのサポートを提供する広範な研究が行われてきた。

Linuxカーネルは、ディスクデータのキャッシュとしてメモリを管理するプリフェッチやページングなどの技術を通じてディスクI/O操作をサポートしている。プリフェッチとは、ディスクアクセスの待機時間を短縮するために、ディスクデータを事前にメモリキャッシュに読み込む技術を指す。メモリでキャッシュミスが発生すると、ディスクからデータを取得するのに相当な時間がかかる。プリフェッチは、要求されるデータを予測し、実際のアクセスが発生する前にそれをメモリに事前に読み込むことを目的とし、それによってI/O時間を短縮する。プリフェッチが効果的であるためには、適切なタイミングで最小限のオーバーヘッドで要求されるデータを正確に予測することが重要である。プリフェッチ技術は、キャッシュ汚染やメモリ帯域幅要件の増加などの二次的な影響を考慮する必要がある。これらの課題にもかかわらず、プリフェッチは計算とI/Oアクセスを重複させることで、全体的なプログラム実行時間を大幅に改善できる。より効果的にプリフェッチを実行するアルゴリズムを提案する多数の研究が行われてきた。

Linuxカーネルでは、プリフェッチ技術の一つとして単純な逐次先読みアルゴリズムが使用されている。Linux先読みアルゴリズムは、ブロックに逐次的にアクセスする操作に対して大幅な性能向上を実証している。しかし、Linux先読みアルゴリズムは、データに非逐次的にアクセスするワークロードに対しては実際に性能を劣化させる可能性がある。これは、不要なデータをメモリに読み込み、その結果メモリの浪費を引き起こすという脆弱性を持っている。

実際、オペレーティングシステムのカーネルは例外と割り込みを迅速に処理する必要がある。この要件のため、I/O処理サポートに深層学習などの複雑な予測モデルを使用することは実現可能ではない。カーネルの焦点は、計算集約的な予測モデルを展開するよりも、例外と割り込みの効率的で応答性の高い処理を維持することにある。したがって、マルコフ連鎖などのよりシンプルで軽量な予測モデルの使用が、オペレーティングシステムカーネルにおけるI/O関連タスクにより適している。オペレーティングシステムカーネル内での予測のオーバーヘッドは、実用的に実現可能であるために最小限である必要がある。本論文では、要求される次のブロックを予測するために軽量な予測モデルであるマルコフ連鎖が採用された。論文では、マルコフ連鎖のサイズを調整することでメモリオーバーヘッドを最小化し、合理的な時間オーバーヘッドで正確な予測を可能にするClusteredMarkov Chain for Prefetch（CluMP）を提案している。CluMPは、ユーザーのワークロードに適合するようにマルコフ連鎖の数とサイズを調整し、その結果、ブロックにランダムにアクセスする操作に対しても合理的なプリフェッチヒット率を達成する新しいプリフェッチ技術となっている。

論文の残りのセクションは以下のように構成されている。セクション2では、Linuxとマルコフ連鎖のプリフェッチアルゴリズムに関する背景知識を提供する。セクション3では、本論文で提案されるCluMPの設計、データ構造、動作アルゴリズムについて説明し、セクション4では、CluMPの効果とオーバーヘッドを分析する性能評価を提示する。さらに、セクション5では関連研究を議論し、セクション6では主要な発見と貢献を要約して論文を結論付ける。

# 2. 背景知識

## 2.1. Linux先読みアルゴリズム

Linuxカーネルはバージョン2.4.13以降、ディスクI/O性能を向上させるためにLinux先読みアルゴリズムを導入した。Linux先読みアルゴリズムは、データの逐次性を考慮し、I/O操作が逐次パターンで連続するブロックにアクセスする際に、要求されたブロックを含む一連のブロックをディスクからメモリに事前読み込みする。

Linuxカーネル5.14.0では、プリフェッチアルゴリズムはファイルディスクリプタ（FD）を利用してI/O操作のファイルの開始と終了を識別する。要求されたブロックがメモリに存在せず、ディスクから要求されているブロックが連続している場合、プリフェッチが実行される。カーネルは最初に、将来の連続データの128KBのプリフェッチウィンドウサイズをメモリに読み込む。逐次ブロックの後続要求が持続する場合、プリフェッチウィンドウサイズは段階的に倍増され、より効率的なプリフェッチが可能になる。しかし、その後非逐次読み取りが開始される場合、先読みアルゴリズムはメモリの浪費を削減するためにプリフェッチウィンドウサイズをリセットする。

## 2.2. マルコフ連鎖

マルコフ連鎖（MC）は離散時間確率過程である。マルコフ連鎖は、時間の経過に伴うシステムの状態変化を表現する。各時間ステップで、システムは新しい状態に遷移するか、同じ状態に留まる。これらの状態遷移は遷移として知られている。マルコフ性は、過去と現在の状態が与えられた未来の状態の条件付き確率分布が現在の状態のみによって決定され、過去の状態とは独立であることを述べている。

各現在状態から各状態への遷移回数は、システムが異なる状態間でどのように移動するかを示している。例えば、状態Aから状態Bへの遷移が5回発生し、状態Aから状態Cへの遷移も同様に5回発生した場合、BとCの確率はそれぞれ50%となる。マルコフ状態遷移はマルコフ連鎖（MC）を構成する。各遷移は以前の遷移の累積確率によって決定され、過去の行動から独立している。マルコフ状態遷移確率は、過去の行動に影響されることなく次の状態を決定する。時間の経過とともに遷移が蓄積されると、全体的な確率に対する個別の遷移の影響は減少する。

マルコフ連鎖の確率分布に基づいて、プリフェッチアルゴリズムのディスクI/Oの次のブロックを予測することが効果的になり得る。例えば、ブロックBが要求され、次にブロックCにアクセスする確率が60%、ブロックAにアクセスする確率が40%である場合、ブロックAではなくブロックCをプリフェッチすることがより好ましい選択となる。

# 3. 設計

## 3.1. 概要

LinuxカーネルにおけるLinux先読みアルゴリズムは、逐次アクセスパターンに対してのみ効果的に動作するという重要な制限を抱えている。これは、I/O要求が非逐次動作を示す場合にプリフェッチが全くトリガーされないことを意味し、ランダムアクセスパターンを持つワークロードに対して大幅な性能劣化を引き起こす。さらに、もう一つの制約は128KBの固定プリフェッチウィンドウサイズであり、調整はこのサイズの倍数に限定される。持続的な逐次アクセスによりプリフェッチウィンドウサイズが増加するが、その後非逐次アクセスが発生する場合に顕著な欠点が生じる。このような場合、プリフェッチされた大量のデータが不要になり、大幅なメモリの浪費が生じる。Linux先読みアルゴリズムのこれらの制限は、多様なI/Oアクセスパターンを効率的に処理する能力を妨げている。その結果、これらの課題に対処し、逐次と非逐次の両方のアクセスパターンを含むシナリオでプリフェッチ性能を最適化するための代替アプローチまたは強化が必要である。

一般的に、Least Recently Used（LRU）と呼ばれる広く使用されている予測手法を考慮すると、ディスクI/O要求が過去の要求の順序に従うことを予測することが可能である。しかし、ディスク全体でLRUを維持することは大幅なオーバーヘッドを発生させ、実用的ではない。CluMPは、要求される次のブロックを予測するためにMCを利用するように設計されている。したがって、ブロックが読み取られる際、CluMPは、MCに基づいて最も頻繁に要求される次のブロックが要求されることを予測する。

一つの注目すべき問題は、ディスク全体のMCを構築する場合にメモリ内で大量のデータを維持する必要があることである。例えば、4KBブロックを持つ4GBディスクを仮定すると、100万×100万の配列が必要になる。このような要件は実用的ではないと考えられる。さらに、ディスクサイズが増加するにつれて、必要なMCのサイズも比例して増大する。

実際には、ディスク上のすべてのブロックが有効なデータを含んでいるわけではなく、有効なブロックの中でも、ワークロードによってアクティブに使用されるのは小さな部分のみである。したがって、すべてのブロックに対してMCを事前に構築し維持することは非効率的である。CluMPでは、MCを複数のセグメントに分割し、ディスク全体を対象とすることでこの問題に対処することを目的としている。これらのセグメント化されたMCは、多段ページテーブル技術と同様に、必要に応じて動的に作成・管理でき、オーバーヘッドを大幅に削減する。

## 3.2. 構造

CluMPで採用されるMCの構造は、必要なMCフラグメントを動的に管理するためにチャンクとクラスタの概念を導入している。従来のMCモデルでは、Nブロックを持つディスクに対してN×Nの2次元データ空間が必要である。しかし、ディスクなどのスパースなMCでは、N×N空間の大部分が未使用のままである。したがって、CluMPはチャンクとクラスタを利用して、それを適切にスライスすることでN×N空間の必要な部分のみを効率的に管理・維持する。

チャンクはディスクブロックのセットを表す。CluMPはチャンクを利用して多数のブロックを効率的に管理し、メモリの浪費を防ぐ。チャンクサイズは、単一のチャンク内に含まれるディスクブロックの数を指す。

クラスタはMCフラグメントのセットを表し、各クラスタは複数のチャンクに対応する。クラスタサイズは、単一のクラスタに関連付けられたチャンクの数を示す。要求されるデータを予測するためのマルコフ連鎖を維持するために、クラスタ化されたMCは、特定の瞬間を対象とし、クラスタサイズに等しい数のチャンクを含んで、メモリ内に選択的にインスタンス化される。このアプローチは、必要なクラスタ化されたMCのみをメモリ内に保持することで効率的なメモリ利用を可能にする。

## 3.3. MCクラスタの管理

従来のMCは、ブロック数の二乗に比例するデータを必要とし、各行はブロック数と等しい列数を必要とする。このオーバーヘッドを最小化するため、CluMPは6つのフィールドで次のチャンクを予測するMCの各行を構造化することで縮小表現を採用している。この設計選択により、CluMPは今後のディスクI/O要求を予測するために最も可能性の高い次のブロックのみを維持・管理できる。

ディスク上の総ブロック数をB_total、チャンクのサイズをCH_size、クラスタのサイズをCL_sizeとすると、総必要メモリサイズは以下のように計算できる：

CH_total（チャンクの総数）= B_total / CH_size
CL_total（クラスタの総数）= CH_total / CL_size
Mem_required（最大メモリ使用量）= CL_total × 24B × CL_size

ここで、24Bは各クラスタ行の情報を格納するために必要なサイズ（6フィールド×4B）を表す。実際、CluMPではすべてのクラスタが事前割り当てされるわけではないため、実際のメモリ使用量はMem_requiredよりもはるかに小さい。クラスタは必要な時にのみ割り当て・維持されるため、CluMPは必要に応じて動的にメモリを割り当て、メモリ使用をはるかに効率的にする。実際のメモリ利用率は、CluMPによって処理されるワークロードの特性によって異なる。

マルコフ連鎖の各行は次のチャンクにアクセスする確率を表し、C1からCN1、CN2、CN3（CNxと呼ばれる）は次にアクセスされる可能性が最も高いチャンク番号を示す。P1、P2、P3（Pxと呼ばれる）は対応するチャンクCNxにアクセスする頻度を示す。CN1は最も多くアクセスされたチャンク番号を保持し、CN2は2番目に多くアクセスされたチャンク番号を表し、CN3は最も最近アクセスされたブロック番号を格納する。さらに、CN3はソート目的のバッファとしても機能する。

各I/Oアクセスにより、Pxの値が更新され、CNx値の並び替えが行われる。複数のPx値が等しい場合、最も最近更新された値が次にアクセスされる確率が高いと見なされる。例えば、行C1が情報を保持し、後続のアクセスがC2である場合、P2の値は1だけ増加し、3に変更される。このシナリオでは、P1とP2が同じ値を持つが、最も最近更新されたCN2に格納されたチャンク値がCN1のチャンク値と交換され、CN1の以前の値がCN2に割り当てられる。

MC行は、ブロックアクセス要求の発生ごとに更新される。CNxとPx値には以前に要求されたチャンクの記録が含まれ、CNxにまだ存在しないチャンクに対する新しいI/O要求がある場合、既存のCN3とP3はそれぞれ最近アクセスされたチャンク番号と1で初期化される。MC内の要求されたブロックを含むチャンクの既存の記録がある場合、対応するPx値が1増加される。各要求でのソートにより、CN1は常にそのチャンク内で次にアクセスされる確率が最も高いブロック番号を格納する。プリフェッチ目的では、CluMPは常にCN1を参照し、それを使用して次のI/O要求を予測する。

CluMPで予測されたチャンクが決定されると、ユーザーが定義できるプリフェッチウィンドウサイズでプリフェッチが実行される。MCを利用するCluMPの注目すべき特徴の一つは、LinuxのRA機構とは異なり、プリフェッチウィンドウサイズの動的調整を必要とせずに効率的にプリフェッチを実行する能力である。

一つの読み取り操作に対するCluMPの動作シーケンスは以下の通りである：

1. ディスクI/O読み取り操作が要求される。
2. 操作は要求されたディスクブロックがメモリに存在するかチェックする。要求されたデータがメモリにある場合、マルコフ連鎖の存在を確認し、情報を作成または更新する。
3. 要求されたデータがメモリに存在しない場合、ディスクからの読み取りを要求する。
4. ディスクから対応するデータを取得し、メモリに読み込む。
5. データに対する既存のマルコフ連鎖があるかチェックする。
6. 予測されたマルコフ連鎖が存在する場合、対応するチャンク番号の情報を更新する。
7. 更新されたマルコフ連鎖の予測を使用して、プリフェッチウィンドウサイズのプリフェッチ読み取りを実行する。
8. マルコフ連鎖が存在しない場合、利用可能な情報を使用して新しいものを作成する。

# 4. 評価

このセクションでは、既存のLinux先読みアルゴリズムと比較してCluMPの性能を評価することを目的としている。比較に使用されたLinuxカーネルバージョンは5.4.0である。この性能評価の主な目的は以下の通りである：

• プリフェッチのヒット率：Linux先読みアルゴリズムに対してCluMPが達成したキャッシュヒット率の改善を比較した。KVM仮想マシンの起動やLinuxカーネルのビルドなどの実際のワークロードを分析に使用した。CluMPとLinux先読みアルゴリズム間のキャッシュヒット率を比較することで性能を評価した。

• CluMPオーバーヘッドの分析：CluMPはMCの維持と更新によるオーバーヘッドを導入する。CluMPが提供する性能向上に関連してCluMPが発生するオーバーヘッドを分析した。この分析により、性能改善とCluMPによって導入される追加的なオーバーヘッド間のトレードオフを理解するのに役立った。

• パラメータによる性能変動：チャンクサイズ、クラスタサイズ、プリフェッチウィンドウサイズなどの異なるパラメータを調整することで、性能変動とミスプリフェッチおよびメモリ効率に対する影響を分析した。この分析を通じて、改善された性能とメモリ効率をもたらす最適なパラメータ値を特定することを目指した。

この性能評価を実施することで、CluMPが達成したキャッシュヒット率の改善に関する洞察を得て、CluMPに関連するオーバーヘッドを分析し、Linux先読みアルゴリズムと比較したCluMPの性能に対する異なるパラメータ構成の効果を確認しようとした。

正確なプリフェッチヒット/ミス比を得るために、SSD環境でのワークロード実行中に収集されたディスクI/Oログを利用した。これらのログは性能評価目的で利用された。ログに基づくシミュレーションにより、キャッシュヒット率とメモリ使用量を正確に決定することができた。さらに、CluMPに関連するメモリオーバーヘッドを正確に測定することができた。

## 4.1. ワークロード

性能を評価するために、実世界のシナリオを反映するワークロードを構築した。以下のワークロードが使用された：

• カーネルベース仮想マシン（KVM）起動：仮想マシンの起動プロセス中に、iosnoopを使用して要求されたブロック番号をトレースし、ログを記録した。CluMPはこれらのログを利用してマルコフ連鎖（MC）を作成し、生成されたブロックシーケンスに基づいてメモリへのブロックのプリフェッチを実行した。ヒット率とミス率を測定し、Linuxの先読みアルゴリズムの結果と比較した。KVMワークロードによって要求されたディスク使用量は42.53MBであった。

• Linuxカーネルビルド：makeツールを使用してLinuxカーネルのビルド中にブロックログを記録した。負荷を導入し、非連続ブロックにアクセスするために、同時に2つの異なるLinuxカーネルをビルドした。ログファイルから作成されたMCを使用するCluMPのヒット率とミス率を、従来のLinux実装の先読みアルゴリズムと比較した。2つのLinuxカーネルをビルドするワークロードサイズは7.96GBであった。

## 4.2. プリフェッチのヒット率

KVM起動ワークロードとLinuxカーネルビルドワークロードを使用したCluMPとLinux先読みアルゴリズム（デフォルト）間のメモリヒット率の比較では、大幅な改善が示されている。Linux先読みアルゴリズムのメモリヒット率は、各ワークロードでそれぞれ41.39%と59%であった。対照的に、CluMPは最大メモリヒット率79.224%と77.252%をそれぞれ達成し、これは1.91倍と1.31倍の改善を表している。CluMPのヒット率はチャンクサイズとクラスタサイズに応じて多少の変動を示したが、全体的にLinux先読みアルゴリズムを一貫して上回った。

ヒット率は、クラスタサイズよりもチャンクサイズによってより影響を受ける。クラスタサイズはメモリに読み込まれるMCフラグメントのサイズを決定するため、ヒット率に対する影響は軽微である。一方、連続するディスクブロックセットのサイズに対応するチャンクサイズは、ヒット率に直接影響する。

## 4.3. ミスプリフェッチの比較

ミスプリフェッチとは、プリフェッチアルゴリズムとメカニズムに基づいてディスクからメモリにプリフェッチされたが、実際には利用されなかったブロックを指す。Linux先読みとCluMPアルゴリズムを使用してプリフェッチされた未使用ブロックの量は、チャンクサイズの増加により、一度により大量のデータがプリフェッチされ、その結果、ワークロードによって元々要求されていないブロックを含む発生率が高くなる可能性があることを示している。

256と512のチャンクサイズを除外すると、CluMPは大幅に低いレベルのミスプリフェッチを示した。256と512のチャンクサイズは評価目的で含まれたが、実用的な使用には適していないと考えられる。ミスプリフェッチデータはメモリに読み込まれたが未使用のままであり、その結果不要なメモリ消費が生じた。Linux先読みと比較して大幅に少ないミスプリフェッチを生成することで、CluMPはその優位性を実証した。CluMPは従来の先読みアプローチと比較してミスプリフェッチ量の削減を可能にした。

## 4.4. MCのメモリオーバーヘッド

クラスタとチャンクサイズを変化させながらワークロード実行中に使用されたMCの累積サイズは、CluMPがプリフェッチを実行する際に、要求されるブロックを予測するためにMCフラグメントをメモリ内に維持する必要があることを示している。このサイズは、ワークロードによって利用されるブロックのワーキングセットのサイズに直接比例する。

チャンクサイズが増加すると、次にアクセスされるブロックを予測するMCの精度はより精密でなくなる。これにより、使用されるMCフラグメントの数が増加する。しかし、各MCフラグメントは比較的小さなサイズを持つため、MCの全体的なメモリ消費は総ワークロードサイズと比較して控えめなままである。MCフラグメント数の増加にもかかわらず、キャッシュヒット率の改善におけるCluMPプリフェッチの効果は実質的であった。したがって、チャンクサイズを慎重に調整することで、MCによって提供されるプリフェッチヒット率の大幅な改善の恩恵を受けながら、効率的なメモリ利用を達成することが可能であった。

さらに、CluMPのクラスタサイズが増加すると、単一のクラスタ化されたMCに含まれるチャンクの数も増加した。これにより、メモリ内でMCを維持するコストが削減された。したがって、プリフェッチヒット率、ミスプリフェッチ率、メモリオーバーヘッドを考慮すると、より小さなチャンクサイズとより大きなクラスタサイズを使用することが実際により合理的で有益であると推論できる。

# 5. 議論

CluMPは2つの側面でオーバーヘッドを導入する可能性がある。第一に、メモリ内でMCフラグメントを管理するためのメモリ空間が必要である。しかし、このオーバーヘッドは比較的小さく、セクション4.4で提示された実験結果によって実証されているように、従来のMCモデルと比較して無視できると考えることができる。第二のオーバーヘッドは、MCフラグメントの管理と更新に必要な計算に関連している。それにもかかわらず、CluMPでMCフラグメントを管理する計算オーバーヘッドは最小限であり、各ディスクI/O要求に対してMC内のデータを更新する単一の計算を含む。計算複雑度はO(1)であり、実際の計算オーバーヘッドは重要ではなく無視できることを示している。

本論文では、実験結果は主にCluMPの短期データの分析に焦点を当てている。しかし、CluMPが長期ワークロードでも堅牢な性能を示すことを予期することは合理的である。この期待は、MCが継続的に記録し、その構造内で長期ワークロードパターンを保持するMCの固有の特性に起因している。その結果、蓄積された情報により、CluMPは将来のアクセスに対してより正確な予測を行うことができる。

長期実験の時間を要する性質のため、長期データとワークロードパターンの結果は本論文では提示されていないが、これは本研究の制限として認識される可能性がある。この制限に対処し、長期ワークロードでのCluMPの動作に関するさらなる洞察を提供するため、将来の研究では拡張実験と分析を実施することを含む。そうすることで、長期ワークロードを効果的に処理するCluMPの効果性を検証し確立することを目指している。

# 6. 関連研究

現代のプロセッサは、メモリ階層を強化するためにCPUキャッシュを含む様々なハードウェアプリフェッチャを装備している。これらのハードウェアプリフェッチャは、メモリ階層の異なるレベルを対象とするソフトウェアベースのプリフェッチアルゴリズムと連携して動作する。本論文の焦点であるディスクI/O操作を加速するためのいくつかのプリフェッチ研究が実施されている。これらのプリフェッチ技術を活用することで、ディスクI/O操作により高速なサポートを提供し、全体的なシステム性能を向上させることを目的としている。

Zhangらは、大規模プリフェッチを通じてI/O操作の処理速度を向上させながらDRAMのメモリ制約を緩和することを目的とした技術であるiTransformerを提案した。小型SSDを不揮発性メモリとして利用することで、同時要求下でも高いディスク効率を維持しながら、ダーティデータに関連する懸念を軽減できた。さらに、iTransformerは、ディスクアクセスに関連するコストをマスクするためにバックグラウンド要求スケジューリングを採用している。

Bhatiaらは、ベースラインプリフェッチアプローチの効果を向上させる拡張プリフェッチ技術を議論した。提案された技術は、Perceptron-Based Prefetch Filtering（PPF）と呼ばれ、精度に悪影響を与えることなくプリフェッチの範囲を拡大した。これは、不正確なプリフェッチをフィルタリングすることで達成された。PPFは、不正確なプリフェッチを識別するためにパーセプトロン層を訓練し、それによってフィルタリングプロセスの精度を向上させる。

プリフェッチにマルコフ連鎖を利用する以前の試みがあった。例えば、Lagaらは、すべてのページに対してマルコフ状態マシンを作成し、プロセスによって要求される次のページを予測するためにマルコフ連鎖を使用した。彼らは、すべてのページ-ページペアに対してマルコフ状態値を維持し、オーバーフィッティング問題に対処するために状態値が特定の閾値に達したときにマルコフ連鎖を更新した。しかし、このアプローチは、すべてのページに対してマルコフ状態を維持する必要があるため、大幅なメモリの浪費を引き起こす可能性があった。

対照的に、CluMPは、ページやブロックをグループ化するチャンクとクラスタ構造を活用し、それによってマルコフ連鎖を維持するために必要なメモリ空間のより効率的な利用を可能にする。データをチャンクとクラスタに整理することで、CluMPはマルコフ連鎖維持のメモリ使用を最適化する。

# 7. 結論

本論文では、メモリ利用の効率を向上させ、I/O操作の処理を加速するための新しいソリューションとしてCluMPを提案した。CluMPは、プロセスによって行われたブロック要求を捉えたMCをクラスタに整理し、効果的なプリフェッチを可能にする手法を採用した。注目すべきことに、CluMPは、従来のLinux先読みアルゴリズムと比較して、約8%から91%の範囲でメモリヒット率の注目すべき改善を示した。ブロック予測に利用されるMCのサイズは、より大きなワークロードで増加する可能性があるが、プリフェッチに必要なメモリ空間は全体的なワークロードに比して大幅に小さいままである。したがって、CluMPは、関連する最小限のメモリオーバーヘッドを上回るプリフェッチによってもたらされる実質的な利点を強調している。さらに、CluMP内でのチャンクとクラスタ構造の利用は、MCに必要なメモリフットプリントを実質的に軽減し、CluMPの顕著な利点を構成している。

将来の研究方向として、ファイルディスクリプタを利用してファイルの開始点と終了点を決定することで、実際のカーネルでCluMPの強化版を実装する計画がある。この改善されたCluMP実装は、ワークロードの範囲内にあるブロックのみのプリフェッチを促進し、不要なプリフェッチを回避する。このアプローチによってLinuxカーネルのプリフェッチアルゴリズムを強化することで、I/O処理時間をさらに効果的に削減することが期待される。

## 参考文献

1. Yang, Q.; Ren, J. I-CASH: Intelligently coupled array of SSD and HDD. In Proceedings of the 2011 IEEE 17th International Symposium on High Performance Computer Architecture, San Antonio, TX, USA, 12--16 February 2011; pp. 278--289.

2. Vanderwiel, S.P.; Lilja, D.J. Data prefetch mechanisms. ACM Comput. Surv. (CSUR) 2000, 32, 174--199.

3. Kang, H.; Wong, J.L. To hardware prefetch or not to prefetch? a virtualized environment study and core binding approach. ACM Sigplan Not. 2013, 48, 357--368.

4. He, J.; Sun, X.H.; Thakur, R. Knowac: I/o prefetch via accumulated knowledge. In Proceedings of the 2012 IEEE International Conference on Cluster Computing, Beijing, China, 24--28 September 2012; pp. 429--437.

5. Wu, F.; Xi, H.; Li, J.; Zou, N. Linux readahead: Less tricks for more. In Proceedings of the Linux Symposium, Ottawa, ON, Canada, 27--30 June 2007; Volume 2, pp. 273--284.

6. Laga, A.; Boukhobza, J.; Koskas, M.; Singhoff, F. Lynx: A learning linux prefetching mechanism for ssd performance model. In Proceedings of the 2016 5th Non-Volatile Memory Systems and Applications Symposium (NVMSA), Daegu, Republic of Korea, 17--19 August 2016; pp. 1--6.

7. Lee, C.J.; Mutlu, O.; Narasiman, V.; Patt, Y.N. Prefetch-aware memory controllers. IEEE Trans. Comput. 2011, 60, 1406--1430.

8. Nesbit, K.J.; Smith, J.E. Data cache prefetching using a global history buffer. In Proceedings of the 10th International Symposium on High Performance Computer Architecture (HPCA'04), Madrid, Spain, 14--18 February 2004; p. 96.

9. Kallahalla, M.; Varman, P.J. PC-OPT: Optimal offline prefetching and caching for parallel I/O systems. IEEE Trans. Comput. 2002, 51, 1333--1344.

10. Zhang, X.; Davis, K.; Jiang, S. iTransformer: Using SSD to improve disk scheduling for high-performance I/O. In Proceedings of the 2012 IEEE 26th International Parallel and Distributed Processing Symposium, Shanghai, China, 21--25 May 2012; pp. 715--726.

11. Bhatia, E.; Chacon, G.; Pugsley, S.; Teran, E.; Gratz, P.V.; Jiménez, D.A. Perceptron-based prefetch filtering. In Proceedings of the 46th International Symposium on Computer Architecture, Phoenix, AZ, USA, 22--26 June 2019; pp. 1--13.

12. Joseph, D.; Grunwald, D. Prefetching using markov predictors. IEEE Trans. Comput. 1999, 48, 121--133.

13. Peled, L.; Mannor, S.; Weiser, U.; Etsion, Y. Semantic locality and context-based prefetching using reinforcement learning. In Proceedings of the 42nd Annual International Symposium on Computer Architecture, Portland, OR, USA, 13--17 June 2015; pp. 285--297.

14. Chen, H.; Zhou, E.; Liu, J.; Zhang, Z. An rnn based mechanism for file prefetching. In Proceedings of the 2019 18th International Symposium on Distributed Computing and Applications for Business Engineering and Science (DCABES), Wuhan, China, 8--10 November 2019; pp. 13--16.

15. Hashemi, M.; Swersky, K.; Smith, J.; Ayers, G.; Litz, H.; Chang, J.; Kozyrakis, C.; Ranganathan, P. Learning memory access patterns. In Proceedings of the International Conference on Machine Learning, Stockholm, Sweden, 10--15 July 2018; pp. 1919--1928.