#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CluMP Performance Evaluation Module
è¦ä»¶å®šç¾©æ›¸ã«åŸºã¥ãæ€§èƒ½è©•ä¾¡ã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¯”è¼ƒæ©Ÿèƒ½

æœ¬ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯ã€CluMPã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®åŒ…æ‹¬çš„ãªæ€§èƒ½è©•ä¾¡ã‚’å®Ÿè¡Œã™ã‚‹ãŸã‚ã®ãƒ„ãƒ¼ãƒ«ã‚»ãƒƒãƒˆã§ã™ã€‚
è¤‡æ•°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã®æ¯”è¼ƒå®Ÿé¨“ã€ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ‰‹æ³•ã¨ã®æ¯”è¼ƒã€çµ±è¨ˆåˆ†æã€å¯è¦–åŒ–æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ã€‚

ä¸»è¦æ©Ÿèƒ½:
1. ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¯”è¼ƒå®Ÿé¨“ - ç•°ãªã‚‹chunk_size/cluster_sizeã§ã®æ€§èƒ½æ¸¬å®š
2. ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒ - Linux read-aheadç›¸å½“ã®æ‰‹æ³•ã¨ã®æ¯”è¼ƒ
3. çµ±è¨ˆåˆ†æ - å®Ÿé¨“çµæœã®è©³ç´°åˆ†æã¨æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç‰¹å®š
4. å¯è¦–åŒ–ãƒ¬ãƒãƒ¼ãƒˆ - ã‚°ãƒ©ãƒ•ã‚£ã‚«ãƒ«ãªçµæœè¡¨ç¤ºï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
5. ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ¢ãƒ¼ãƒ‰ - ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ãªè¨­å®šãƒ»å®Ÿè¡Œ

ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£:
    PerformanceEvaluator (ä¸»è¦è©•ä¾¡å™¨)
    â”œâ”€â”€ BaselinePrefetcher (æ¯”è¼ƒç”¨ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³)
    â”œâ”€â”€ CluMPSimulator (clump_simulator.pyã‹ã‚‰)
    â””â”€â”€ CluMPVisualizer (visualization.pyã‹ã‚‰ã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³)

ä½¿ç”¨ä¾‹:
    # åŸºæœ¬çš„ãªæ¯”è¼ƒå®Ÿé¨“
    evaluator = PerformanceEvaluator()
    results = evaluator.compare_parameters(trace, [4, 8, 16], [16, 32, 64])
    analysis = evaluator.analyze_results(results)
    
    # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒ
    comparison = evaluator.compare_with_baseline(trace, best_params)
"""

import sys
import os
import logging
import time
import statistics
import random
from typing import List, Dict, Any, Tuple, Optional, Union

# ãƒ‘ã‚¹è¨­å®š
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# CluMPã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ã®å…¨æ©Ÿèƒ½ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from clump_simulator import *

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# å¯è¦–åŒ–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
try:
    from visualization import CluMPVisualizer
    VISUALIZATION_AVAILABLE = True
except ImportError:
    VISUALIZATION_AVAILABLE = False
    print("è­¦å‘Š: å¯è¦–åŒ–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ã‚°ãƒ©ãƒ•ç”Ÿæˆã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™ã€‚")


class BaselinePrefetcher:
    """
    ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒç”¨ã®ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ—ãƒªãƒ•ã‚§ãƒƒãƒãƒ£
    Linux read-aheadã®ç°¡æ˜“å®Ÿè£…
    
    ã“ã®å®Ÿè£…ã¯ã€å¾“æ¥ã®Linux read-aheadæ©Ÿèƒ½ã‚’æ¨¡æ“¬ã—ãŸãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ‰‹æ³•ã§ã™ã€‚
    é †æ¬¡ã‚¢ã‚¯ã‚»ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡ºã—ãŸéš›ã«ã€ä¸€å®šæ•°ã®å¾Œç¶šãƒ–ãƒ­ãƒƒã‚¯ã‚’å…ˆèª­ã¿ã—ã¾ã™ã€‚
    
    ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ æ¦‚è¦:
    1. ã‚¢ã‚¯ã‚»ã‚¹å‡¦ç†: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆ/ãƒŸã‚¹åˆ¤å®š
    2. é †æ¬¡æ¤œå‡º: å‰å›ã‚¢ã‚¯ã‚»ã‚¹ã®+1ç•ªãƒ–ãƒ­ãƒƒã‚¯ã‹ãƒã‚§ãƒƒã‚¯
    3. å…ˆèª­ã¿å®Ÿè¡Œ: é †æ¬¡ã®å ´åˆã€readahead_sizeåˆ†ã ã‘å…ˆèª­ã¿
    4. LRUç®¡ç†: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ç½®æ›ã¯é€šå¸¸ã®LRUæ–¹å¼
    
    CluMPã¨ã®é•ã„:
    - å­¦ç¿’æ©Ÿèƒ½ãªã—ï¼ˆãƒãƒ«ã‚³ãƒ•é€£é–ãªã—ï¼‰
    - å˜ç´”ãªé †æ¬¡æ¤œå‡ºã®ã¿
    - å›ºå®šã‚µã‚¤ã‚ºã®å…ˆèª­ã¿
    - ãƒ¡ãƒ¢ãƒªã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã»ã¼ã‚¼ãƒ­
    
    Attributes:
        cache (LRUCache): ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        readahead_size (int): å…ˆèª­ã¿ã‚µã‚¤ã‚ºï¼ˆãƒ–ãƒ­ãƒƒã‚¯æ•°ï¼‰
        total_accesses (int): ç·ã‚¢ã‚¯ã‚»ã‚¹æ•°
        cache_hits (int): ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆæ•°
        last_block (Optional[int]): å‰å›ã‚¢ã‚¯ã‚»ã‚¹ã—ãŸãƒ–ãƒ­ãƒƒã‚¯ID
        
    Example:
        >>> baseline = BaselinePrefetcher(cache_size_blocks=4096, readahead_size=8)
        >>> for block_id in trace:
        ...     hit = baseline.process_access(block_id)
        >>> metrics = baseline.get_evaluation_metrics()
        >>> print(f"ãƒ’ãƒƒãƒˆç‡: {metrics['hit_rate']:.3f}")
    """
    
    def __init__(self, cache_size_blocks: int, readahead_size: int = 8):
        """
        ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒãƒ£ã‚’åˆæœŸåŒ–
        
        Args:
            cache_size_blocks (int): ã‚­ãƒ£ãƒƒã‚·ãƒ¥å®¹é‡ï¼ˆãƒ–ãƒ­ãƒƒã‚¯æ•°ï¼‰
            readahead_size (int): å…ˆèª­ã¿ã‚µã‚¤ã‚ºï¼ˆãƒ–ãƒ­ãƒƒã‚¯æ•°ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 8ï¼‰
            
        Raises:
            ValueError: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒä¸æ­£ãªå ´åˆ
            
        Note:
            readahead_sizeã¯é€šå¸¸4-32ã®ç¯„å›²ã§è¨­å®šã—ã¾ã™ã€‚
            å¤§ãã™ãã‚‹ã¨ç„¡é§„ãªãƒ—ãƒªãƒ•ã‚§ãƒƒãƒãŒå¢—åŠ ã—ã€åŠ¹ç‡ãŒä½ä¸‹ã—ã¾ã™ã€‚
        """
        if cache_size_blocks <= 0:
            raise ValueError(f"cache_size_blocks must be positive, got {cache_size_blocks}")
        if readahead_size <= 0:
            raise ValueError(f"readahead_size must be positive, got {readahead_size}")
            
        self.cache: LRUCache = LRUCache(cache_size_blocks)
        self.readahead_size: int = readahead_size
        self.total_accesses: int = 0
        self.cache_hits: int = 0
        self.last_block: Optional[int] = None
        
        logging.debug(f"BaselinePrefetcher initialized: cache_size={cache_size_blocks}, "
                     f"readahead_size={readahead_size}")
    
    def process_access(self, block_id: int) -> bool:
        """
        ã‚¢ã‚¯ã‚»ã‚¹å‡¦ç†ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ãªé †æ¬¡å…ˆèª­ã¿ï¼‰
        
        Linux read-aheadã®å‹•ä½œã‚’æ¨¡æ“¬:
        1. ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¢ã‚¯ã‚»ã‚¹ç¢ºèª
        2. ãƒŸã‚¹æ™‚ã¯ãƒ–ãƒ­ãƒƒã‚¯èª­ã¿è¾¼ã¿
        3. é †æ¬¡ã‚¢ã‚¯ã‚»ã‚¹æ¤œå‡ºæ™‚ã«å…ˆèª­ã¿å®Ÿè¡Œ
        
        Args:
            block_id (int): ã‚¢ã‚¯ã‚»ã‚¹å¯¾è±¡ã®ãƒ–ãƒ­ãƒƒã‚¯ID
            
        Returns:
            bool: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆã—ãŸã‹ã©ã†ã‹
            
        Raises:
            ValueError: block_idãŒè² ã®å€¤ã®å ´åˆ
            
        Note:
            é †æ¬¡ã‚¢ã‚¯ã‚»ã‚¹ã¯ã€Œå‰å›ã‚¢ã‚¯ã‚»ã‚¹ + 1ã€ã§åˆ¤å®šã—ã¾ã™ã€‚
            ã‚ˆã‚Šè¤‡é›‘ãªé †æ¬¡æ€§æ¤œå‡ºï¼ˆé€£ç¶šã—ãŸè¤‡æ•°ã‚¢ã‚¯ã‚»ã‚¹ï¼‰ã¯å®Ÿè£…ã—ã¦ã„ã¾ã›ã‚“ã€‚
        """
        if block_id < 0:
            raise ValueError(f"block_id must be non-negative, got {block_id}")
            
        self.total_accesses += 1
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¢ã‚¯ã‚»ã‚¹ç¢ºèª
        cache_hit = self.cache.access(block_id)
        
        if cache_hit:
            self.cache_hits += 1
            return True
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹: ãƒ–ãƒ­ãƒƒã‚¯ã‚’èª­ã¿è¾¼ã¿
        self.cache.insert(block_id, is_prefetch=False)
        
        # é †æ¬¡ã‚¢ã‚¯ã‚»ã‚¹ã®å ´åˆã€å…ˆèª­ã¿å®Ÿè¡Œ
        # Linux read-aheadã§ã¯ã€é€£ç¶šã™ã‚‹è¤‡æ•°ã®ã‚¢ã‚¯ã‚»ã‚¹ã§é †æ¬¡æ€§ã‚’åˆ¤å®šã™ã‚‹ãŒã€
        # ã“ã“ã§ã¯ç°¡ç•¥åŒ–ã—ã¦å‰å›+1ã®ã‚¢ã‚¯ã‚»ã‚¹ã§é †æ¬¡ã¨åˆ¤å®š
        if self.last_block is not None and block_id == self.last_block + 1:
            try:
                for i in range(1, self.readahead_size + 1):
                    # å…ˆèª­ã¿ãƒ–ãƒ­ãƒƒã‚¯ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«æŒ¿å…¥
                    # ã“ã“ã§ã¯ãƒ–ãƒ­ãƒƒã‚¯IDãŒç¯„å›²å¤–ã«ãªã‚‹å¯èƒ½æ€§ã¯è€ƒæ…®ã—ãªã„
                    # ï¼ˆå®Ÿéš›ã®ã‚·ã‚¹ãƒ†ãƒ ã§ã¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºåˆ¶é™ãªã©ã§åˆ¶å¾¡ã•ã‚Œã‚‹ï¼‰
                    self.cache.insert(block_id + i, is_prefetch=True)
            except Exception as e:
                logging.warning(f"Prefetch failed for block {block_id}: {e}")
        
        self.last_block = block_id
        return False
    
    def get_evaluation_metrics(self) -> Dict[str, Any]:
        """
        è©•ä¾¡æŒ‡æ¨™ã‚’å–å¾—
        
        CluMPã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ã¨åŒã˜å½¢å¼ã®æŒ‡æ¨™ã‚’è¿”ã—ã¾ã™ã€‚
        ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ‰‹æ³•ãªã®ã§ã€memory_usage_mc_rowsã¯å¸¸ã«0ã§ã™ã€‚
        
        Returns:
            Dict[str, Any]: è©•ä¾¡æŒ‡æ¨™è¾æ›¸
                - total_accesses: ç·ã‚¢ã‚¯ã‚»ã‚¹æ•°
                - cache_hits: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆæ•°
                - hit_rate: ãƒ’ãƒƒãƒˆç‡ (0.0-1.0)
                - prefetch_total: ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒç·æ•°
                - prefetch_used: ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒä½¿ç”¨æ•°
                - prefetch_unused_evicted: æœªä½¿ç”¨ã§é€€é¿ã•ã‚ŒãŸãƒ—ãƒªãƒ•ã‚§ãƒƒãƒæ•°
                - prefetch_efficiency: ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒåŠ¹ç‡ (0.0-1.0)
                - memory_usage_mc_rows: MCè¡Œæ•°ï¼ˆãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã§ã¯0ï¼‰
                
        Note:
            division by zeroã‚’é¿ã‘ã‚‹ãŸã‚ã€åˆ†æ¯ãŒ0ã®å ´åˆã¯0.0ã‚’è¿”ã—ã¾ã™ã€‚
        """
        try:
            prefetch_stats = self.cache.get_prefetch_stats()
            hit_rate = (self.cache_hits / self.total_accesses) if self.total_accesses > 0 else 0.0
            prefetch_efficiency = (prefetch_stats["prefetch_used"] / 
                                 prefetch_stats["prefetch_total"]) if prefetch_stats["prefetch_total"] > 0 else 0.0
            
            return {
                "total_accesses": self.total_accesses,
                "cache_hits": self.cache_hits,
                "hit_rate": hit_rate,
                "prefetch_total": prefetch_stats["prefetch_total"],
                "prefetch_used": prefetch_stats["prefetch_used"],
                "prefetch_unused_evicted": prefetch_stats["prefetch_unused_evicted"],
                "prefetch_efficiency": prefetch_efficiency,
                "memory_usage_mc_rows": 0  # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¯MCRowã‚’ä½¿ç”¨ã—ãªã„
            }
        except Exception as e:
            logging.error(f"Failed to get evaluation metrics: {e}")
            return {"error": str(e)}


class PerformanceEvaluator:
    """
    æ€§èƒ½è©•ä¾¡å™¨
    è¦ä»¶å®šç¾©æ›¸ã«åŸºã¥ãåŒ…æ‹¬çš„ãªæ€§èƒ½è©•ä¾¡ã‚’å®Ÿè¡Œ
    
    æœ¬ã‚¯ãƒ©ã‚¹ã¯ã€CluMPã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®æ€§èƒ½ã‚’å¤šè§’çš„ã«è©•ä¾¡ã™ã‚‹ãŸã‚ã®ä¸­æ ¸æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ã€‚
    ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ã€ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒã€çµ±è¨ˆåˆ†æã€å¯è¦–åŒ–ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆãªã©ã‚’çµ±åˆã—ã¦å®Ÿè¡Œã§ãã¾ã™ã€‚
    
    ä¸»è¦æ©Ÿèƒ½:
    1. ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¯”è¼ƒå®Ÿé¨“: è¤‡æ•°ã®chunk_size/cluster_sizeã§ã®æ€§èƒ½æ¸¬å®š
    2. ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒ: Linux read-aheadç›¸å½“æ‰‹æ³•ã¨ã®æ€§èƒ½å·®åˆ†æ
    3. çµ±è¨ˆåˆ†æ: å¹³å‡ãƒ»åˆ†æ•£ãƒ»æœ€é©å€¤ãªã©ã®è©³ç´°çµ±è¨ˆ
    4. å¯è¦–åŒ–ãƒ¬ãƒãƒ¼ãƒˆ: ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ãƒ»æ¨ç§»ã‚°ãƒ©ãƒ•ãªã©ã®ç”Ÿæˆ
    5. å®Ÿè¡Œæ™‚é–“æ¸¬å®š: å„å®Ÿé¨“ã®å‡¦ç†æ™‚é–“è¿½è·¡
    
    è¨­è¨ˆæ€æƒ³:
    - è¦ä»¶å®šç¾©æ›¸å®Œå…¨æº–æ‹ : æŒ‡å®šã•ã‚ŒãŸè©•ä¾¡æŒ‡æ¨™ã‚’æ­£ç¢ºã«ç®—å‡º
    - æ‹¡å¼µæ€§: æ–°ã—ã„è©•ä¾¡æ‰‹æ³•ã®è¿½åŠ ãŒå®¹æ˜“
    - å†ç¾æ€§: åŒã˜è¨­å®šã§ã®çµæœå†ç¾ãŒå¯èƒ½
    - ãƒ¦ãƒ¼ã‚¶ãƒ“ãƒªãƒ†ã‚£: ç›´æ„Ÿçš„ãªAPIè¨­è¨ˆ
    
    ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³:
    ```python
    # åŸºæœ¬ä½¿ç”¨ä¾‹
    evaluator = PerformanceEvaluator()
    
    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¯”è¼ƒå®Ÿé¨“
    results = evaluator.compare_parameters(trace, [4, 8, 16], [16, 32, 64])
    analysis = evaluator.analyze_results(results)
    evaluator.print_analysis_report(analysis)
    
    # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒ
    comparison = evaluator.compare_with_baseline(trace, best_params)
    evaluator.print_baseline_comparison_report(comparison)
    ```
    
    Attributes:
        results_history (List[Dict[str, Any]]): éå»ã®å®Ÿé¨“çµæœå±¥æ­´
        enable_visualization (bool): å¯è¦–åŒ–æ©Ÿèƒ½ã®æœ‰åŠ¹æ€§
        visualizer (Optional[CluMPVisualizer]): å¯è¦–åŒ–ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    """
    
    def __init__(self, enable_visualization: bool = True):
        """
        æ€§èƒ½è©•ä¾¡å™¨ã‚’åˆæœŸåŒ–
        
        Args:
            enable_visualization (bool): å¯è¦–åŒ–æ©Ÿèƒ½ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã‹ã©ã†ã‹
                True: matplotlibç­‰ãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆã«å¯è¦–åŒ–æ©Ÿèƒ½ã‚’æœ‰åŠ¹åŒ–
                False: å¯è¦–åŒ–æ©Ÿèƒ½ã‚’ç„¡åŠ¹åŒ–ï¼ˆæ•°å€¤å‡ºåŠ›ã®ã¿ï¼‰
                
        Note:
            å¯è¦–åŒ–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨ã§ããªã„ç’°å¢ƒã§ã¯ã€enable_visualization=Trueã§ã‚‚
            è‡ªå‹•çš„ã«ç„¡åŠ¹åŒ–ã•ã‚Œã€è­¦å‘Šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚
        """
        self.results_history: List[Dict[str, Any]] = []
        self.enable_visualization: bool = enable_visualization and VISUALIZATION_AVAILABLE
        
        if self.enable_visualization:
            try:
                self.visualizer = CluMPVisualizer()
                logging.info("å¯è¦–åŒ–æ©Ÿèƒ½ãŒæœ‰åŠ¹ã«ãªã‚Šã¾ã—ãŸã€‚")
            except Exception as e:
                logging.warning(f"å¯è¦–åŒ–ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®åˆæœŸåŒ–ã«å¤±æ•—: {e}")
                self.enable_visualization = False
                self.visualizer = None
        else:
            self.visualizer = None
            if enable_visualization:
                logging.warning("å¯è¦–åŒ–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨ã§ããªã„ãŸã‚ã€å¯è¦–åŒ–æ©Ÿèƒ½ã¯ç„¡åŠ¹åŒ–ã•ã‚Œã¾ã—ãŸã€‚")
        
        logging.info(f"PerformanceEvaluator initialized. Visualization: {self.enable_visualization}")
    
    def compare_parameters(self, trace: List[int], 
                         chunk_sizes: List[int] = [4, 8, 16, 32],
                         cluster_sizes: List[int] = [16, 32, 64, 128],
                         cache_size: int = 4096,
                         prefetch_window: int = 16) -> List[Dict[str, Any]]:
        """
        ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¯”è¼ƒå®Ÿé¨“ã‚’å®Ÿè¡Œ
        
        è¤‡æ•°ã®chunk_size/cluster_sizeã®çµ„ã¿åˆã‚ã›ã§ CluMPã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã—ã€
        æœ€é©ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šã‚’ç‰¹å®šã™ã‚‹ãŸã‚ã®æ¯”è¼ƒå®Ÿé¨“ã‚’è¡Œã„ã¾ã™ã€‚
        
        å®Ÿé¨“è¨­è¨ˆ:
        - å…¨çµ„ã¿åˆã‚ã›ã§ã®ç·å½“ãŸã‚Šå®Ÿé¨“ï¼ˆNÃ—Må›ï¼‰
        - å›ºå®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: cache_size, prefetch_window
        - å¯å¤‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: chunk_size, cluster_size
        - åŒä¸€ãƒˆãƒ¬ãƒ¼ã‚¹ã§ã®å…¬å¹³æ¯”è¼ƒ
        
        Args:
            trace (List[int]): è©•ä¾¡ç”¨ãƒˆãƒ¬ãƒ¼ã‚¹ï¼ˆãƒ–ãƒ­ãƒƒã‚¯ã‚¢ã‚¯ã‚»ã‚¹åˆ—ï¼‰
            chunk_sizes (List[int]): ãƒ†ã‚¹ãƒˆå¯¾è±¡ã®ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºãƒªã‚¹ãƒˆ
            cluster_sizes (List[int]): ãƒ†ã‚¹ãƒˆå¯¾è±¡ã®ã‚¯ãƒ©ã‚¹ã‚¿ã‚µã‚¤ã‚ºãƒªã‚¹ãƒˆ
            cache_size (int): ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºï¼ˆå›ºå®šï¼‰
            prefetch_window (int): ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒçª“ã‚µã‚¤ã‚ºï¼ˆå›ºå®šï¼‰
            
        Returns:
            List[Dict[str, Any]]: å®Ÿé¨“çµæœã®ãƒªã‚¹ãƒˆ
                å„è¦ç´ ã¯ä»¥ä¸‹ã®æƒ…å ±ã‚’å«ã‚€:
                - chunk_size, cluster_size: å®Ÿé¨“ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
                - hit_rate, prefetch_efficiency: ä¸»è¦æ€§èƒ½æŒ‡æ¨™
                - memory_usage_mc_rows: ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡
                - experiment_id: å®Ÿé¨“ç•ªå·
                - execution_time: å®Ÿè¡Œæ™‚é–“ï¼ˆç§’ï¼‰
                
        Raises:
            ValueError: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒä¸æ­£ãªå ´åˆ
            RuntimeError: ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œã«å¤±æ•—ã—ãŸå ´åˆ
            
        Example:
            >>> evaluator = PerformanceEvaluator()
            >>> results = evaluator.compare_parameters(
            ...     trace=my_trace,
            ...     chunk_sizes=[4, 8, 16],
            ...     cluster_sizes=[16, 32]
            ... )
            >>> print(f"å®Ÿé¨“æ•°: {len(results)}")  # 6å®Ÿé¨“ï¼ˆ3Ã—2ï¼‰
        """
        if not trace:
            raise ValueError("trace cannot be empty")
        if not chunk_sizes or not cluster_sizes:
            raise ValueError("chunk_sizes and cluster_sizes cannot be empty")
        if cache_size <= 0 or prefetch_window <= 0:
            raise ValueError("cache_size and prefetch_window must be positive")
            
        results = []
        total_experiments = len(chunk_sizes) * len(cluster_sizes)
        current_exp = 0
        
        logging.info(f"ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¯”è¼ƒå®Ÿé¨“é–‹å§‹ (ç·å®Ÿé¨“æ•°: {total_experiments})")
        print(f"ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¯”è¼ƒå®Ÿé¨“é–‹å§‹ (ç·å®Ÿé¨“æ•°: {total_experiments})")
        print("-" * 60)
        
        for chunk_size in chunk_sizes:
            for cluster_size in cluster_sizes:
                current_exp += 1
                print(f"å®Ÿé¨“ {current_exp}/{total_experiments}: "
                      f"ãƒãƒ£ãƒ³ã‚¯={chunk_size}, ã‚¯ãƒ©ã‚¹ã‚¿={cluster_size}")
                
                try:
                    # CluMPã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
                    start_time = time.time()
                    result = run_clump_simulation(
                        trace=trace,
                        chunk_size=chunk_size,
                        cluster_size=cluster_size,
                        cache_size=cache_size,
                        prefetch_window=prefetch_window
                    )
                    execution_time = time.time() - start_time
                    
                    # çµæœã«å®Ÿé¨“æƒ…å ±ã‚’è¿½åŠ 
                    result.update({
                        "experiment_id": current_exp,
                        "execution_time": execution_time
                    })
                    
                    results.append(result)
                    
                    print(f"  â†’ ãƒ’ãƒƒãƒˆç‡: {result['hit_rate']:.3f}, "
                          f"ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒåŠ¹ç‡: {result['prefetch_efficiency']:.3f}, "
                          f"MCè¡Œæ•°: {result['memory_usage_mc_rows']}")
                    
                    logging.debug(f"Experiment {current_exp} completed in {execution_time:.2f}s")
                    
                except Exception as e:
                    logging.error(f"Experiment {current_exp} failed: {e}")
                    print(f"  â†’ ã‚¨ãƒ©ãƒ¼: {e}")
                    # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå®Ÿé¨“ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ç¶šè¡Œ
                    continue
        
        self.results_history.extend(results)
        logging.info(f"ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¯”è¼ƒå®Ÿé¨“å®Œäº†: {len(results)}/{total_experiments} æˆåŠŸ")
        return results
    
    def compare_with_baseline(self, trace: List[int], 
                            clump_params: Optional[Dict[str, int]] = None,
                            baseline_readahead: int = 8) -> Dict[str, Dict[str, Any]]:
        """
        ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ‰‹æ³•ã¨ã®æ¯”è¼ƒ
        
        CluMPã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¨å¾“æ¥ã®Linux read-aheadç›¸å½“æ‰‹æ³•ã‚’åŒä¸€ãƒˆãƒ¬ãƒ¼ã‚¹ã§æ¯”è¼ƒã—ã€
        æ€§èƒ½å·®ã‚’å®šé‡çš„ã«åˆ†æã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€CluMPã®æœ‰åŠ¹æ€§ã‚’å®¢è¦³çš„ã«è©•ä¾¡ã§ãã¾ã™ã€‚
        
        æ¯”è¼ƒå¯¾è±¡:
        - CluMP: ãƒãƒ«ã‚³ãƒ•é€£é–å­¦ç¿’ãƒ™ãƒ¼ã‚¹ã®ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒ
        - Baseline: é †æ¬¡ã‚¢ã‚¯ã‚»ã‚¹æ¤œå‡ºãƒ™ãƒ¼ã‚¹ã®å˜ç´”å…ˆèª­ã¿
        
        å…¬å¹³æ€§ç¢ºä¿:
        - åŒä¸€ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚º
        - åŒä¸€ã®ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¹
        - åŒã˜LRUç½®æ›ãƒãƒªã‚·ãƒ¼
        
        Args:
            trace (List[int]): è©•ä¾¡ç”¨ãƒˆãƒ¬ãƒ¼ã‚¹ï¼ˆãƒ–ãƒ­ãƒƒã‚¯ã‚¢ã‚¯ã‚»ã‚¹åˆ—ï¼‰
            clump_params (Optional[Dict[str, int]]): CluMPã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
                None ã®å ´åˆã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½¿ç”¨:
                - chunk_size: 8
                - cluster_size: 32
                - cache_size: 4096
                - prefetch_window: 16
            baseline_readahead (int): ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã®å…ˆèª­ã¿ã‚µã‚¤ã‚º
                
        Returns:
            Dict[str, Dict[str, Any]]: æ¯”è¼ƒçµæœè¾æ›¸
                "clump": CluMPã®è©•ä¾¡çµæœ
                "baseline": ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã®è©•ä¾¡çµæœ
                
        Raises:
            ValueError: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒä¸æ­£ãªå ´åˆ
            RuntimeError: ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œã«å¤±æ•—ã—ãŸå ´åˆ
            
        Example:
            >>> comparison = evaluator.compare_with_baseline(
            ...     trace=my_trace,
            ...     clump_params={"chunk_size": 16, "cluster_size": 64, 
            ...                  "cache_size": 8192, "prefetch_window": 32}
            ... )
            >>> clump_hit_rate = comparison["clump"]["hit_rate"]
            >>> baseline_hit_rate = comparison["baseline"]["hit_rate"]
            >>> improvement = (clump_hit_rate - baseline_hit_rate) / baseline_hit_rate * 100
            >>> print(f"CluMP improvement: {improvement:.1f}%")
        """
        if not trace:
            raise ValueError("trace cannot be empty")
        if baseline_readahead <= 0:
            raise ValueError("baseline_readahead must be positive")
            
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
        if clump_params is None:
            clump_params = {
                "chunk_size": 8,
                "cluster_size": 32,
                "cache_size": 4096,
                "prefetch_window": 16
            }
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¤œè¨¼
        required_keys = ["chunk_size", "cluster_size", "cache_size", "prefetch_window"]
        for key in required_keys:
            if key not in clump_params or clump_params[key] <= 0:
                raise ValueError(f"clump_params must contain positive {key}")
        
        logging.info(f"ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒå®Ÿé¨“é–‹å§‹: CluMP vs Linux read-ahead")
        print("ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒå®Ÿé¨“é–‹å§‹")
        print("-" * 40)
        
        try:
            # CluMPå®Ÿè¡Œ
            print("CluMPå®Ÿè¡Œä¸­...")
            logging.info(f"Running CluMP with params: {clump_params}")
            clump_start = time.time()
            clump_result = run_clump_simulation(trace=trace, **clump_params)
            clump_time = time.time() - clump_start
            clump_result["execution_time"] = clump_time
            
            # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ
            print("ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³å®Ÿè¡Œä¸­...")
            logging.info(f"Running baseline with readahead_size: {baseline_readahead}")
            baseline_start = time.time()
            baseline = BaselinePrefetcher(
                cache_size_blocks=clump_params["cache_size"],
                readahead_size=baseline_readahead
            )
            
            for block_id in trace:
                baseline.process_access(block_id)
            
            baseline_result = baseline.get_evaluation_metrics()
            baseline_time = time.time() - baseline_start
            baseline_result["execution_time"] = baseline_time
            
            # ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯
            if "error" in clump_result:
                raise RuntimeError(f"CluMP simulation failed: {clump_result['error']}")
            if "error" in baseline_result:
                raise RuntimeError(f"Baseline simulation failed: {baseline_result['error']}")
            
            comparison_result = {
                "clump": clump_result,
                "baseline": baseline_result
            }
            
            logging.info(f"ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒå®Œäº†: CluMP={clump_time:.2f}s, Baseline={baseline_time:.2f}s")
            return comparison_result
            
        except Exception as e:
            logging.error(f"Baseline comparison failed: {e}")
            raise RuntimeError(f"Failed to execute baseline comparison: {e}")
    
    def analyze_results(self, results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        å®Ÿé¨“çµæœã‚’åˆ†æ
        
        è¤‡æ•°ã®å®Ÿé¨“çµæœã‹ã‚‰çµ±è¨ˆçš„åˆ†æã‚’è¡Œã„ã€æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ç‰¹å®šã¨
        æ€§èƒ½åˆ†å¸ƒã®æŠŠæ¡ã‚’è¡Œã„ã¾ã™ã€‚
        
        åˆ†æå†…å®¹:
        1. æœ€é©ãƒ»æœ€æ‚ªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ç‰¹å®š
        2. å„æŒ‡æ¨™ã®çµ±è¨ˆå€¤ï¼ˆå¹³å‡ãƒ»åˆ†æ•£ãƒ»ç¯„å›²ï¼‰
        3. ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–åŠ¹æœã®å®šé‡åŒ–
        4. å¤–ã‚Œå€¤ãƒ»ç•°å¸¸å€¤ã®æ¤œå‡º
        
        Args:
            results (List[Dict[str, Any]]): å®Ÿé¨“çµæœã®ãƒªã‚¹ãƒˆ
                å„è¦ç´ ã¯ compare_parameters() ã®æˆ»ã‚Šå€¤å½¢å¼
                
        Returns:
            Dict[str, Any]: åˆ†æçµæœè¾æ›¸
                "best_parameters": æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ãã®æ€§èƒ½
                "worst_parameters": æœ€æ‚ªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ãã®æ€§èƒ½
                "statistics": å„æŒ‡æ¨™ã®çµ±è¨ˆæƒ…å ±
                "optimization_effect": æœ€é©åŒ–ã«ã‚ˆã‚‹æ”¹å–„åŠ¹æœ
                
        Raises:
            ValueError: çµæœãƒªã‚¹ãƒˆãŒç©ºã®å ´åˆ
            KeyError: å¿…è¦ãªã‚­ãƒ¼ãŒä¸è¶³ã—ã¦ã„ã‚‹å ´åˆ
            
        Example:
            >>> analysis = evaluator.analyze_results(param_results)
            >>> best = analysis["best_parameters"]
            >>> print(f"æœ€é©è¨­å®š: chunk={best['chunk_size']}, cluster={best['cluster_size']}")
            >>> print(f"æœ€é«˜ãƒ’ãƒƒãƒˆç‡: {best['hit_rate']:.3f}")
        """
        if not results:
            return {"error": "No results to analyze"}
        
        try:
            # æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ç‰¹å®šï¼ˆãƒ’ãƒƒãƒˆç‡åŸºæº–ï¼‰
            best_result = max(results, key=lambda x: x.get("hit_rate", 0))
            worst_result = min(results, key=lambda x: x.get("hit_rate", 0))
            
            # çµ±è¨ˆè¨ˆç®—ç”¨ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
            hit_rates = [r.get("hit_rate", 0) for r in results]
            prefetch_effs = [r.get("prefetch_efficiency", 0) for r in results]
            mc_rows = [r.get("memory_usage_mc_rows", 0) for r in results]
            exec_times = [r.get("execution_time", 0) for r in results if "execution_time" in r]
            
            # çµ±è¨ˆå€¤è¨ˆç®—ï¼ˆdivision by zeroå¯¾ç­–ï¼‰
            def safe_stats(data):
                if not data:
                    return {"mean": 0, "max": 0, "min": 0, "std": 0}
                return {
                    "mean": statistics.mean(data),
                    "max": max(data),
                    "min": min(data),
                    "std": statistics.stdev(data) if len(data) > 1 else 0
                }
            
            analysis = {
                "best_parameters": {
                    "chunk_size": best_result.get("chunk_size", 0),
                    "cluster_size": best_result.get("cluster_size", 0),
                    "hit_rate": best_result.get("hit_rate", 0),
                    "prefetch_efficiency": best_result.get("prefetch_efficiency", 0),
                    "mc_rows": best_result.get("memory_usage_mc_rows", 0)
                },
                "worst_parameters": {
                    "chunk_size": worst_result.get("chunk_size", 0),
                    "cluster_size": worst_result.get("cluster_size", 0),
                    "hit_rate": worst_result.get("hit_rate", 0)
                },
                "statistics": {
                    "hit_rate": safe_stats(hit_rates),
                    "prefetch_efficiency": safe_stats(prefetch_effs),
                    "mc_rows": safe_stats(mc_rows),
                    "execution_time": safe_stats(exec_times)
                }
            }
            
            # æœ€é©åŒ–åŠ¹æœã®è¨ˆç®—
            min_hit_rate = analysis["statistics"]["hit_rate"]["min"]
            max_hit_rate = analysis["statistics"]["hit_rate"]["max"]
            if min_hit_rate > 0:
                improvement = ((max_hit_rate - min_hit_rate) / min_hit_rate * 100)
                analysis["optimization_effect"] = {
                    "hit_rate_improvement_percent": improvement
                }
            else:
                analysis["optimization_effect"] = {"hit_rate_improvement_percent": 0}
            
            logging.info(f"Results analysis completed: {len(results)} experiments analyzed")
            return analysis
            
        except Exception as e:
            logging.error(f"Failed to analyze results: {e}")
            return {"error": f"Analysis failed: {e}"}
    
    def print_analysis_report(self, analysis: Dict[str, Any]) -> None:
        """
        åˆ†æçµæœãƒ¬ãƒãƒ¼ãƒˆã‚’å‡ºåŠ›
        
        å®Ÿé¨“çµæœã®åˆ†æã‹ã‚‰å¾—ã‚‰ã‚ŒãŸçŸ¥è¦‹ã‚’ã€èª­ã¿ã‚„ã™ã„å½¢å¼ã§å‡ºåŠ›ã—ã¾ã™ã€‚
        æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€çµ±è¨ˆæƒ…å ±ã€æœ€é©åŒ–åŠ¹æœãªã©ã‚’åŒ…æ‹¬çš„ã«è¡¨ç¤ºã—ã¾ã™ã€‚
        
        Args:
            analysis (Dict[str, Any]): analyze_results()ã®æˆ»ã‚Šå€¤
                
        Note:
            ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¯æ¨™æº–å‡ºåŠ›ã¸ã®å‡ºåŠ›ã®ã¿ã‚’è¡Œã„ã¾ã™ã€‚
            ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›ãŒå¿…è¦ãªå ´åˆã¯ã€åˆ¥é€”å®Ÿè£…ã—ã¦ãã ã•ã„ã€‚
        """
        if "error" in analysis:
            print(f"\nâŒ åˆ†æã‚¨ãƒ©ãƒ¼: {analysis['error']}")
            return
            
        try:
            print("\n" + "=" * 80)
            print("CluMP ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åˆ†æãƒ¬ãƒãƒ¼ãƒˆ")
            print("=" * 80)
            
            # æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æƒ…å ±
            best = analysis["best_parameters"]
            print(f"\nğŸ† æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:")
            print(f"   ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º: {best['chunk_size']} ãƒ–ãƒ­ãƒƒã‚¯")
            print(f"   ã‚¯ãƒ©ã‚¹ã‚¿ã‚µã‚¤ã‚º: {best['cluster_size']} ãƒãƒ£ãƒ³ã‚¯")
            print(f"   ãƒ’ãƒƒãƒˆç‡: {best['hit_rate']:.3f} ({best['hit_rate']*100:.1f}%)")
            print(f"   ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒåŠ¹ç‡: {best['prefetch_efficiency']:.3f} ({best['prefetch_efficiency']*100:.1f}%)")
            print(f"   MCè¡Œæ•°: {best['mc_rows']:,}")
            
            # çµ±è¨ˆæƒ…å ±
            stats = analysis["statistics"]
            print(f"\nğŸ“Š æ€§èƒ½çµ±è¨ˆ:")
            print(f"   ãƒ’ãƒƒãƒˆç‡: {stats['hit_rate']['mean']:.3f} Â± {stats['hit_rate']['std']:.3f}")
            print(f"   ã€€ã€€ç¯„å›²: {stats['hit_rate']['min']:.3f} - {stats['hit_rate']['max']:.3f}")
            print(f"   ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒåŠ¹ç‡: {stats['prefetch_efficiency']['mean']:.3f} Â± {stats['prefetch_efficiency']['std']:.3f}")
            print(f"   ã€€ã€€ç¯„å›²: {stats['prefetch_efficiency']['min']:.3f} - {stats['prefetch_efficiency']['max']:.3f}")
            print(f"   MCè¡Œæ•°: {stats['mc_rows']['mean']:.0f} Â± {stats['mc_rows']['std']:.0f}")
            print(f"   ã€€ç¯„å›²: {stats['mc_rows']['min']} - {stats['mc_rows']['max']}")
            
            # å®Ÿè¡Œæ™‚é–“çµ±è¨ˆï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
            if "execution_time" in stats and stats["execution_time"]["mean"] > 0:
                print(f"   å®Ÿè¡Œæ™‚é–“: {stats['execution_time']['mean']:.2f} Â± {stats['execution_time']['std']:.2f} ç§’")
                print(f"   ã€€ã€€ç¯„å›²: {stats['execution_time']['min']:.2f} - {stats['execution_time']['max']:.2f} ç§’")
            
            # æœ€é©åŒ–åŠ¹æœ
            if "optimization_effect" in analysis:
                improvement = analysis["optimization_effect"]["hit_rate_improvement_percent"]
                print(f"\nğŸ“ˆ æœ€é©åŒ–åŠ¹æœ:")
                print(f"   ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ã«ã‚ˆã‚‹ãƒ’ãƒƒãƒˆç‡å‘ä¸Š: {improvement:.1f}%")
                
                # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è§£é‡ˆ
                if improvement > 20:
                    print(f"   ğŸ’¡ è§£é‡ˆ: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ã«ã‚ˆã‚‹å¤§å¹…ãªæ€§èƒ½å‘ä¸ŠãŒæœŸå¾…ã§ãã¾ã™")
                elif improvement > 10:
                    print(f"   ğŸ’¡ è§£é‡ˆ: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ã«ã‚ˆã‚‹ä¸­ç¨‹åº¦ã®æ€§èƒ½å‘ä¸ŠãŒè¦‹è¾¼ã‚ã¾ã™")
                elif improvement > 5:
                    print(f"   ğŸ’¡ è§£é‡ˆ: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ã«ã‚ˆã‚‹è»½å¾®ãªæ€§èƒ½å‘ä¸ŠãŒã‚ã‚Šã¾ã™")
                else:
                    print(f"   ğŸ’¡ è§£é‡ˆ: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«ã‚ˆã‚‹æ€§èƒ½å·®ã¯å°ã•ãã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã§ååˆ†ã§ã™")
            
            # æœ€æ‚ªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆå‚è€ƒæƒ…å ±ï¼‰
            if "worst_parameters" in analysis:
                worst = analysis["worst_parameters"]
                print(f"\nâš ï¸  æœ€æ‚ªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆå‚è€ƒï¼‰:")
                print(f"   ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º: {worst['chunk_size']}, ã‚¯ãƒ©ã‚¹ã‚¿ã‚µã‚¤ã‚º: {worst['cluster_size']}")
                print(f"   ãƒ’ãƒƒãƒˆç‡: {worst['hit_rate']:.3f} ({worst['hit_rate']*100:.1f}%)")
            
            print("\n" + "=" * 80)
            
        except Exception as e:
            logging.error(f"Failed to print analysis report: {e}")
            print(f"\nâŒ ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›ã‚¨ãƒ©ãƒ¼: {e}")
    
    def print_baseline_comparison_report(self, comparison: Dict[str, Dict[str, Any]]) -> None:
        """
        ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆã‚’å‡ºåŠ›
        
        CluMPã¨ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ‰‹æ³•ã®æ¯”è¼ƒçµæœã‚’è©³ç´°ã«è¡¨ç¤ºã—ã¾ã™ã€‚
        å„æŒ‡æ¨™ã§ã®æ”¹å–„ç‡ã‚„å®Ÿç”¨æ€§ã®åˆ†æã‚‚å«ã‚ã¦å‡ºåŠ›ã—ã¾ã™ã€‚
        
        Args:
            comparison (Dict[str, Dict[str, Any]]): compare_with_baseline()ã®æˆ»ã‚Šå€¤
                "clump": CluMPã®å®Ÿè¡Œçµæœ
                "baseline": ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ‰‹æ³•ã®å®Ÿè¡Œçµæœ
                
        Note:
            æ”¹å–„ç‡ã®è¨ˆç®—ã§ã¯ã€ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ‰‹æ³•ã‚’åŸºæº–ï¼ˆ100%ï¼‰ã¨ã—ãŸç›¸å¯¾å€¤ã§è¡¨ç¤ºã—ã¾ã™ã€‚
        """
        if "clump" not in comparison or "baseline" not in comparison:
            print(f"\nâŒ æ¯”è¼ƒãƒ‡ãƒ¼ã‚¿ãŒä¸å®Œå…¨ã§ã™")
            return
            
        try:
            clump = comparison["clump"]
            baseline = comparison["baseline"]
            
            # ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯
            if "error" in clump:
                print(f"\nâŒ CluMPå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {clump['error']}")
                return
            if "error" in baseline:
                print(f"\nâŒ ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {baseline['error']}")
                return
            
            print("\n" + "=" * 80)
            print("CluMP vs ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆ")
            print("=" * 80)
            
            # ãƒ’ãƒƒãƒˆç‡æ¯”è¼ƒ
            print(f"\nğŸ“ˆ ãƒ’ãƒƒãƒˆç‡æ¯”è¼ƒ:")
            print(f"   CluMP:      {clump['hit_rate']:.3f} ({clump['hit_rate']*100:.1f}%)")
            print(f"   ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³: {baseline['hit_rate']:.3f} ({baseline['hit_rate']*100:.1f}%)")
            
            if baseline['hit_rate'] > 0:
                hit_improvement = ((clump['hit_rate'] - baseline['hit_rate']) / baseline['hit_rate'] * 100)
                print(f"   æ”¹å–„ç‡:      {hit_improvement:+.1f}%")
                
                # æ”¹å–„åŠ¹æœã®è§£é‡ˆ
                if hit_improvement > 25:
                    print(f"   ğŸ’¡ CluMPã¯å¤§å¹…ãªæ€§èƒ½å‘ä¸Šã‚’å®Ÿç¾ã—ã¦ã„ã¾ã™")
                elif hit_improvement > 15:
                    print(f"   ğŸ’¡ CluMPã¯ä¸­ç¨‹åº¦ã®æ€§èƒ½å‘ä¸Šã‚’é”æˆã—ã¦ã„ã¾ã™")
                elif hit_improvement > 5:
                    print(f"   ğŸ’¡ CluMPã¯è»½å¾®ãªæ€§èƒ½å‘ä¸Šã‚’ã‚‚ãŸã‚‰ã—ã¦ã„ã¾ã™")
                elif hit_improvement > -5:
                    print(f"   ğŸ’¡ ä¸¡æ‰‹æ³•ã®æ€§èƒ½ã¯ã»ã¼åŒç­‰ã§ã™")
                else:
                    print(f"   âš ï¸  ã“ã®ã‚±ãƒ¼ã‚¹ã§ã¯ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ‰‹æ³•ã®æ–¹ãŒå„ªç§€ã§ã™")
            else:
                print(f"   âš ï¸  ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã®ãƒ’ãƒƒãƒˆç‡ãŒ0ã®ãŸã‚ã€æ”¹å–„ç‡ã‚’è¨ˆç®—ã§ãã¾ã›ã‚“")
            
            # ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒåŠ¹ç‡æ¯”è¼ƒ
            print(f"\nğŸ¯ ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒåŠ¹ç‡æ¯”è¼ƒ:")
            print(f"   CluMP:      {clump['prefetch_efficiency']:.3f} ({clump['prefetch_efficiency']*100:.1f}%)")
            print(f"   ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³: {baseline['prefetch_efficiency']:.3f} ({baseline['prefetch_efficiency']*100:.1f}%)")
            
            if baseline['prefetch_efficiency'] > 0:
                pf_improvement = ((clump['prefetch_efficiency'] - baseline['prefetch_efficiency']) / 
                                baseline['prefetch_efficiency'] * 100)
                print(f"   æ”¹å–„ç‡:      {pf_improvement:+.1f}%")
            else:
                if clump['prefetch_efficiency'] > 0:
                    print(f"   æ”¹å–„ç‡:      +âˆ% (ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã§å…ˆèª­ã¿æœªå®Ÿè¡Œ)")
                else:
                    print(f"   æ”¹å–„ç‡:      N/A (ä¸¡æ‰‹æ³•ã¨ã‚‚å…ˆèª­ã¿æœªå®Ÿè¡Œ)")
            
            # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡
            print(f"\nğŸ’¾ ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡:")
            print(f"   CluMP MCè¡Œæ•°: {clump['memory_usage_mc_rows']:,}")
            print(f"   ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³: 0 (MCRowãªã—)")
            
            if clump['memory_usage_mc_rows'] > 0:
                # MCè¡Œã‚ãŸã‚Šã®æ€§èƒ½å‘ä¸Šã‚’è¨ˆç®—
                hit_gain = clump['hit_rate'] - baseline['hit_rate']
                if hit_gain > 0:
                    efficiency = hit_gain / clump['memory_usage_mc_rows'] * 1000
                    print(f"   åŠ¹ç‡æŒ‡æ¨™: {efficiency:.3f} (ãƒ’ãƒƒãƒˆç‡å‘ä¸Š/1000MCè¡Œ)")
                else:
                    print(f"   åŠ¹ç‡æŒ‡æ¨™: N/A (ãƒ’ãƒƒãƒˆç‡å‘ä¸Šãªã—)")
            
            # è©³ç´°çµ±è¨ˆ
            print(f"\nğŸ“Š è©³ç´°çµ±è¨ˆ:")
            print(f"   ç·ã‚¢ã‚¯ã‚»ã‚¹æ•°: {clump.get('total_accesses', 'N/A'):,}")
            print(f"   CluMP ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒ: ç·æ•°={clump['prefetch_total']:,}, ä½¿ç”¨æ•°={clump['prefetch_used']:,}")
            print(f"   ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒ: ç·æ•°={baseline['prefetch_total']:,}, ä½¿ç”¨æ•°={baseline['prefetch_used']:,}")
            
            # å®Ÿè¡Œæ™‚é–“æ¯”è¼ƒï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
            if "execution_time" in clump and "execution_time" in baseline:
                print(f"\nâ±ï¸  å®Ÿè¡Œæ™‚é–“æ¯”è¼ƒ:")
                print(f"   CluMP: {clump['execution_time']:.3f} ç§’")
                print(f"   ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³: {baseline['execution_time']:.3f} ç§’")
                
                if baseline['execution_time'] > 0:
                    time_ratio = clump['execution_time'] / baseline['execution_time']
                    print(f"   æ™‚é–“æ¯”: {time_ratio:.2f}x")
                    if time_ratio > 1.5:
                        print(f"   ğŸ’¡ CluMPã¯å­¦ç¿’ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã«ã‚ˆã‚Šå®Ÿè¡Œæ™‚é–“ãŒé•·ã‚ã§ã™")
                    elif time_ratio > 1.1:
                        print(f"   ğŸ’¡ CluMPã®å®Ÿè¡Œæ™‚é–“ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã¯è¨±å®¹ç¯„å›²å†…ã§ã™")
                    else:
                        print(f"   ğŸ’¡ ä¸¡æ‰‹æ³•ã®å®Ÿè¡Œæ™‚é–“ã¯ã»ã¼åŒç­‰ã§ã™")
            
            # ç·åˆè©•ä¾¡
            print(f"\nğŸ ç·åˆè©•ä¾¡:")
            if baseline['hit_rate'] > 0:
                total_gain = ((clump['hit_rate'] - baseline['hit_rate']) / baseline['hit_rate'] * 100)
                if total_gain > 20:
                    print(f"   â­â­â­ CluMPã¯æ˜ç¢ºãªæ€§èƒ½å„ªä½æ€§ã‚’ç¤ºã—ã¦ã„ã¾ã™ï¼ˆ+{total_gain:.1f}%ï¼‰")
                elif total_gain > 10:
                    print(f"   â­â­ CluMPã¯æœ‰åŠ¹ãªæ€§èƒ½å‘ä¸Šã‚’é”æˆã—ã¦ã„ã¾ã™ï¼ˆ+{total_gain:.1f}%ï¼‰")
                elif total_gain > 0:
                    print(f"   â­ CluMPã¯è»½å¾®ãªæ”¹å–„ã‚’ã‚‚ãŸã‚‰ã—ã¦ã„ã¾ã™ï¼ˆ+{total_gain:.1f}%ï¼‰")
                else:
                    print(f"   âš ï¸ ã“ã®ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã§ã¯CluMPã®åŠ¹æœã¯é™å®šçš„ã§ã™ï¼ˆ{total_gain:.1f}%ï¼‰")
            
            print("\n" + "=" * 80)
            
        except Exception as e:
            logging.error(f"Failed to print baseline comparison report: {e}")
            print(f"\nâŒ æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›ã‚¨ãƒ©ãƒ¼: {e}")


def get_user_config() -> Dict[str, Any]:
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®šã‚’å–å¾—
    
    ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å…¥åŠ›ã«ã‚ˆã‚Šã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå®Ÿé¨“è¨­å®šã‚’
    ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚‚æä¾›ã—ã€
    å…¥åŠ›ã‚¨ãƒ©ãƒ¼ã«å¯¾ã™ã‚‹å …ç‰¢æ€§ã‚‚ç¢ºä¿ã—ã¦ã„ã¾ã™ã€‚
    
    è¨­å®šå¯èƒ½é …ç›®:
    1. ãƒˆãƒ¬ãƒ¼ã‚¹è¨­å®š: ã‚¢ã‚¯ã‚»ã‚¹æ•°ã€ãƒ•ã‚¡ã‚¤ãƒ«æ•°ã€ã‚¢ã‚¯ã‚»ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³ç¢ºç‡
    2. CluMPãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: ãƒãƒ£ãƒ³ã‚¯/ã‚¯ãƒ©ã‚¹ã‚¿ã‚µã‚¤ã‚ºã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚º
    3. ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³è¨­å®š: å…ˆèª­ã¿ã‚µã‚¤ã‚º
    
    Returns:
        Dict[str, Any]: ãƒ¦ãƒ¼ã‚¶ãƒ¼è¨­å®šè¾æ›¸
            "trace": ãƒˆãƒ¬ãƒ¼ã‚¹ç”Ÿæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            "parameters": CluMPã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿  
            "baseline": ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ‰‹æ³•ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            
    Note:
        å…¥åŠ›ã‚¨ãƒ©ãƒ¼ã‚„ã‚­ãƒ£ãƒ³ã‚»ãƒ«ï¼ˆCtrl+Cï¼‰ã®å ´åˆã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’è¿”ã—ã¾ã™ã€‚
        ã™ã¹ã¦ã®å…¥åŠ›ã¯æ¤œè¨¼ã•ã‚Œã€ä¸æ­£ãªå€¤ã®å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ãŒä½¿ç”¨ã•ã‚Œã¾ã™ã€‚
        
    Example:
        >>> config = get_user_config()
        >>> print(f"å®Ÿé¨“æ•°: {len(config['parameters']['chunk_sizes']) * len(config['parameters']['cluster_sizes'])}")
    """
    print("\nğŸ”§ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š")
    print("-" * 40)
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šï¼ˆç ”ç©¶ã«é©ã—ãŸæ¨™æº–çš„ãªå€¤ï¼‰
    config = {
        "trace": {
            "n_events": 15000,      # ååˆ†ãªå­¦ç¿’æœŸé–“ã‚’ç¢ºä¿
            "num_files": 60,        # å¤šæ§˜ãªã‚¢ã‚¯ã‚»ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³
            "avg_file_length_blocks": 120,  # å®Ÿç”¨çš„ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º
            "sequential_prob": 0.6,  # é †æ¬¡ã‚¢ã‚¯ã‚»ã‚¹å„ªå‹¢ï¼ˆå®Ÿç’°å¢ƒã«è¿‘ã„ï¼‰
            "jump_prob": 0.15       # é©åº¦ãªãƒ©ãƒ³ãƒ€ãƒ ã‚¢ã‚¯ã‚»ã‚¹
        },
        "parameters": {
            "chunk_sizes": [4, 8, 16, 32],    # å¹…åºƒã„ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºæ¤œè¨¼
            "cluster_sizes": [16, 32, 64],    # åŠ¹ç‡çš„ãªã‚¯ãƒ©ã‚¹ã‚¿ã‚µã‚¤ã‚ºç¯„å›²
            "cache_size": 4096,               # æ¨™æº–çš„ãªã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚º
            "prefetch_window": 16             # ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸå…ˆèª­ã¿çª“
        },
        "baseline": {
            "readahead_size": 8               # Linuxæ¨™æº–çš„ãªå…ˆèª­ã¿ã‚µã‚¤ã‚º
        }
    }
    
    try:
        print("1. ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã§å®Ÿè¡Œï¼ˆæ¨å¥¨ï¼‰")
        print("2. ã‚«ã‚¹ã‚¿ãƒ è¨­å®šã§å®Ÿè¡Œï¼ˆä¸Šç´šè€…å‘ã‘ï¼‰")
        
        choice = input("\né¸æŠã—ã¦ãã ã•ã„ (1-2, ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1): ").strip()
        
        if choice == "2":
            print("\nğŸ“Š ãƒˆãƒ¬ãƒ¼ã‚¹è¨­å®š")
            print("  æ³¨æ„: å¤§ããªå€¤ã¯å®Ÿè¡Œæ™‚é–“ãŒé•·ããªã‚Šã¾ã™")
            
            # ãƒˆãƒ¬ãƒ¼ã‚¹è¨­å®šã®ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º
            n_events_input = input(f"ã‚¢ã‚¯ã‚»ã‚¹æ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {config['trace']['n_events']}): ").strip()
            if n_events_input and n_events_input.isdigit():
                config["trace"]["n_events"] = max(1000, int(n_events_input))  # æœ€ä½1000ã‚¢ã‚¯ã‚»ã‚¹
            
            num_files_input = input(f"ãƒ•ã‚¡ã‚¤ãƒ«æ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {config['trace']['num_files']}): ").strip()
            if num_files_input and num_files_input.isdigit():
                config["trace"]["num_files"] = max(10, int(num_files_input))  # æœ€ä½10ãƒ•ã‚¡ã‚¤ãƒ«
            
            file_length_input = input(f"å¹³å‡ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º(ãƒ–ãƒ­ãƒƒã‚¯) (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {config['trace']['avg_file_length_blocks']}): ").strip()
            if file_length_input and file_length_input.isdigit():
                config["trace"]["avg_file_length_blocks"] = max(50, int(file_length_input))
            
            seq_prob_input = input(f"é †æ¬¡ã‚¢ã‚¯ã‚»ã‚¹ç¢ºç‡ (0.0-1.0, ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {config['trace']['sequential_prob']}): ").strip()
            if seq_prob_input:
                try:
                    seq_prob = float(seq_prob_input)
                    if 0.0 <= seq_prob <= 1.0:
                        config["trace"]["sequential_prob"] = seq_prob
                except ValueError:
                    pass
            
            jump_prob_input = input(f"ã‚¸ãƒ£ãƒ³ãƒ—ç¢ºç‡ (0.0-1.0, ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {config['trace']['jump_prob']}): ").strip()
            if jump_prob_input:
                try:
                    jump_prob = float(jump_prob_input)
                    if 0.0 <= jump_prob <= 1.0:
                        config["trace"]["jump_prob"] = jump_prob
                except ValueError:
                    pass
            
            print("\nâš™ï¸ CluMPãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š")
            print("  æ³¨æ„: çµ„ã¿åˆã‚ã›æ•°ãŒå®Ÿé¨“æ™‚é–“ã«å½±éŸ¿ã—ã¾ã™")
            
            # CluMPãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º
            chunk_sizes_str = input(f"ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º (ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Š, ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {','.join(map(str, config['parameters']['chunk_sizes']))}): ").strip()
            if chunk_sizes_str:
                try:
                    chunk_sizes = [max(1, int(x.strip())) for x in chunk_sizes_str.split(",") if x.strip().isdigit()]
                    if chunk_sizes:
                        config["parameters"]["chunk_sizes"] = chunk_sizes
                except ValueError:
                    pass
            
            cluster_sizes_str = input(f"ã‚¯ãƒ©ã‚¹ã‚¿ã‚µã‚¤ã‚º (ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Š, ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {','.join(map(str, config['parameters']['cluster_sizes']))}): ").strip()
            if cluster_sizes_str:
                try:
                    cluster_sizes = [max(4, int(x.strip())) for x in cluster_sizes_str.split(",") if x.strip().isdigit()]
                    if cluster_sizes:
                        config["parameters"]["cluster_sizes"] = cluster_sizes
                except ValueError:
                    pass
            
            cache_size_input = input(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚º (ãƒ–ãƒ­ãƒƒã‚¯æ•°, ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {config['parameters']['cache_size']}): ").strip()
            if cache_size_input and cache_size_input.isdigit():
                config["parameters"]["cache_size"] = max(1024, int(cache_size_input))  # æœ€ä½1024ãƒ–ãƒ­ãƒƒã‚¯
            
            prefetch_window_input = input(f"ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒçª“ã‚µã‚¤ã‚º (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {config['parameters']['prefetch_window']}): ").strip()
            if prefetch_window_input and prefetch_window_input.isdigit():
                config["parameters"]["prefetch_window"] = max(4, int(prefetch_window_input))
            
            print("\nğŸ ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³è¨­å®š")
            baseline_input = input(f"ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³å…ˆèª­ã¿ã‚µã‚¤ã‚º (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {config['baseline']['readahead_size']}): ").strip()
            if baseline_input and baseline_input.isdigit():
                config["baseline"]["readahead_size"] = max(1, int(baseline_input))
            
    except (ValueError, KeyboardInterrupt):
        print("\nâš ï¸ å…¥åŠ›ã‚¨ãƒ©ãƒ¼ã¾ãŸã¯ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
        logging.info("User input cancelled or invalid, using default configuration")
    
    return config


def print_config_summary(config: Dict[str, Any]) -> None:
    """
    è¨­å®šã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º
    
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒé¸æŠã—ãŸå®Ÿé¨“è¨­å®šã‚’è¦‹ã‚„ã™ã„å½¢å¼ã§è¡¨ç¤ºã—ã€
    å®Ÿè¡Œå‰ã®æœ€çµ‚ç¢ºèªã‚’å¯èƒ½ã«ã—ã¾ã™ã€‚
    
    Args:
        config (Dict[str, Any]): get_user_config()ã®æˆ»ã‚Šå€¤
        
    Note:
        å®Ÿé¨“æ•°ã®è¨ˆç®—ã‚‚å«ã‚ã€å®Ÿè¡Œæ™‚é–“ã®è¦‹ç©ã‚‚ã‚Šã«å½¹ç«‹ã¤æƒ…å ±ã‚’æä¾›ã—ã¾ã™ã€‚
    """
    print("\nğŸ“‹ å®Ÿè¡Œè¨­å®šã‚µãƒãƒªãƒ¼")
    print("-" * 40)
    trace = config["trace"]
    params = config["parameters"]
    baseline = config["baseline"]
    
    print(f"ğŸ“Š ãƒˆãƒ¬ãƒ¼ã‚¹:")
    print(f"   ã‚¢ã‚¯ã‚»ã‚¹æ•°: {trace['n_events']:,}")
    print(f"   ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {trace['num_files']}")
    print(f"   å¹³å‡ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {trace['avg_file_length_blocks']} ãƒ–ãƒ­ãƒƒã‚¯")
    print(f"   é †æ¬¡ã‚¢ã‚¯ã‚»ã‚¹ç¢ºç‡: {trace['sequential_prob']:.1%}")
    print(f"   ã‚¸ãƒ£ãƒ³ãƒ—ç¢ºç‡: {trace['jump_prob']:.1%}")
    
    print(f"\nâš™ï¸ CluMPãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:")
    print(f"   ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º: {params['chunk_sizes']}")
    print(f"   ã‚¯ãƒ©ã‚¹ã‚¿ã‚µã‚¤ã‚º: {params['cluster_sizes']}")
    print(f"   ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚º: {params['cache_size']:,} ãƒ–ãƒ­ãƒƒã‚¯")
    print(f"   ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒçª“: {params['prefetch_window']}")
    
    print(f"\nğŸ ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³:")
    print(f"   å…ˆèª­ã¿ã‚µã‚¤ã‚º: {baseline['readahead_size']}")
    
    total_experiments = len(params['chunk_sizes']) * len(params['cluster_sizes'])
    print(f"\nğŸ§ª å®Ÿé¨“æ•°: {total_experiments} ãƒ‘ã‚¿ãƒ¼ãƒ³")
    
    # å®Ÿè¡Œæ™‚é–“ã®ç°¡æ˜“è¦‹ç©ã‚‚ã‚Š
    estimated_time = total_experiments * trace['n_events'] / 10000  # çµŒé¨“çš„ãªå¼
    if estimated_time < 60:
        print(f"â±ï¸ æ¨å®šå®Ÿè¡Œæ™‚é–“: {estimated_time:.1f} ç§’")
    elif estimated_time < 3600:
        print(f"â±ï¸ æ¨å®šå®Ÿè¡Œæ™‚é–“: {estimated_time/60:.1f} åˆ†")
    else:
        print(f"â±ï¸ æ¨å®šå®Ÿè¡Œæ™‚é–“: {estimated_time/3600:.1f} æ™‚é–“")
        print(f"   âš ï¸ é•·æ™‚é–“ã®å®Ÿè¡ŒãŒäºˆæƒ³ã•ã‚Œã¾ã™ã€‚è¨­å®šã®è¦‹ç›´ã—ã‚’æ¨å¥¨ã—ã¾ã™ã€‚")


def quick_simulation(chunk_size: int = 8, cluster_size: int = 32, 
                    cache_size: int = 4096, n_events: int = 5000) -> Dict[str, Any]:
    """
    ã‚¯ã‚¤ãƒƒã‚¯ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆå˜ä¸€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼‰
    
    å˜ä¸€ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šã§CluMPã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã—ã€
    åŸºæœ¬çš„ãªå‹•ä½œç¢ºèªã‚„æ€§èƒ½ã®æ¦‚è¦æŠŠæ¡ã‚’è¡Œã„ã¾ã™ã€‚
    
    ç”¨é€”:
    - CluMPã®åŸºæœ¬å‹•ä½œç¢ºèª
    - æ–°ã—ã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®äºˆå‚™è©•ä¾¡
    - ãƒ‡ãƒ¢ãƒ»æ•™è‚²ç›®çš„ã§ã®å®Ÿè¡Œ
    - åŒ…æ‹¬çš„å®Ÿé¨“å‰ã®äº‹å‰æ¤œè¨¼
    
    Args:
        chunk_size (int): ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºï¼ˆãƒ–ãƒ­ãƒƒã‚¯æ•°ï¼‰
        cluster_size (int): ã‚¯ãƒ©ã‚¹ã‚¿ã‚µã‚¤ã‚ºï¼ˆãƒãƒ£ãƒ³ã‚¯æ•°ï¼‰
        cache_size (int): ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºï¼ˆãƒ–ãƒ­ãƒƒã‚¯æ•°ï¼‰
        n_events (int): ã‚¢ã‚¯ã‚»ã‚¹æ•°
        
    Returns:
        Dict[str, Any]: ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœ
            run_clump_simulation()ã¨åŒã˜å½¢å¼
            
    Raises:
        ValueError: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒä¸æ­£ãªå ´åˆ
        RuntimeError: ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œã«å¤±æ•—ã—ãŸå ´åˆ
        
    Example:
        >>> result = quick_simulation(chunk_size=16, cluster_size=64, n_events=10000)
        >>> print(f"ãƒ’ãƒƒãƒˆç‡: {result['hit_rate']:.3f}")
        >>> print(f"MCè¡Œæ•°: {result['memory_usage_mc_rows']}")
    """
    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¤œè¨¼
    if chunk_size <= 0 or cluster_size <= 0 or cache_size <= 0 or n_events <= 0:
        raise ValueError("All parameters must be positive")
    
    print(f"ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ")
    print(f"   ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: chunk={chunk_size}, cluster={cluster_size}, cache={cache_size}")
    print(f"   ã‚¢ã‚¯ã‚»ã‚¹æ•°: {n_events:,}")
    
    try:
        # åˆæˆãƒˆãƒ¬ãƒ¼ã‚¹ç”Ÿæˆï¼ˆã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆç”¨ã®è¨­å®šï¼‰
        trace = TraceGenerator.generate_synthetic_trace(
            n_events=n_events,
            num_files=max(10, n_events // 250),  # ã‚¢ã‚¯ã‚»ã‚¹æ•°ã«å¿œã˜ãŸãƒ•ã‚¡ã‚¤ãƒ«æ•°
            avg_file_length_blocks=50,            # å°ã•ã‚ã®ãƒ•ã‚¡ã‚¤ãƒ«
            sequential_prob=0.6,                  # æ¨™æº–çš„ãªé †æ¬¡ç‡
            jump_prob=0.15                        # æ¨™æº–çš„ãªã‚¸ãƒ£ãƒ³ãƒ—ç‡
        )
        
        # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
        logging.info(f"Quick simulation: chunk={chunk_size}, cluster={cluster_size}, "
                    f"cache={cache_size}, events={n_events}")
        
        result = run_clump_simulation(
            trace=trace,
            chunk_size=chunk_size,
            cluster_size=cluster_size,
            cache_size=cache_size,
            prefetch_window=16  # å›ºå®šå€¤
        )
        
        print(f"âœ… çµæœ: ãƒ’ãƒƒãƒˆç‡ {result['hit_rate']:.3f}, ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒåŠ¹ç‡ {result['prefetch_efficiency']:.3f}")
        logging.info(f"Quick simulation completed: hit_rate={result['hit_rate']:.3f}")
        
        return result
        
    except Exception as e:
        logging.error(f"Quick simulation failed: {e}")
        raise RuntimeError(f"Quick simulation failed: {e}")


def custom_parameter_experiment() -> None:
    """
    ã‚«ã‚¹ã‚¿ãƒ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å®Ÿé¨“ãƒ¢ãƒ¼ãƒ‰
    
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæŒ‡å®šã—ãŸå˜ä¸€ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§è©³ç´°ãªå®Ÿé¨“ã‚’è¡Œã„ã¾ã™ã€‚
    quick_simulation()ã‚ˆã‚Šã‚‚è©³ç´°ãªçµæœè¡¨ç¤ºã¨åˆ†æã‚’æä¾›ã—ã¾ã™ã€‚
    
    æ©Ÿèƒ½:
    - ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å…¥åŠ›
    - è©³ç´°ãªçµæœè¡¨ç¤º
    - ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
    - å…¥åŠ›æ¤œè¨¼
    
    Note:
        ã“ã®é–¢æ•°ã¯å¯¾è©±å‹ãƒ¢ãƒ¼ãƒ‰ã§ã®ã¿ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚
        ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‹ã‚‰ã®å‘¼ã³å‡ºã—ã«ã¯ quick_simulation() ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚
    """
    print("\nğŸ”¬ ã‚«ã‚¹ã‚¿ãƒ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å®Ÿé¨“ãƒ¢ãƒ¼ãƒ‰")
    print("-" * 50)
    
    try:
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å…¥åŠ›ï¼ˆæ¤œè¨¼ä»˜ãï¼‰
        chunk_size_input = input("ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 8): ").strip()
        chunk_size = max(1, int(chunk_size_input)) if chunk_size_input.isdigit() else 8
        
        cluster_size_input = input("ã‚¯ãƒ©ã‚¹ã‚¿ã‚µã‚¤ã‚º (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 32): ").strip()
        cluster_size = max(4, int(cluster_size_input)) if cluster_size_input.isdigit() else 32
        
        cache_size_input = input("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚º (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 4096): ").strip()
        cache_size = max(1024, int(cache_size_input)) if cache_size_input.isdigit() else 4096
        
        n_events_input = input("ã‚¢ã‚¯ã‚»ã‚¹æ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 5000): ").strip()
        n_events = max(1000, int(n_events_input)) if n_events_input.isdigit() else 5000
        
        # å®Ÿè¡Œæ™‚é–“è­¦å‘Š
        if n_events > 50000:
            confirm = input(f"âš ï¸ ã‚¢ã‚¯ã‚»ã‚¹æ•°ãŒå¤šã„ãŸã‚å®Ÿè¡Œæ™‚é–“ãŒé•·ããªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ç¶šè¡Œã—ã¾ã™ã‹ï¼Ÿ (y/N): ").strip().lower()
            if confirm not in ['y', 'yes']:
                print("å®Ÿé¨“ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸã€‚")
                return
        
        # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
        result = quick_simulation(chunk_size, cluster_size, cache_size, n_events)
        
        # è©³ç´°çµæœè¡¨ç¤º
        print(f"\nğŸ“Š è©³ç´°çµæœ:")
        print(f"   ç·ã‚¢ã‚¯ã‚»ã‚¹æ•°: {result['total_accesses']:,}")
        print(f"   ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆæ•°: {result['cache_hits']:,}")
        print(f"   ãƒ’ãƒƒãƒˆç‡: {result['hit_rate']:.3f} ({result['hit_rate']*100:.1f}%)")
        print(f"   ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒç·æ•°: {result['prefetch_total']:,}")
        print(f"   ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒä½¿ç”¨æ•°: {result['prefetch_used']:,}")
        print(f"   ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒåŠ¹ç‡: {result['prefetch_efficiency']:.3f} ({result['prefetch_efficiency']*100:.1f}%)")
        print(f"   MCè¡Œæ•°: {result['memory_usage_mc_rows']:,}")
        
        # çµæœã®è©•ä¾¡ã‚³ãƒ¡ãƒ³ãƒˆ
        if result['hit_rate'] > 0.7:
            print(f"\nğŸ’¡ è©•ä¾¡: å„ªç§€ãªãƒ’ãƒƒãƒˆç‡ã§ã™ã€‚ã“ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šã¯åŠ¹æœçš„ã§ã™ã€‚")
        elif result['hit_rate'] > 0.5:
            print(f"\nğŸ’¡ è©•ä¾¡: æ¨™æº–çš„ãªãƒ’ãƒƒãƒˆç‡ã§ã™ã€‚ã•ã‚‰ãªã‚‹æœ€é©åŒ–ã®ä½™åœ°ãŒã‚ã‚Šã¾ã™ã€‚")
        else:
            print(f"\nğŸ’¡ è©•ä¾¡: ãƒ’ãƒƒãƒˆç‡ãŒä½ã‚ã§ã™ã€‚ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®èª¿æ•´ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚")
            
    except (ValueError, KeyboardInterrupt):
        print("\nâš ï¸ å…¥åŠ›ã‚¨ãƒ©ãƒ¼ã¾ãŸã¯ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸã€‚")
        logging.info("Custom parameter experiment cancelled or failed")


def main():
    """
    ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°
    
    CluMPæ€§èƒ½è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆã§ã™ã€‚
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é¸æŠã«å¿œã˜ã¦ç•°ãªã‚‹è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã—ã€
    åŒ…æ‹¬çš„ãªæ€§èƒ½åˆ†æã‚’æä¾›ã—ã¾ã™ã€‚
    
    å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰:
    1. åŒ…æ‹¬çš„æ€§èƒ½è©•ä¾¡: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¯”è¼ƒ + ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒ + å¯è¦–åŒ–
    2. ã‚«ã‚¹ã‚¿ãƒ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å®Ÿé¨“: å˜ä¸€è¨­å®šã§ã®è©³ç´°åˆ†æ
    3. ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆ: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã§ã®å‹•ä½œç¢ºèª
    
    æ©Ÿèƒ½:
    - ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªãƒ¢ãƒ¼ãƒ‰é¸æŠ
    - å …ç‰¢ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
    - è©³ç´°ãªå®Ÿè¡Œãƒ­ã‚°
    - å†ç¾æ€§ç¢ºä¿ï¼ˆä¹±æ•°ã‚·ãƒ¼ãƒ‰å›ºå®šï¼‰
    - å¯è¦–åŒ–ãƒ¬ãƒãƒ¼ãƒˆè‡ªå‹•ç”Ÿæˆ
    
    Note:
        é•·æ™‚é–“å®Ÿè¡ŒãŒäºˆæƒ³ã•ã‚Œã‚‹å ´åˆã¯ã€äº‹å‰ã«è­¦å‘Šã‚’è¡¨ç¤ºã—ã¾ã™ã€‚
        ã™ã¹ã¦ã®å®Ÿé¨“çµæœã¯ãƒ­ã‚°ã«è¨˜éŒ²ã•ã‚Œã€ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã«æ´»ç”¨ã§ãã¾ã™ã€‚
    """
    print("CluMP æ€§èƒ½è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ï¼ˆè¦ä»¶å®šç¾©æ›¸æº–æ‹ ç‰ˆï¼‰")
    print("=" * 60)
    
    logging.info("CluMP Performance Evaluation System started")
    
    print("å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠã—ã¦ãã ã•ã„:")
    print("1. åŒ…æ‹¬çš„æ€§èƒ½è©•ä¾¡ï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¯”è¼ƒï¼‹ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒï¼‰")
    print("2. ã‚«ã‚¹ã‚¿ãƒ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å®Ÿé¨“ï¼ˆå˜ä¸€è¨­å®šï¼‰")
    print("3. ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šï¼‰")
    
    try:
        mode = input("\né¸æŠã—ã¦ãã ã•ã„ (1-3, ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1): ").strip()
        
        if mode == "2":
            logging.info("Custom parameter experiment mode selected")
            custom_parameter_experiment()
            return
        elif mode == "3":
            logging.info("Quick test mode selected")
            quick_simulation()
            return
        
        # ãƒ¢ãƒ¼ãƒ‰1: åŒ…æ‹¬çš„è©•ä¾¡
        logging.info("Comprehensive evaluation mode selected")
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼è¨­å®šå–å¾—
        config = get_user_config()
        print_config_summary(config)
        
        # å®Ÿè¡Œç¢ºèª
        print("\n" + "=" * 60)
        confirm = input("ã“ã®è¨­å®šã§å®Ÿè¡Œã—ã¾ã™ã‹ï¼Ÿ (y/N): ").strip().lower()
        if confirm not in ['y', 'yes']:
            print("å®Ÿè¡Œã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸã€‚")
            logging.info("Execution cancelled by user")
            return
            
    except KeyboardInterrupt:
        print("\nå®Ÿè¡Œã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸã€‚")
        logging.info("Execution cancelled by user (KeyboardInterrupt)")
        return
    except Exception as e:
        print(f"\näºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        logging.error(f"Unexpected error in mode selection: {e}")
        return
    
    # å®Ÿè¡Œç’°å¢ƒã®æº–å‚™
    # ä¹±æ•°ã‚·ãƒ¼ãƒ‰å›ºå®šï¼ˆå†ç¾æ€§ç¢ºä¿ï¼‰
    random.seed(42)
    logging.info("Random seed set to 42 for reproducibility")
    
    # åˆæˆãƒˆãƒ¬ãƒ¼ã‚¹ç”Ÿæˆ
    print("\nåˆæˆãƒˆãƒ¬ãƒ¼ã‚¹ç”Ÿæˆä¸­...")
    try:
        trace = TraceGenerator.generate_synthetic_trace(**config["trace"])
        print(f"ãƒˆãƒ¬ãƒ¼ã‚¹ç”Ÿæˆå®Œäº†: {len(trace)} ã‚¢ã‚¯ã‚»ã‚¹")
        logging.info(f"Synthetic trace generated: {len(trace)} accesses")
    except Exception as e:
        print(f"âŒ ãƒˆãƒ¬ãƒ¼ã‚¹ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        logging.error(f"Trace generation failed: {e}")
        return
    
    # æ€§èƒ½è©•ä¾¡å™¨åˆæœŸåŒ–
    try:
        evaluator = PerformanceEvaluator()
        logging.info("PerformanceEvaluator initialized successfully")
    except Exception as e:
        print(f"âŒ æ€§èƒ½è©•ä¾¡å™¨ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        logging.error(f"PerformanceEvaluator initialization failed: {e}")
        return
    
    # 1. ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¯”è¼ƒå®Ÿé¨“
    print("\n1. ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¯”è¼ƒå®Ÿé¨“å®Ÿè¡Œä¸­...")
    try:
        param_results = evaluator.compare_parameters(
            trace=trace,
            chunk_sizes=config["parameters"]["chunk_sizes"],
            cluster_sizes=config["parameters"]["cluster_sizes"],
            cache_size=config["parameters"]["cache_size"],
            prefetch_window=config["parameters"]["prefetch_window"]
        )
        
        if not param_results:
            print("âš ï¸ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¯”è¼ƒå®Ÿé¨“ã§æœ‰åŠ¹ãªçµæœãŒå¾—ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
            logging.warning("No valid results from parameter comparison")
            return
            
        logging.info(f"Parameter comparison completed: {len(param_results)} experiments")
        
    except Exception as e:
        print(f"âŒ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¯”è¼ƒå®Ÿé¨“ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        logging.error(f"Parameter comparison failed: {e}")
        return
    
    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åˆ†æ
    try:
        analysis = evaluator.analyze_results(param_results)
        
        if "error" in analysis:
            print(f"âŒ çµæœåˆ†æã«å¤±æ•—ã—ã¾ã—ãŸ: {analysis['error']}")
            logging.error(f"Results analysis failed: {analysis['error']}")
            return
            
        evaluator.print_analysis_report(analysis)
        logging.info("Parameter analysis completed successfully")
        
    except Exception as e:
        print(f"âŒ çµæœåˆ†æã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        logging.error(f"Results analysis failed: {e}")
        return
    
    # 2. ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒå®Ÿé¨“
    print("\n\n2. ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒå®Ÿé¨“å®Ÿè¡Œä¸­...")
    try:
        best_params = {
            "chunk_size": analysis["best_parameters"]["chunk_size"],
            "cluster_size": analysis["best_parameters"]["cluster_size"],
            "cache_size": config["parameters"]["cache_size"],
            "prefetch_window": config["parameters"]["prefetch_window"]
        }
        
        baseline_comparison = evaluator.compare_with_baseline(
            trace=trace,
            clump_params=best_params,
            baseline_readahead=config["baseline"]["readahead_size"]
        )
        
        # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆ
        evaluator.print_baseline_comparison_report(baseline_comparison)
        logging.info("Baseline comparison completed successfully")
        
    except Exception as e:
        print(f"âŒ ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒå®Ÿé¨“ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        logging.error(f"Baseline comparison failed: {e}")
        # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒãŒå¤±æ•—ã—ã¦ã‚‚ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åˆ†æçµæœã¯æœ‰åŠ¹ãªã®ã§ç¶šè¡Œ
    
    # 3. å¯è¦–åŒ–ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆï¼ˆè¦ä»¶å®šç¾©æ›¸ã®æ‹¡å¼µè¦ä»¶ï¼‰
    if evaluator.enable_visualization:
        print("\n\n3. å¯è¦–åŒ–ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­...")
        try:
            visualization_files = evaluator.visualizer.create_visualization_report(
                results=param_results,
                analysis=analysis,
                comparison=baseline_comparison if 'baseline_comparison' in locals() else None,
                trace=trace
            )
            print(f"\nğŸ“Š å¯è¦–åŒ–ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†ï¼")
            print(f"ç”Ÿæˆã•ã‚ŒãŸã‚°ãƒ©ãƒ•: {len(visualization_files)} å€‹")
            for i, path in enumerate(visualization_files, 1):
                print(f"  {i}. {os.path.basename(path)}")
            logging.info(f"Visualization report generated: {len(visualization_files)} files")
            
        except Exception as e:
            print(f"âš ï¸ å¯è¦–åŒ–ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            logging.warning(f"Visualization generation failed: {e}")
            print("æ•°å€¤ã«ã‚ˆã‚‹åˆ†æçµæœã¯æ­£å¸¸ã«å®Œäº†ã—ã¦ã„ã¾ã™ã€‚")
    else:
        print("\nå¯è¦–åŒ–æ©Ÿèƒ½ã¯ç„¡åŠ¹ã§ã™ã€‚æ•°å€¤ã«ã‚ˆã‚‹åˆ†æã®ã¿ã‚’å®Ÿè¡Œã—ã¾ã—ãŸã€‚")
        logging.info("Visualization disabled, numerical analysis only")
    
    # å®Ÿè¡Œå®Œäº†
    print("\nâœ… æ€§èƒ½è©•ä¾¡å®Œäº†")
    print("\nğŸ“‹ å®Ÿè¡Œã‚µãƒãƒªãƒ¼:")
    print(f"   å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰: åŒ…æ‹¬çš„æ€§èƒ½è©•ä¾¡")
    print(f"   ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å®Ÿé¨“: {len(param_results)} è¨­å®š")
    print(f"   æœ€é©è¨­å®š: chunk={analysis['best_parameters']['chunk_size']}, "
          f"cluster={analysis['best_parameters']['cluster_size']}")
    print(f"   æœ€é«˜ãƒ’ãƒƒãƒˆç‡: {analysis['best_parameters']['hit_rate']:.3f}")
    
    if 'baseline_comparison' in locals():
        clump_hit = baseline_comparison['clump']['hit_rate']
        baseline_hit = baseline_comparison['baseline']['hit_rate']
        if baseline_hit > 0:
            improvement = (clump_hit - baseline_hit) / baseline_hit * 100
            print(f"   ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒ: {improvement:+.1f}% æ”¹å–„")
    
    logging.info("Performance evaluation completed successfully")


if __name__ == "__main__":
    main()